Search.setIndex({"docnames": ["index", "source_files/Advanced_Learning_Algorithms/Deep_learning", "source_files/Advanced_Learning_Algorithms/Deep_learning-Copy1", "source_files/Advanced_Learning_Algorithms/practice", "source_files/Advanced_Learning_Algorithms/week1", "source_files/Advanced_Learning_Algorithms/week1/C2W1A1/C2_W1_Assignment", "source_files/Advanced_Learning_Algorithms/week1/C2W1A1/archive/C2_W1_Assignment-Copy1", "source_files/Advanced_Learning_Algorithms/week1/optional-labs/C2_W1_Lab01_Neurons_and_Layers", "source_files/Advanced_Learning_Algorithms/week1/optional-labs/C2_W1_Lab02_CoffeeRoasting_TF", "source_files/Advanced_Learning_Algorithms/week1/optional-labs/C2_W1_Lab03_CoffeeRoasting_Numpy", "source_files/Advanced_Learning_Algorithms/week2/C2W2A1/C2_W2_Assignment", "source_files/Advanced_Learning_Algorithms/week2/optional-labs/C2_W2_Multiclass_TF", "source_files/Advanced_Learning_Algorithms/week2/optional-labs/C2_W2_Relu", "source_files/Advanced_Learning_Algorithms/week2/optional-labs/C2_W2_SoftMax", "source_files/Advanced_Learning_Algorithms/week2/optional-labs/archive/C2_W2_SoftMax-Copy1", "source_files/Advanced_Learning_Algorithms/week2/optional-labs/archive/C2_W2_SoftMax-Copy2", "source_files/Advanced_Learning_Algorithms/week3/C2W3A1/C2_W3_Assignment", "source_files/Advanced_Learning_Algorithms/week4/C2W4A1/C2_W4_Decision_Tree_with_Markdown", "source_files/Supervised_Machine_Learning_Regression_and_Classification/Practice", "source_files/Supervised_Machine_Learning_Regression_and_Classification/Supervised", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week1/Optional_Labs/C1_W1_Lab01_Python_Jupyter_Soln", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week1/Optional_Labs/C1_W1_Lab03_Model_Representation_Soln", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week1/Optional_Labs/C1_W1_Lab04_Cost_function_Soln", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week1/Optional_Labs/C1_W1_Lab05_Gradient_Descent_Soln", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week1/Weak1", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week2/C1W2A1/week2_linear_regression", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week2/Optional_Labs/C1_W2_Lab01_Python_Numpy_Vectorization_Soln", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week2/Optional_Labs/C1_W2_Lab02_Multiple_Variable_Soln", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week2/Optional_Labs/C1_W2_Lab03_Feature_Scaling_and_Learning_Rate_Soln", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week2/Optional_Labs/C1_W2_Lab04_FeatEng_PolyReg_Soln", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week2/Optional_Labs/C1_W2_Lab05_Sklearn_GD_Soln", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week2/Optional_Labs/C1_W2_Lab06_Sklearn_Normal_Soln", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week2/Week2_practice_quiz", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/C1W3A1/C1_W3_Logistic_Regression", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/C1W3A1/archive/C1_W3_Logistic_Regression-Copy1", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/C1_W3_Lab01_Classification_Soln", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/C1_W3_Lab02_Sigmoid_function_Soln", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/C1_W3_Lab03_Decision_Boundary_Soln", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/C1_W3_Lab04_LogisticLoss_Soln", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/C1_W3_Lab05_Cost_Function_Soln", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/C1_W3_Lab06_Gradient_Descent_Soln", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/C1_W3_Lab07_Scikit_Learn_Soln", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/C1_W3_Lab08_Overfitting_Soln", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/C1_W3_Lab09_Regularization_Soln", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/archive/C1_W3_Lab05_Cost_Function_Soln-Copy1", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/archive/C1_W3_Lab05_Cost_Function_Soln-Copy2", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/archive/C1_W3_Lab09_Regularization_Soln-Copy1", "source_files/Unsupervised_Learning_Recommenders_Reinforcement_Learning/Unsupervised", "source_files/Unsupervised_Learning_Recommenders_Reinforcement_Learning/week1/C3W1A/C3W1A1/C3_W1_KMeans_Assignment", "source_files/Unsupervised_Learning_Recommenders_Reinforcement_Learning/week1/C3W1A/C3W1A2/C3_W1_Anomaly_Detection", "source_files/Unsupervised_Learning_Recommenders_Reinforcement_Learning/week2/C3W2/C3W2A1/C3_W2_Collaborative_RecSys_Assignment", "source_files/Unsupervised_Learning_Recommenders_Reinforcement_Learning/week2/C3W2/C3W2A2/C3_W2_RecSysNN_Assignment", "source_files/Unsupervised_Learning_Recommenders_Reinforcement_Learning/week3/C3W3A1/C3_W3_A1_Assignment", "source_files/Unsupervised_Learning_Recommenders_Reinforcement_Learning/week3/optional-labs/State-action value function example"], "filenames": ["index.rst", "source_files/Advanced_Learning_Algorithms/Deep_learning.ipynb", "source_files/Advanced_Learning_Algorithms/Deep_learning-Copy1.ipynb", "source_files/Advanced_Learning_Algorithms/practice.ipynb", "source_files/Advanced_Learning_Algorithms/week1.ipynb", "source_files/Advanced_Learning_Algorithms/week1/C2W1A1/C2_W1_Assignment.ipynb", "source_files/Advanced_Learning_Algorithms/week1/C2W1A1/archive/C2_W1_Assignment-Copy1.ipynb", "source_files/Advanced_Learning_Algorithms/week1/optional-labs/C2_W1_Lab01_Neurons_and_Layers.ipynb", "source_files/Advanced_Learning_Algorithms/week1/optional-labs/C2_W1_Lab02_CoffeeRoasting_TF.ipynb", "source_files/Advanced_Learning_Algorithms/week1/optional-labs/C2_W1_Lab03_CoffeeRoasting_Numpy.ipynb", "source_files/Advanced_Learning_Algorithms/week2/C2W2A1/C2_W2_Assignment.ipynb", "source_files/Advanced_Learning_Algorithms/week2/optional-labs/C2_W2_Multiclass_TF.ipynb", "source_files/Advanced_Learning_Algorithms/week2/optional-labs/C2_W2_Relu.ipynb", "source_files/Advanced_Learning_Algorithms/week2/optional-labs/C2_W2_SoftMax.ipynb", "source_files/Advanced_Learning_Algorithms/week2/optional-labs/archive/C2_W2_SoftMax-Copy1.ipynb", "source_files/Advanced_Learning_Algorithms/week2/optional-labs/archive/C2_W2_SoftMax-Copy2.ipynb", "source_files/Advanced_Learning_Algorithms/week3/C2W3A1/C2_W3_Assignment.ipynb", "source_files/Advanced_Learning_Algorithms/week4/C2W4A1/C2_W4_Decision_Tree_with_Markdown.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/Practice.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/Supervised.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week1/Optional_Labs/C1_W1_Lab01_Python_Jupyter_Soln.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week1/Optional_Labs/C1_W1_Lab03_Model_Representation_Soln.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week1/Optional_Labs/C1_W1_Lab04_Cost_function_Soln.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week1/Optional_Labs/C1_W1_Lab05_Gradient_Descent_Soln.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week1/Weak1.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week2/C1W2A1/week2_linear_regression.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week2/Optional_Labs/C1_W2_Lab01_Python_Numpy_Vectorization_Soln.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week2/Optional_Labs/C1_W2_Lab02_Multiple_Variable_Soln.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week2/Optional_Labs/C1_W2_Lab03_Feature_Scaling_and_Learning_Rate_Soln.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week2/Optional_Labs/C1_W2_Lab04_FeatEng_PolyReg_Soln.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week2/Optional_Labs/C1_W2_Lab05_Sklearn_GD_Soln.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week2/Optional_Labs/C1_W2_Lab06_Sklearn_Normal_Soln.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week2/Week2_practice_quiz.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/C1W3A1/C1_W3_Logistic_Regression.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/C1W3A1/archive/C1_W3_Logistic_Regression-Copy1.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/C1_W3_Lab01_Classification_Soln.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/C1_W3_Lab02_Sigmoid_function_Soln.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/C1_W3_Lab03_Decision_Boundary_Soln.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/C1_W3_Lab04_LogisticLoss_Soln.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/C1_W3_Lab05_Cost_Function_Soln.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/C1_W3_Lab06_Gradient_Descent_Soln.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/C1_W3_Lab07_Scikit_Learn_Soln.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/C1_W3_Lab08_Overfitting_Soln.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/C1_W3_Lab09_Regularization_Soln.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/archive/C1_W3_Lab05_Cost_Function_Soln-Copy1.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/archive/C1_W3_Lab05_Cost_Function_Soln-Copy2.ipynb", "source_files/Supervised_Machine_Learning_Regression_and_Classification/week3/OptionalLabs/archive/C1_W3_Lab09_Regularization_Soln-Copy1.ipynb", "source_files/Unsupervised_Learning_Recommenders_Reinforcement_Learning/Unsupervised.ipynb", "source_files/Unsupervised_Learning_Recommenders_Reinforcement_Learning/week1/C3W1A/C3W1A1/C3_W1_KMeans_Assignment.ipynb", "source_files/Unsupervised_Learning_Recommenders_Reinforcement_Learning/week1/C3W1A/C3W1A2/C3_W1_Anomaly_Detection.ipynb", "source_files/Unsupervised_Learning_Recommenders_Reinforcement_Learning/week2/C3W2/C3W2A1/C3_W2_Collaborative_RecSys_Assignment.ipynb", "source_files/Unsupervised_Learning_Recommenders_Reinforcement_Learning/week2/C3W2/C3W2A2/C3_W2_RecSysNN_Assignment.ipynb", "source_files/Unsupervised_Learning_Recommenders_Reinforcement_Learning/week3/C3W3A1/C3_W3_A1_Assignment.ipynb", "source_files/Unsupervised_Learning_Recommenders_Reinforcement_Learning/week3/optional-labs/State-action value function example.ipynb"], "titles": ["Welcome to Machine-Learning-Andrew-Ng\u2019s documentation!", "Advanced_Learning_Algorithms", "Advanced_Learning_Algorithms", "&lt;no title&gt;", "Advanced_Learning_Algorithms", "Practice Lab: Neural Networks for Handwritten Digit Recognition, Binary", "Neural Networks for Handwritten Digit Recognition, Binary", "Optional Lab - Neurons and Layers", "Optional Lab - Simple Neural Network", "Optional Lab - Simple Neural Network", "Practice Lab: Neural Networks for Handwritten Digit Recognition, Multiclass", "Optional Lab - Multi-class Classification", "Optional Lab - ReLU activation", "Optional Lab - Softmax Function", "Optional Lab - Softmax Function", "Optional Lab - Softmax Function", "Practice Lab: Advice for Applying Machine Learning", "Practice Lab: Decision Trees", "2 - Logistic Regression", "Supervised_Machine_Learning", "Optional Lab: Brief Introduction to Python and Jupyter Notebooks", "Optional Lab: Model Representation", "Optional Lab: Cost Function", "Optional Lab: Gradient Descent for Linear Regression", "Supervised_Machine_Learning", "Assignment - W2:", "Optional Lab: Python, NumPy and Vectorization", "Optional Lab: Multiple Variable Linear Regression", "Optional Lab: Feature scaling and Learning Rate (Multi-variable)", "Optional Lab: Feature Engineering and Polynomial Regression", "Optional Lab: Linear Regression using Scikit-Learn", "Optional Lab: Linear Regression using Scikit-Learn", "Weak-2", "Logistic Regression", "Logistic Regression", "Optional Lab: Classification", "Optional Lab: Logistic Regression", "Optional Lab: Logistic Regression, Decision Boundary", "Optional Lab: Logistic Regression, Logistic Loss", "Optional Lab: Cost Function for Logistic Regression", "Optional Lab: Gradient Descent for Logistic Regression", "Ungraded Lab: Logistic Regression using Scikit-Learn", "Ungraded Lab: Overfitting", "Optional Lab - Regularized Cost and Gradient", "Optional Lab: Cost Function for Logistic Regression", "Optional Lab: Cost Function for Logistic Regression", "Optional Lab - Regularized Cost and Gradient", "Unsupervised_Learning", "K-means Clustering", "Anomaly Detection", " Practice lab: Collaborative Filtering Recommender Systems", " Practice lab: Deep Learning for Content-Based Filtering", "Deep Q-Learning - Lunar Lander", "State Action Value Function Example"], "terms": {"supervised_machine_learn": 0, "modul": [0, 6, 34, 44, 45, 46, 52], "1": [0, 2, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 17, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53], "option": [0, 5, 6, 10, 48], "lab": [0, 6], "w1": [0, 2, 4, 5, 6, 8, 9, 10, 11, 12, 28], "brief": [0, 26, 50], "introduct": [0, 26, 50], "python": [0, 5, 6, 10, 16, 17, 18, 21, 23, 25, 27, 28, 33, 34, 36, 48, 49, 50, 51, 52], "jupyt": [0, 31, 52, 53], "notebook": [0, 2, 4, 5, 6, 8, 13, 14, 15, 31, 52, 53], "practic": [0, 2, 4, 8, 20, 40, 43, 46, 48, 52], "quiz": 0, "2": [0, 2, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 17, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53], "w2": [0, 2, 4, 5, 6, 8, 9, 10, 11, 12, 28], "numpi": [0, 2, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53], "vector": [0, 2, 4, 5, 6, 9, 10, 13, 14, 15, 18, 21, 27, 28, 33, 34, 36, 37, 49, 50, 51, 52], "assign": [0, 5, 6, 10, 16, 17, 18, 22, 33, 34, 48, 49, 52], "3": [0, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 21, 22, 23, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52], "w3": [0, 5, 6, 10, 28], "advanced_learning_algorithm": 0, "convolut": 0, "neural": [0, 7, 11, 13, 14, 15, 16, 50, 51, 52], "network": [0, 7, 11, 12, 13, 14, 15, 16, 49, 50, 51, 52], "unsupervised_learn": 0, "index": [0, 6, 10, 13, 14, 15, 16, 17, 19, 21, 26, 48, 50], "search": 0, "page": [0, 31], "9": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 21, 23, 25, 26, 27, 29, 30, 31, 33, 34, 36, 40, 43, 46, 48, 49, 51, 52], "ignor": [2, 4, 5, 6, 10, 12, 18, 19], "line": [2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 25, 26, 28, 33, 34, 36, 37, 40, 44, 45, 46, 49, 52], "ar": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52], "ad": [2, 4, 5, 6, 7, 10, 12, 16, 22, 25, 27, 29, 42, 52], "load": [2, 4, 5, 6, 8, 10, 17, 23, 25, 27, 28, 33, 34, 36, 48, 49, 50, 51, 52], "some": [2, 4, 5, 6, 7, 8, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 33, 34, 42, 43, 46, 48, 49, 50, 51, 52], "data": [2, 5, 6, 7, 16, 17, 21, 23, 26, 27, 28, 29, 30, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 50, 51, 52], "import": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53], "sy": [2, 4, 18, 19], "o": [2, 4, 7, 8, 9, 18, 19, 35], "proj_path": [2, 4, 18, 19], "f": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 37, 40, 43, 46, 49, 50, 51, 52], "environ": [2, 4, 19, 31, 52], "home": [2, 4, 8, 9, 18, 19, 25, 27, 28], "my_web": [2, 4, 18, 19, 25], "machin": [2, 4, 5, 6, 7, 10, 18, 19, 25, 26, 30, 31, 50, 51], "learn": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 20, 21, 22, 23, 24, 25, 26, 27, 29, 33, 34, 37, 40, 50], "andrew": [2, 4, 18, 19, 25], "ng": [2, 4, 18, 19, 25], "module_path": [2, 4], "sourc": [2, 4, 16, 18, 19, 25, 30, 31, 50], "source_fil": [2, 4, 18, 19, 25], "chdir": [2, 4, 19], "In": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53], "thi": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53], "we": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 33, 34, 36, 37, 38, 39, 40, 44, 45, 48, 49, 50, 51, 52], "explor": [2, 4, 5, 6, 7, 8, 11, 13, 14, 15, 16, 19, 22, 26, 27, 28, 29, 35, 36, 37, 38, 40, 42, 51, 52], "inner": [2, 4, 7, 48, 52], "work": [2, 4, 5, 6, 7, 11, 12, 16, 17, 18, 19, 20, 24, 25, 26, 28, 30, 31, 33, 34, 36, 38, 48, 49, 50, 52], "unit": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 21, 25, 33, 34, 48, 49, 50, 51, 52], "particular": [2, 4, 7, 8, 10, 13, 14, 15, 16, 19, 26, 35, 43, 46], "draw": [2, 4, 7, 16, 19, 26, 27, 49], "parallel": [2, 4, 7, 19, 26], "you": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53], "have": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38, 40, 42, 43, 46, 48, 49, 50, 51, 52], "master": [2, 4, 7], "cours": [2, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 26, 27, 30, 31, 37, 38, 43, 46, 50, 51], "The": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52], "introduc": [2, 4, 7, 10, 12], "demonstr": [2, 4, 5, 6, 7, 8, 16, 19, 26, 27, 35], "how": [2, 4, 5, 6, 7, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 33, 34, 37, 43, 46, 48, 49, 50, 51, 52, 53], "implement": [2, 4, 5, 6, 7, 9, 10, 13, 14, 15, 17, 18, 21, 22, 23, 26, 27, 28, 30, 31, 33, 34, 36, 38, 39, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52], "framework": [2, 4, 5, 6, 7, 50, 52], "kera": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 50, 51, 52], "i": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52], "develop": [2, 4, 5, 6, 7, 16, 19, 23, 27, 28, 29, 38, 39, 42, 43, 44, 45, 46, 50], "googl": [2, 4, 5, 6, 7], "2019": [2, 4, 5, 6, 7, 16], "integr": [2, 4, 5, 6, 7, 13, 14, 15], "releas": [2, 4, 5, 6, 7, 51], "0": [2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53], "independ": [2, 4, 5, 6, 7], "fran\u00e7oi": [2, 4, 5, 6, 7], "chollet": [2, 4, 5, 6, 7], "creat": [2, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 29, 33, 34, 48, 49, 50, 51, 52], "centric": [2, 4, 5, 6, 7], "interfac": [2, 4, 5, 6, 7], "us": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52], "10": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 23, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52], "np": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53], "matplotlib": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49], "pyplot": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49], "plt": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49], "path": [2, 4, 14, 15, 18, 19, 23], "append": [2, 4, 17, 18, 19, 23, 25, 27, 33, 34, 40, 48, 51, 52], "week1": [2, 4, 19], "tf": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 50, 51, 52], "from": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53], "dens": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 51, 52], "input": [2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 40, 48, 51, 52], "sequenti": [2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 51, 52], "loss": [2, 4, 5, 6, 7, 8, 11, 13, 14, 15, 16, 18, 22, 25, 33, 34, 39, 40, 44, 45, 50, 51, 52], "meansquarederror": [2, 4, 7, 51], "binarycrossentropi": [2, 4, 5, 6, 7, 8], "lab_utils_common": [2, 4, 7, 8, 9, 12, 13, 14, 15, 19, 28, 30, 35, 36, 37, 39, 40, 43, 44, 45, 46], "dlc": [2, 4, 7, 8, 9, 12, 13, 14, 15, 16, 19, 28, 30, 35, 39, 40, 44, 45], "lab_neurons_util": [2, 4, 7], "plt_prob_1d": [2, 4, 7], "sigmoidnp": [2, 4, 7], "plt_linear": [2, 4, 7], "plt_logist": [2, 4, 7], "style": [2, 4, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 31, 35, 36, 37, 38, 39, 40, 42, 44, 45], "deeplearn": [2, 4, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 21, 22, 23, 27, 28, 30, 31, 35, 36, 37, 38, 39, 40, 42, 44, 45], "mplstyle": [2, 4, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 21, 22, 23, 27, 28, 30, 31, 35, 36, 37, 38, 39, 40, 42, 44, 45], "log": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 33, 34, 38, 39, 40, 43, 44, 45, 46, 50, 52], "getlogg": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 52], "setlevel": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 52], "error": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 22, 23, 26, 28, 33, 34, 40, 50, 51, 52], "autograph": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16], "set_verbos": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16], "2023": [2, 4, 6, 16], "08": [2, 4, 7, 8, 18, 19, 23, 28, 29, 33, 35, 40], "28": [2, 4, 5, 6, 8, 9, 10, 11, 16, 18, 19, 29, 34, 40, 50, 51], "22": [2, 4, 5, 6, 10, 11, 16, 17, 18, 19, 25, 33, 34, 44, 45, 46, 51], "44": [2, 4, 11, 16, 18, 19, 33, 34, 50], "25": [2, 4, 5, 6, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 28, 31, 33, 34, 51, 52], "464276": 2, "tsl": [2, 4, 6], "cuda": [2, 4, 6], "cudart_stub": [2, 4, 6], "cc": [2, 4, 5, 6, 10], "could": [2, 4, 5, 6, 10, 13, 14, 15, 16, 19, 26, 29, 35, 50, 51], "find": [2, 4, 6, 13, 14, 15, 16, 18, 19, 20, 22, 23, 25, 28, 29, 33, 34, 35, 36, 48, 49, 50], "driver": [2, 4, 6], "your": [2, 4, 5, 6, 8, 9, 16, 18, 20, 21, 22, 24, 26, 27, 28, 29, 30, 38, 48, 50, 51, 52], "gpu": [2, 4, 6, 19, 26], "26": [2, 4, 5, 6, 8, 10, 11, 16, 17, 18, 19, 25, 27, 29, 33, 34, 50, 51], "260482": 2, "262869": 2, "core": [2, 4, 6, 14, 15], "platform": [2, 4, 5, 6, 10, 16], "cpu_feature_guard": [2, 4, 6], "182": [2, 4, 6, 11, 16], "binari": [2, 4, 10, 11, 12, 19, 26, 35, 49, 50], "optim": [2, 4, 5, 6, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 22, 23, 25, 27, 28, 33, 34, 50, 51, 52], "avail": [2, 4, 6, 14, 15, 16, 19, 20, 24, 26, 29, 35, 51, 52], "cpu": [2, 4, 6, 19, 26], "instruct": [2, 4, 6, 17, 19, 22, 26, 42], "perform": [2, 4, 5, 6, 9, 13, 14, 15, 16, 18, 19, 23, 25, 26, 27, 28, 30, 31, 33, 34, 40, 43, 46, 49, 52], "critic": [2, 4, 6, 19, 26], "oper": [2, 4, 5, 6, 9, 11, 13, 14, 15, 18, 23, 25, 26, 27, 33, 34, 49, 50], "To": [2, 4, 5, 6, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 33, 34, 42, 48, 49, 50, 51, 52], "enabl": [2, 4, 6, 10, 12, 13, 14, 15], "follow": [2, 4, 5, 6, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 33, 34, 35, 36, 37, 38, 48, 49, 50, 52], "avx2": [2, 4, 6], "fma": [2, 4, 6], "other": [2, 4, 6, 11, 13, 14, 15, 16, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 33, 34, 36, 50, 51], "rebuild": [2, 4, 6], "appropri": [2, 4, 6, 19, 25, 38], "compil": [2, 4, 5, 6, 8, 10, 11, 13, 14, 15, 16, 28, 50, 51], "flag": [2, 4, 6, 52], "29": [2, 4, 5, 6, 8, 9, 10, 11, 13, 16, 18, 19, 33, 34, 51], "460556": 2, "w": [2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 40, 43, 44, 45, 46, 50, 52], "tf2tensorrt": [2, 4, 6], "util": [2, 4, 5, 6, 8, 9, 10, 16, 17, 18, 19, 21, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 39, 40, 44, 45, 48, 49, 50, 51, 52, 53], "py_util": [2, 4, 6], "38": [2, 4, 5, 6, 8, 10, 11, 16, 17, 18, 19, 30], "trt": [2, 4, 6], "warn": [2, 4, 5, 6, 10, 12, 52], "tensorrt": [2, 4, 6], "ll": [2, 4, 5, 6, 7, 9, 16, 17, 19, 23, 26, 29, 37, 39, 40, 44, 45, 50, 51, 52], "an": [2, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 38, 40, 43, 46, 48, 49, 50, 52], "exampl": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38, 40, 42, 48, 49, 50, 51, 52], "hous": [2, 4, 7, 18, 19, 21, 22, 23, 27, 28, 29, 31, 33, 34], "price": [2, 4, 7, 21, 22, 23, 27, 28, 29, 30, 31], "11": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 23, 25, 26, 27, 28, 29, 30, 33, 34, 36, 37, 40, 44, 45, 48, 49, 50, 51, 52], "x_train": [2, 4, 7, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 38, 39, 40, 44, 45, 49], "arrai": [2, 4, 5, 6, 7, 8, 9, 10, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52], "dtype": [2, 4, 5, 7, 18, 19, 26, 38, 48, 50, 52], "float32": [2, 4, 5, 7], "size": [2, 4, 5, 6, 7, 8, 10, 16, 18, 19, 21, 22, 23, 26, 27, 28, 30, 31, 33, 34, 35, 36, 43, 46, 48, 49, 50, 51, 52], "1000": [2, 4, 5, 6, 7, 8, 16, 18, 19, 21, 22, 23, 26, 27, 28, 29, 30, 31, 33, 34, 40, 49, 52], "squar": [2, 4, 7, 16, 18, 21, 22, 23, 25, 28, 29, 31, 33, 49, 50, 51, 52], "feet": [2, 4, 7, 21, 22, 23, 28, 31], "y_train": [2, 4, 7, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 27, 28, 30, 31, 33, 34, 35, 36, 38, 39, 40, 44, 45, 51], "300": [2, 4, 7, 16, 21, 22, 23, 25, 27, 28, 29, 30, 31, 48, 50, 52], "500": [2, 4, 5, 6, 7, 16, 21, 22, 23, 27, 28, 29, 31, 52], "dollar": [2, 4, 7, 21, 22, 23, 27, 28, 31], "fig": [2, 4, 5, 6, 7, 10, 16, 19, 22, 23, 27, 28, 29, 30, 35, 36, 37, 39, 40, 44, 45, 48, 52], "ax": [2, 4, 5, 6, 7, 10, 11, 16, 18, 19, 22, 23, 28, 29, 30, 33, 34, 35, 36, 37, 39, 40, 44, 45, 48, 51], "subplot": [2, 4, 5, 6, 7, 10, 16, 18, 19, 23, 27, 28, 29, 30, 35, 36, 37, 39, 40, 44, 45, 48], "scatter": [2, 4, 7, 16, 18, 19, 21, 25, 28, 29, 30, 35, 49], "marker": [2, 4, 7, 18, 19, 21, 25, 29, 33, 34, 35, 49], "x": [2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 52], "c": [2, 4, 7, 18, 19, 21, 25, 26, 29, 33, 34, 35, 36, 37, 39, 40, 44, 45, 48, 49, 52], "r": [2, 4, 7, 14, 15, 18, 19, 21, 23, 25, 27, 28, 29, 33, 34, 37, 40, 43, 46, 50, 52], "label": [2, 4, 5, 6, 7, 10, 16, 17, 18, 19, 21, 25, 28, 29, 30, 33, 34, 35, 37, 39, 40, 44, 45, 49], "point": [2, 4, 5, 6, 7, 8, 10, 11, 12, 16, 17, 18, 19, 21, 22, 23, 25, 28, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 48, 49, 51, 52], "legend": [2, 4, 7, 16, 18, 19, 21, 28, 29, 30, 33, 34, 35, 39, 44, 45], "fontsiz": [2, 4, 5, 6, 7, 10, 16, 19, 35, 39, 40, 44, 45], "xx": [2, 4, 5, 6, 7], "larg": [2, 4, 7, 13, 14, 15, 16, 18, 19, 21, 22, 23, 26, 28, 29, 33, 34, 35, 36], "set_ylabel": [2, 4, 7, 16, 18, 19, 23, 27, 28, 29, 30, 35, 36, 37, 39, 40, 44, 45], "set_xlabel": [2, 4, 7, 16, 18, 19, 23, 27, 28, 29, 30, 35, 36, 37, 39, 40, 44, 45], "sqft": [2, 4, 7, 21, 22, 23, 27, 28, 30, 31], "show": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 48, 49, 51], "same": [2, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 22, 23, 25, 26, 27, 33, 34, 36, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52], "f_": [2, 4, 7, 16, 18, 19, 21, 22, 23, 25, 27, 28, 29, 33, 34, 36, 37, 38, 39, 40, 43, 44, 45, 46], "mathbf": [2, 4, 5, 6, 7, 10, 13, 14, 15, 16, 18, 19, 21, 25, 26, 27, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 43, 44, 45, 46, 50, 51], "b": [2, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 40, 43, 44, 45, 46, 49, 50, 51], "cdot": [2, 4, 7, 10, 18, 19, 27, 28, 33, 34, 36, 37, 38, 39, 40, 43, 44, 45, 46, 49, 50], "tag": [2, 4, 7, 10, 13, 14, 15, 16, 18, 19, 21, 22, 23, 25, 27, 28, 29, 33, 34, 36, 37, 38, 39, 40, 43, 44, 45, 46, 50, 51, 52], "can": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53], "defin": [2, 4, 5, 6, 7, 8, 10, 13, 14, 15, 18, 19, 23, 25, 33, 34, 38, 39, 44, 45, 46, 50, 52], "one": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 19, 21, 22, 23, 25, 26, 27, 28, 29, 31, 35, 36, 38, 39, 40, 44, 45, 48, 49, 50, 51, 52], "compar": [2, 4, 5, 6, 7, 10, 13, 14, 15, 16, 18, 19, 25, 28, 29, 33, 34, 40, 43, 46, 51], "familiar": [2, 4, 5, 6, 7, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 29, 33, 34, 36, 40, 48, 49, 50, 51], "12": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 16, 18, 19, 23, 26, 27, 28, 29, 30, 33, 34, 35, 39, 40, 44, 45, 48, 51, 52], "linear_lay": [2, 4, 7], "let": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 25, 26, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 44, 45, 48, 49, 50, 51], "": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53], "examin": [2, 4, 5, 6, 7, 8, 10, 12, 19, 23, 38, 39, 40, 44, 45], "13": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 23, 25, 26, 27, 28, 29, 33, 34, 44, 45, 48, 49, 50, 51, 52], "get_weight": [2, 4, 5, 6, 7, 8, 10, 11, 52], "There": [2, 4, 7, 8, 9, 10, 11, 16, 19, 26, 27, 30, 31, 40, 42, 51], "yet": [2, 4, 7, 16], "instanti": [2, 4, 7, 8, 50], "try": [2, 4, 5, 6, 7, 9, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 28, 29, 31, 33, 34, 35, 36, 37, 38, 40, 42, 43, 46, 48, 49, 52], "trigger": [2, 4, 7], "note": [2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 26, 27, 28, 29, 30, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52], "must": [2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 19, 26, 28, 31, 50, 51], "d": [2, 4, 5, 6, 7, 8, 10, 17, 18, 19, 23, 26, 27, 29, 31, 33, 34, 37, 48, 49, 50, 51, 52], "so": [2, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 33, 34, 48, 50, 51, 52], "reshap": [2, 4, 5, 6, 7, 8, 10, 11, 16, 18, 19, 26, 29, 31, 33, 34, 37, 43, 46, 48, 50, 51], "14": [2, 4, 5, 6, 7, 8, 10, 11, 14, 15, 16, 18, 19, 25, 26, 27, 28, 30, 34, 40, 44, 45, 48, 49, 51, 52], "a1": [2, 4, 5, 6, 7, 9, 51], "print": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 21, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52], "tensor": [2, 4, 5, 6, 7, 52], "71": [2, 4, 8, 11, 16, 18, 27, 28, 30], "shape": [2, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 33, 34, 36, 39, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52], "result": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 21, 22, 26, 27, 28, 29, 31, 33, 34, 35, 36, 48, 49, 50, 51, 52], "anoth": [2, 4, 5, 6, 7, 10, 16, 17, 18, 19, 25, 28, 29, 33, 34, 38, 49], "name": [2, 4, 5, 6, 7, 8, 10, 11, 14, 15, 16, 17, 18, 19, 20, 23, 24, 34, 38, 44, 45, 46, 50, 52], "entri": [2, 4, 7, 13, 14, 15, 21, 51], "now": [2, 4, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 27, 29, 33, 34, 35, 36, 37, 38, 39, 43, 44, 45, 46, 48, 49, 50, 51, 52], "look": [2, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 18, 19, 25, 28, 33, 34, 35, 36, 37, 38, 48, 49, 51, 52], "bia": [2, 4, 5, 6, 7, 8, 9, 10, 12, 16, 18, 19, 21, 27, 28, 33, 34, 50], "These": [2, 4, 5, 6, 7, 11, 19, 21, 22, 25, 26, 27, 28, 35, 36, 42, 50, 51, 52], "randomli": [2, 4, 5, 6, 7, 10, 48], "initi": [2, 4, 7, 10, 16, 18, 19, 23, 25, 27, 28, 29, 33, 34, 36, 40, 48, 50, 51, 52], "small": [2, 4, 7, 8, 9, 10, 13, 14, 15, 16, 19, 22, 28, 29, 38, 50, 51], "number": [2, 4, 5, 6, 7, 8, 10, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 30, 33, 34, 36, 38, 39, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52], "default": [2, 4, 7, 8, 10, 21, 52], "being": [2, 4, 7, 11, 17, 19, 28, 35, 38, 49], "zero": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 33, 34, 35, 36, 38, 40, 43, 46, 48, 50, 51, 52], "15": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 25, 26, 27, 28, 31, 34, 48, 49, 51, 52], "A": [2, 4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 23, 25, 26, 27, 28, 33, 34, 36, 49, 50, 51, 52], "singl": [2, 4, 5, 6, 7, 10, 13, 14, 15, 18, 19, 23, 25, 26, 27, 28, 33, 34, 35, 36, 38, 39, 40, 44, 45, 48, 51, 52], "featur": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 21, 23, 25, 26, 27, 30, 31, 33, 34, 37, 38, 39, 40, 43, 44, 45, 46, 49, 50, 51], "match": [2, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 16, 18, 19, 22, 26, 28, 29, 30, 35, 36, 38, 50, 51], "dimens": [2, 4, 5, 6, 7, 18, 21, 22, 26, 27, 48], "our": [2, 4, 5, 6, 7, 8, 9, 10, 16, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 33, 34, 36, 37, 38, 40, 48, 49, 50, 51, 52], "abov": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38, 40, 42, 43, 46, 48, 50, 51, 52], "random": [2, 4, 5, 6, 7, 8, 10, 11, 16, 18, 19, 26, 33, 34, 43, 46, 48, 50, 51, 52], "valu": [2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52], "set": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 21, 23, 25, 26, 27, 28, 29, 30, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52], "them": [2, 4, 5, 6, 7, 16, 17, 19, 26, 50, 52], "known": [2, 4, 7, 19, 36, 37, 52], "16": [2, 4, 5, 6, 7, 8, 10, 11, 14, 15, 16, 18, 25, 26, 28, 29, 30, 34, 48, 49, 51, 52], "set_w": [2, 4, 7], "200": [2, 4, 7, 8, 9, 11, 16, 18, 21, 22, 27, 28, 29, 31, 50, 52], "set_b": [2, 4, 7], "100": [2, 4, 7, 10, 11, 16, 18, 19, 21, 22, 23, 27, 28, 29, 31, 33, 34, 35, 49, 50, 52, 53], "set_weight": [2, 4, 7, 8, 52], "take": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 33, 34, 38, 40, 48, 52], "list": [2, 4, 6, 7, 14, 15, 17, 23, 48, 50, 51], "equat": [2, 4, 7, 13, 14, 15, 18, 19, 22, 23, 25, 27, 28, 29, 31, 33, 34, 38, 40, 43, 46, 49, 50, 52], "output": [2, 4, 5, 6, 7, 8, 9, 10, 12, 16, 17, 18, 19, 21, 25, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52], "17": [2, 4, 5, 6, 7, 8, 9, 10, 11, 16, 18, 19, 25, 26, 27, 28, 30, 34, 44, 45, 46, 48, 49, 50, 51, 52], "alin": [2, 4, 7], "dot": [2, 4, 5, 6, 7, 9, 11, 16, 18, 19, 21, 26, 27, 28, 29, 30, 33, 37, 39, 40, 43, 44, 45, 46, 50, 51, 52], "thei": [2, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 19, 26, 29, 42, 43, 46, 49, 50, 51], "produc": [2, 4, 5, 6, 7, 8, 10, 11, 12, 16, 18, 19, 20, 21, 22, 23, 24, 26, 31, 33, 34, 38, 48, 50, 51, 52], "make": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 30, 33, 34, 36, 37, 48, 50, 51, 52], "predict": [2, 5, 6, 7, 11, 13, 14, 15, 16, 18, 22, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 40, 43, 46, 49, 50, 52], "train": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52], "18": [2, 4, 5, 6, 7, 8, 9, 10, 11, 16, 18, 19, 25, 26, 27, 29, 31, 33, 34, 44, 45, 46, 48, 49, 51, 52], "prediction_tf": [2, 4, 7], "prediction_np": [2, 4, 7], "19": [2, 4, 5, 6, 7, 8, 10, 11, 16, 18, 19, 25, 26, 27, 29, 33, 34, 44, 45, 46, 49, 50, 51], "g": [2, 4, 5, 6, 7, 9, 18, 19, 33, 34, 36, 37, 38, 39, 40, 43, 44, 45, 46], "where": [2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 52], "check": [2, 4, 5, 6, 7, 16, 18, 28, 39, 40, 44, 45, 48, 50, 52], "20": [2, 4, 5, 6, 8, 10, 11, 16, 18, 19, 23, 25, 26, 29, 33, 34, 36, 44, 45, 46, 49, 50, 51], "4": [2, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 17, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53], "5": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53], "matrix": [2, 4, 5, 6, 7, 8, 9, 10, 17, 18, 26, 27, 28, 29, 31, 33, 34, 48, 49, 50, 51], "21": [2, 4, 6, 10, 11, 16, 18, 19, 25, 28, 30, 33, 34, 46, 51], "po": [2, 4, 7, 18, 19, 35], "neg": [2, 4, 7, 8, 9, 12, 13, 14, 15, 18, 19, 23, 25, 26, 28, 33, 34, 35, 36, 49], "figsiz": [2, 4, 5, 6, 7, 10, 16, 18, 19, 23, 27, 28, 29, 30, 35, 36, 37, 39, 40, 44, 45, 48], "80": [2, 4, 7, 11, 16, 18, 19, 23, 33, 34, 35, 50, 51], "red": [2, 4, 5, 6, 7, 16, 17, 19, 21, 23, 25, 35, 37, 39, 40, 44, 45, 48, 49], "y": [2, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 27, 28, 29, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 49, 50, 51, 52], "facecolor": [2, 4, 7, 19, 35], "none": [2, 4, 5, 6, 7, 8, 10, 16, 18, 19, 27, 33, 34, 35, 49, 51], "edgecolor": [2, 4, 7, 19, 35], "dlblue": [2, 4, 7, 16, 19, 35, 39, 40, 44, 45], "lw": [2, 4, 7, 16, 19, 35, 40], "set_ylim": [2, 4, 7, 19, 35], "set_titl": [2, 4, 5, 6, 7, 10, 16, 19, 23, 27, 28, 35, 36, 37, 48], "variabl": [2, 4, 5, 6, 7, 18, 20, 21, 22, 23, 24, 35, 36, 37, 38, 39, 40, 44, 45, 48, 50, 51, 52], "plot": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 21, 22, 23, 25, 27, 28, 29, 30, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 46, 48, 49, 52], "describ": [2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 21, 23, 25, 26, 28, 29, 35, 38, 42, 48, 49, 51, 52], "section": [2, 4, 5, 6, 7, 17, 18, 19, 25, 26, 28, 33, 34, 48, 49, 50, 52], "contain": [2, 4, 5, 6, 7, 9, 10, 12, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33, 34, 35, 48, 49, 50, 51, 52], "altern": [2, 4, 7], "method": [2, 4, 5, 6, 7, 8, 10, 13, 14, 15, 19, 20, 22, 24, 25, 28, 31, 42, 48, 52], "most": [2, 4, 5, 6, 7, 13, 14, 15, 18, 19, 26, 27, 28, 29, 34, 44, 45, 46, 48, 49], "often": [2, 4, 7, 11, 19, 25, 26, 28, 35, 48, 49, 51], "multi": [2, 4, 5, 6, 7, 9], "conveni": [2, 4, 7, 19, 26, 36, 52], "mean": [2, 4, 7, 8, 9, 16, 18, 19, 22, 23, 25, 26, 28, 29, 33, 34, 49, 50, 51, 52], "construct": [2, 4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 51], "23": [2, 4, 5, 6, 10, 11, 13, 16, 17, 18, 19, 33, 34, 51], "input_dim": [2, 4, 7], "l1": [2, 4, 5, 6, 7, 8, 10, 11, 16], "summari": [2, 4, 5, 6, 7, 8, 10, 16, 19, 21, 23, 27, 51], "paramet": [2, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 21, 22, 23, 25, 26, 27, 28, 29, 30, 33, 34, 36, 37, 38, 39, 40, 43, 44, 45, 46, 48, 50, 52], "onli": [2, 4, 7, 10, 13, 14, 15, 17, 18, 19, 21, 25, 26, 28, 33, 34, 38, 43, 46, 48, 49, 50, 51, 52], "ha": [2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23, 25, 26, 28, 29, 30, 31, 33, 34, 36, 37, 38, 40, 48, 49, 50, 51, 52], "two": [2, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 31, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 48, 49, 50, 51, 52], "24": [2, 4, 5, 6, 10, 11, 16, 17, 18, 19, 26, 29, 33, 34, 48, 51, 52], "34": [2, 4, 5, 6, 7, 8, 10, 11, 14, 15, 16, 18, 19, 29, 33, 34, 44, 45, 46, 51], "_________________________________________________________________": [2, 4, 5, 6, 7, 8, 10, 16], "type": [2, 4, 5, 6, 7, 8, 10, 11, 16, 17, 18, 19, 20, 24, 25, 26, 27, 33, 34, 51, 52], "param": [2, 4, 5, 6, 7, 8, 10, 16, 51], "total": [2, 4, 5, 6, 7, 8, 10, 16, 18, 19, 22, 25, 33, 34, 39, 40, 45, 48, 51, 52], "8": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 40, 43, 46, 48, 49, 50, 51, 52], "00": [2, 4, 5, 18, 19, 23, 27, 28, 30, 31, 33, 34, 36, 50, 51], "byte": [2, 4], "trainabl": [2, 4, 5, 6, 7, 8, 10, 16, 50, 51], "non": [2, 4, 5, 6, 7, 8, 10, 11, 16, 17, 18, 19, 21, 25, 27, 28, 29, 33, 34, 37, 38, 49, 50, 51], "logistic_lay": [2, 4, 7], "get_lay": [2, 4, 7, 8, 11], "alog": [2, 4, 7], "569m": 2, "step": [2, 4, 5, 6, 8, 10, 11, 13, 16, 17, 18, 19, 23, 25, 26, 27, 28, 31, 33, 34, 36, 48, 49, 50, 51, 52], "01": [2, 4, 5, 7, 8, 10, 11, 13, 16, 18, 19, 23, 25, 27, 28, 29, 30, 33, 34, 36, 51, 52], "30": [2, 6, 10, 11, 13, 14, 15, 16, 18, 19, 33, 34, 49, 51], "82m": 2, "70m": 2, "67m": [2, 4], "60m": [2, 4], "57m": 2, "53m": [2, 4], "62m": 2, "64m": 2, "50m": [2, 4], "49m": [2, 4], "52m": [2, 4], "54m": [2, 4], "51m": [2, 4], "65m": 2, "48m": [2, 4], "55m": [2, 4], "68m": 2, "69m": 2, "76m": 2, "58m": [2, 4], "66m": [2, 4], "46m": [2, 4], "shade": [2, 4, 7, 8, 9, 19, 37, 40], "reflect": [2, 4, 7, 19, 23, 39, 40, 44, 45], "which": [2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52], "vari": [2, 4, 5, 6, 7, 10, 13, 14, 15, 16, 18, 19, 22, 28, 33, 34], "built": [2, 4, 5, 6, 7, 8, 9, 10], "veri": [2, 4, 7, 8, 11, 16, 19, 26, 27, 28, 29, 30, 31, 43, 46, 49, 50], "similar": [2, 4, 7, 8, 9, 16, 18, 19, 27, 28, 33, 34, 35, 38, 43, 46, 48, 49, 50], "build": [2, 4, 5, 6, 8, 9, 10, 11, 16, 17, 18, 19, 21, 25, 27, 28, 29, 33, 34, 35, 50, 51, 52], "33": [2, 5, 6, 10, 11, 16, 18, 19, 33, 34, 48], "lab_coffee_util": [2, 4, 8, 9], "load_coffee_data": [2, 4, 8, 9], "plt_roast": [2, 4, 8, 9], "plt_prob": [2, 4, 8, 9, 19, 40], "plt_layer": [2, 4, 8, 9], "plt_network": [2, 4, 8, 9], "plt_output_unit": [2, 4, 8, 9], "coffe": [2, 4, 8, 9], "roast": [2, 4, 8, 9], "below": [2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52], "temperatur": [2, 4, 8, 9], "celsiu": [2, 4, 8, 9], "durat": [2, 4, 8, 9, 19, 26], "minut": [2, 4, 8, 9, 16, 18, 19, 33, 34, 48, 51, 52], "suggest": [2, 4, 8, 9, 51], "best": [2, 4, 8, 9, 10, 12, 17, 19, 25, 26, 29, 30, 35, 36, 42, 48, 49, 50], "kept": [2, 4, 8, 9, 12], "between": [2, 4, 8, 9, 10, 11, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 28, 36, 37, 38, 39, 42, 43, 44, 45, 46, 48, 51, 52], "while": [2, 4, 8, 9, 11, 13, 14, 15, 16, 18, 19, 22, 23, 25, 27, 28, 31, 33, 34, 35, 37, 38, 39, 40, 43, 44, 45, 46, 49, 50, 51], "temp": [2, 4, 8, 9], "should": [2, 4, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 21, 23, 25, 26, 28, 29, 33, 34, 36, 37, 42, 48, 49, 50, 51, 52], "175": [2, 4, 8, 9, 11, 16, 19, 25], "260": [2, 4, 8, 9, 16, 18], "degre": [2, 4, 8, 9, 16, 19, 42, 43, 46], "Of": [2, 4, 8, 9, 19, 26], "rise": [2, 4, 8, 9, 50], "shrink": [2, 4, 8, 9, 23], "35": [2, 4, 5, 6, 10, 11, 16, 18, 19, 25, 27, 33], "fit": [2, 4, 5, 6, 8, 10, 11, 13, 14, 15, 16, 18, 21, 22, 23, 25, 29, 30, 33, 34, 36, 37, 39, 42, 44, 45, 49, 50, 51], "back": [2, 4, 5, 6, 8, 10, 19, 21, 23, 37], "propag": [2, 4, 8], "cover": [2, 4, 8, 13, 14, 15, 19, 36], "next": [2, 4, 5, 6, 8, 10, 11, 14, 15, 17, 18, 19, 21, 26, 27, 29, 33, 34, 36, 38, 42, 48, 52], "week": [2, 4, 5, 6, 8, 10, 12, 19, 35, 40, 42, 51], "lectur": [2, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 28, 35, 36, 37, 42], "proce": [2, 4, 8, 48], "more": [2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 25, 26, 28, 29, 33, 34, 37, 38, 48, 49, 50, 51, 52], "quickli": [2, 4, 8, 28], "normal": [2, 13, 14, 15, 19, 29, 30, 31, 49, 50, 51], "procedur": [2, 4, 8, 19, 43, 46, 48], "each": [2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 33, 34, 36, 37, 39, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52], "rang": [2, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 39, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52], "It": [2, 4, 5, 6, 8, 9, 10, 11, 16, 17, 18, 19, 22, 25, 26, 27, 28, 29, 33, 34, 36, 38, 48, 50, 51, 52], "appli": [2, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 26, 29, 33, 34, 35, 36, 39, 44, 45, 48, 49, 50, 51, 52], "here": [2, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 30, 33, 34, 35, 38, 39, 42, 44, 45, 48, 49, 50, 51, 52], "adapt": [2, 4, 8, 9, 10], "varianc": [2, 4, 8, 9, 16, 28, 49], "save": [2, 4, 8, 18, 19, 23, 25, 27, 33, 34, 40, 51, 52], "intern": [2, 4, 8, 18], "ani": [2, 4, 8, 18, 19, 23, 25, 28, 33, 34, 35, 36, 37, 38, 49, 50, 51], "futur": [2, 4, 5, 6, 8], "36": [2, 5, 6, 8, 10, 11, 16, 17, 18, 19, 33, 51], "max": [2, 4, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 28, 49, 51, 52], "min": [2, 4, 8, 9, 13, 14, 15, 18, 19, 28, 49, 51, 52], "pre": [2, 4, 8, 9, 12, 27, 48, 50], "2f": [2, 4, 8, 9, 16, 18, 19, 25, 27, 31, 33, 34, 50, 51, 52], "norm_l": [2, 4, 8, 9], "axi": [2, 4, 5, 6, 8, 9, 11, 16, 18, 19, 21, 25, 26, 28, 29, 30, 33, 34, 35, 37, 38, 39, 40, 44, 45, 48, 49, 51, 52], "xn": [2, 4, 8, 9, 11], "post": [2, 4, 8, 9], "284": [2, 4, 8, 9, 16], "99": [2, 4, 8, 9, 10, 11, 16, 27], "151": [2, 4, 8, 9, 11, 16, 50], "32": [2, 4, 5, 6, 8, 9, 10, 11, 13, 16, 18, 19, 28, 30, 31, 33, 34, 51], "45": [2, 4, 8, 9, 11, 13, 16, 18, 19, 25, 27, 33, 34, 50], "51": [2, 4, 8, 9, 11, 16, 18, 19, 25, 29, 33, 34, 50, 51], "66": [2, 4, 8, 9, 10, 11, 16, 18], "69": [2, 4, 8, 9, 11, 16, 18, 19, 27, 28, 30, 50], "79": [2, 4, 8, 9, 11, 16, 18, 19, 28, 29, 33, 50], "70": [2, 4, 8, 9, 11, 16, 18, 19, 25, 27], "tile": [2, 4, 8], "copi": [2, 4, 5, 6, 8, 9, 18, 19, 23, 25, 27, 28, 33, 34, 40, 52], "increas": [2, 4, 8, 10, 16, 18, 19, 22, 23, 25, 28, 29, 33, 34, 38, 42, 43, 46, 51, 52], "reduc": [2, 4, 8, 16, 18, 19, 23, 27, 28, 29, 33, 34, 42, 43, 46, 48, 50, 51], "xt": [2, 4, 8], "yt": [2, 4, 8], "200000": [2, 4, 8, 29], "shown": [2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 35, 36, 37, 39, 40, 44, 45, 48, 49, 50, 51, 52], "49": [2, 11, 16, 18, 19, 25, 28, 29, 50], "set_se": [2, 4, 8, 10, 11, 16, 50, 51, 52], "1234": [2, 4, 8, 10, 11, 16, 50], "achiev": [2, 4, 8, 11, 19, 22, 25, 26, 29, 42], "consist": [2, 4, 8, 10, 11, 12, 19, 36, 50, 51, 52], "layer1": [2, 4, 5, 6, 8, 10], "layer2": [2, 4, 5, 6, 8, 10], "specifi": [2, 4, 5, 6, 8, 10, 11, 13, 14, 15, 19, 26, 48, 51, 52], "expect": [2, 4, 5, 6, 8, 10, 13, 14, 15, 16, 17, 18, 19, 23, 25, 26, 27, 29, 31, 33, 34, 39, 40, 43, 44, 45, 46, 48, 49, 50], "allow": [2, 4, 8, 13, 14, 15, 16, 18, 19, 20, 24, 26, 29, 33, 34, 42, 48, 49, 51, 52], "when": [2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 25, 26, 27, 28, 29, 33, 34, 38, 48, 50, 51, 52], "statement": [2, 4, 5, 6, 8, 10, 11, 17, 23, 27, 33, 34, 49, 51, 52], "omit": [2, 4, 8], "includ": [2, 4, 5, 6, 8, 10, 11, 13, 14, 15, 16, 19, 22, 26, 38, 39, 43, 44, 45, 46, 50, 51, 52], "final": [2, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 23, 25, 27, 28, 31, 33, 34, 37, 40, 48, 49, 51, 52], "consid": [2, 4, 8, 16, 17, 19, 25, 29, 38, 49, 50, 52], "would": [2, 4, 8, 13, 14, 15, 16, 17, 18, 19, 21, 22, 25, 27, 28, 29, 33, 34, 35, 36, 51, 52], "instead": [2, 4, 8, 21, 29, 50, 51], "account": [2, 4, 8, 52], "improv": [2, 4, 8, 10, 16, 19, 26, 27, 28, 35, 36, 42, 51, 52], "numer": [2, 4, 8, 10, 11, 13, 14, 15, 19, 26, 52], "stabil": [2, 4, 8, 10, 52], "detail": [2, 4, 5, 6, 8, 9, 11, 12, 16, 18, 19, 23, 26, 28, 33, 34, 50], "later": [2, 4, 5, 6, 8, 17, 18, 19, 23, 25, 27, 28, 33, 34, 40, 50, 52], "provid": [2, 4, 5, 6, 8, 10, 11, 12, 16, 17, 18, 19, 20, 22, 23, 24, 26, 28, 29, 33, 34, 38, 39, 40, 44, 45, 48, 49, 50, 51, 52], "descript": [2, 4, 5, 6, 8, 16, 21, 27, 28, 39, 44, 45, 50, 52], "50": [2, 4, 8, 11, 16, 18, 19, 25, 33, 34, 48, 50, 51], "sequential_1": [2, 4, 51], "52": [2, 4, 11, 16, 18, 29, 31, 33, 51], "count": [2, 4, 5, 6, 8, 10, 13, 14, 15, 19, 26, 28, 51], "correspond": [2, 4, 5, 6, 8, 9, 10, 13, 14, 15, 18, 19, 33, 34, 40, 48, 49, 50, 52], "element": [2, 4, 5, 6, 8, 10, 11, 13, 14, 15, 17, 18, 19, 25, 26, 27, 28, 33, 34, 36, 40, 48, 49, 50, 51, 52], "l1_num_param": [2, 4, 5, 6, 8], "b1": [2, 4, 5, 6, 8, 9, 10, 11, 12, 51], "l2_num_param": [2, 4, 5, 6, 8], "b2": [2, 4, 5, 6, 8, 9, 10, 11, 12, 51], "l2": [2, 4, 5, 6, 8, 10, 11, 16], "bias": [2, 4, 5, 6, 8, 9, 12, 50], "first": [2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 28, 31, 33, 34, 36, 39, 44, 45, 48, 49, 50, 51, 52], "second": [2, 4, 5, 6, 8, 10, 19, 22, 26, 27, 28, 40, 48, 51], "n": [2, 4, 5, 6, 8, 9, 10, 13, 14, 15, 17, 18, 19, 21, 25, 26, 27, 28, 29, 30, 31, 33, 34, 39, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52], "nb1": [2, 4, 8], "nb2": [2, 4, 8], "06": [2, 5, 10, 13, 18, 19, 23, 27, 28, 30, 33], "82": [2, 4, 9, 11, 16, 18, 19, 29, 33, 51], "04": [2, 5, 10, 13, 18, 19, 23, 28, 29, 33, 36, 52], "75": [2, 11, 16, 18, 19, 25, 33, 51], "week2": [2, 4, 8, 16, 19, 25], "For": [2, 4, 5, 6, 8, 10, 13, 14, 15, 16, 17, 18, 19, 21, 25, 26, 27, 29, 33, 34, 37, 38, 39, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52], "run": [2, 4, 5, 6, 8, 9, 10, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 40, 42, 43, 46, 48, 49, 50, 51, 52], "gradient": [2, 4, 5, 6, 8, 10, 16, 22, 25, 27, 28, 29, 33, 34, 38, 42, 50, 52], "descent": [2, 4, 5, 6, 8, 10, 16, 25, 27, 28, 29, 33, 34, 38, 42, 50, 52], "adam": [2, 4, 5, 6, 8, 10, 11, 13, 14, 15, 16, 50, 51, 52], "learning_r": [2, 4, 8, 10, 50, 51, 52], "6250": [2, 4, 8, 16], "768u": [2, 4, 8], "1782": [2, 4, 8, 16], "781u": [2, 4, 8, 16], "1165": [2, 4, 8], "792u": [2, 4, 8, 16], "0426": [2, 4, 8], "791u": [2, 4, 8, 16], "0160": [2, 4, 8], "787u": [2, 4, 8, 16], "0104": [2, 4, 8], "6": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53], "795u": [2, 4, 8, 16], "0073": [2, 4, 8, 29], "7": [2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 21, 22, 23, 25, 26, 27, 29, 30, 31, 33, 34, 36, 39, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52], "0052": [2, 4, 8], "789u": [2, 4, 8, 16], "0037": [2, 4, 8], "780u": [2, 4, 8, 16], "0027": [2, 4, 8], "773u": [2, 4, 8], "0020": [2, 4, 8], "lt": [2, 4, 5, 6, 8, 11, 13, 14, 15, 16, 17, 18, 19, 25, 26, 27, 33, 48, 49, 51], "callback": [2, 4, 5, 8, 11, 13, 16, 51], "histori": [2, 4, 5, 8, 10, 11, 13, 16, 18, 19, 23, 25, 27, 33, 34, 40, 50, 51, 52], "0x7f5edc665990": [2, 4, 8], "gt": [2, 4, 5, 6, 8, 11, 13, 14, 15, 16, 17, 18, 19, 25, 26, 27, 33, 34, 44, 45, 46, 48, 49, 51], "after": [2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 23, 25, 28, 29, 33, 34, 48, 49, 50, 51, 52], "been": [2, 4, 8, 10, 11, 16, 18, 19, 21, 26, 33, 34, 35, 50, 51, 52], "92": [2, 4, 5, 6, 8, 11, 16, 18, 19, 27, 33, 34], "85": [2, 4, 8, 11, 16, 18, 28, 30, 52], "76": [2, 4, 8, 11, 13, 16, 18, 25, 50], "42": [2, 4, 5, 8, 10, 11, 13, 16, 19, 31, 50], "95": [2, 4, 8, 11, 16, 18, 28, 30], "previou": [2, 4, 8, 9, 11, 16, 17, 18, 19, 22, 23, 25, 26, 27, 28, 29, 30, 33, 34, 35, 39, 43, 44, 45, 46, 49], "remain": [2, 4, 8, 16, 23], "robust": [2, 4, 8], "chang": [2, 4, 8, 12, 13, 14, 15, 16, 18, 19, 21, 23, 25, 28, 33, 34, 40, 43, 46, 49, 50, 51, 52, 53], "over": [2, 4, 8, 10, 16, 18, 22, 23, 25, 27, 28, 33, 34, 37, 38, 39, 44, 45, 49], "time": [2, 4, 5, 6, 8, 10, 16, 18, 19, 23, 25, 26, 27, 29, 33, 34, 40, 48, 50, 51, 52], "differ": [2, 4, 8, 10, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 33, 34, 38, 39, 43, 44, 45, 46, 48, 49, 52], "somewhat": [2, 4, 8, 19, 26], "discuss": [2, 4, 8, 13, 14, 15, 17, 19, 23, 28, 36, 51], "solut": [2, 4, 8, 22, 23, 28, 31, 33, 34, 42, 48, 51], "feel": [2, 4, 8, 17, 50, 51], "free": [2, 4, 8, 17, 50, 51], "re": [2, 4, 8, 16, 17, 18, 19, 25, 28, 29, 33, 34, 35, 36, 42, 48, 49], "cell": [2, 4, 5, 6, 8, 9, 10, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 27, 29, 31, 33, 34, 35, 36, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 52], "comment": [2, 4, 8, 23], "out": [2, 4, 5, 6, 8, 10, 11, 16, 17, 18, 19, 21, 25, 26, 28, 29, 33, 34, 38, 43, 46, 48, 49, 50, 52], "see": [2, 4, 5, 6, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 33, 34, 36, 37, 39, 41, 43, 44, 45, 46, 48, 49, 51, 52, 53], "94": [2, 4, 8, 11, 16, 18, 29], "89": [2, 4, 8, 11, 16, 18, 50], "87": [2, 4, 8, 11, 16, 18, 28, 50], "31": [2, 4, 5, 6, 8, 9, 10, 11, 13, 16, 18, 19, 25, 33, 34, 51], "27": [2, 4, 5, 6, 8, 9, 10, 11, 16, 17, 18, 19, 28, 29, 30, 31, 33, 34, 51], "86": [2, 4, 8, 11, 16, 18, 19, 27, 33], "54": [2, 4, 8, 11, 16, 18, 29], "onc": [2, 4, 5, 6, 8, 9, 11, 16, 18, 19, 21, 29, 33, 34, 48, 50, 51, 52], "recal": [2, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 25, 27, 28, 29, 33, 34, 35, 37, 38, 39, 40, 44, 45, 49, 50, 51, 52], "probabl": [2, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 18, 19, 33, 34, 37, 40, 49, 53], "case": [2, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 22, 25, 26, 28, 33, 34, 35, 36, 38, 43, 46, 48, 50, 51, 52], "good": [2, 4, 5, 6, 8, 9, 10, 16, 17, 18, 19, 25, 28, 33, 34, 35, 36, 48, 49], "decis": [2, 4, 8, 9, 11, 33, 34, 39, 40, 44, 45], "threshold": [2, 4, 5, 6, 8, 9, 17, 18, 19, 33, 34, 35, 36], "start": [2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23, 25, 26, 28, 29, 33, 34, 36, 37, 38, 39, 40, 41, 44, 45, 48, 49, 50, 51, 52], "row": [2, 4, 5, 6, 8, 9, 10, 19, 26, 27, 48, 49, 50, 51], "m": [2, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 33, 34, 36, 38, 39, 40, 43, 44, 45, 46, 48, 49, 52], "test": [2, 4, 5, 6, 8, 10, 17, 18, 19, 25, 26, 27, 33, 34, 48, 49, 50, 51, 52], "well": [2, 4, 8, 10, 12, 16, 18, 19, 22, 26, 28, 29, 30, 31, 33, 34, 35, 36, 38, 49, 52], "x_test": [2, 4, 8, 16, 31], "postiv": [2, 4, 8, 9], "x_testn": [2, 4, 8], "63e": [2, 8, 18, 19], "03e": [2, 8, 10, 18], "wa": [2, 4, 5, 6, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 28, 29, 33, 34, 35, 39, 42, 43, 44, 45, 46, 48, 50, 51, 52], "entir": [2, 4, 8, 10, 19, 25, 52], "dure": [2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 23, 25, 28, 33, 34, 49, 50, 51, 52], "progress": [2, 4, 8, 10, 19, 23, 25, 28, 48, 52], "like": [2, 4, 8, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 28, 29, 30, 33, 34, 35, 36, 37, 48, 49, 50, 52], "910u": [2, 4, 8, 16], "current": [2, 4, 8, 10, 17, 19, 23, 40, 48, 52], "effici": [2, 4, 5, 6, 8, 10, 19, 26, 48, 52], "broken": [2, 4, 8, 10], "expand": [2, 4, 5, 6, 8, 10, 19, 25, 51], "notat": [2, 4, 8, 10, 19, 26, 27, 50], "2nd": [2, 4, 8, 10, 11, 12, 19, 26], "execut": [2, 4, 8, 10, 23], "convert": [2, 4, 8, 9, 10, 13, 14, 15], "yhat": [2, 4, 5, 6, 8, 9, 10, 16], "zeros_lik": [2, 4, 8, 9, 19, 27, 40], "len": [2, 4, 8, 9, 10, 16, 17, 18, 19, 21, 23, 25, 27, 28, 29, 30, 33, 34, 43, 46, 50, 51], "els": [2, 4, 5, 6, 8, 9, 17, 18, 19, 33, 52], "accomplish": [2, 4, 5, 6, 8, 9, 10, 11, 19, 29, 36], "succinctli": [2, 4, 8, 9], "astyp": [2, 4, 5, 6, 8, 9, 50], "int": [2, 4, 5, 6, 8, 9, 16, 17, 18, 19, 23, 25, 27, 33, 34, 48, 50, 51], "determin": [2, 4, 5, 6, 8, 10, 16, 18, 19, 21, 22, 33, 34, 35, 38, 49, 51, 52], "role": [2, 4, 8, 51], "node": [2, 4, 8, 17], "all": [2, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 22, 23, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52], "whose": [2, 4, 8, 18, 19, 21, 51, 52], "graph": [2, 4, 5, 6, 8, 9, 10, 11, 16, 17, 18, 19, 22, 23, 25, 27, 29, 33, 34, 40, 49], "repres": [2, 4, 5, 6, 8, 9, 10, 11, 16, 18, 19, 21, 22, 23, 25, 26, 27, 33, 34, 35, 37, 42, 48, 52], "typic": [2, 4, 8, 13, 14, 15, 16, 19, 22, 26, 50], "thing": [2, 4, 8, 13, 14, 15, 19, 23, 35, 42, 50, 52], "mai": [2, 4, 5, 6, 8, 10, 11, 16, 19, 20, 24, 25, 26, 28, 29, 36, 40, 48, 49, 51], "respons": [2, 4, 8, 12, 49], "bad": [2, 4, 8], "region": [2, 4, 8, 19, 37, 49], "larger": [2, 4, 5, 6, 8, 10, 13, 14, 15, 17, 19, 23, 28, 29, 31, 35, 49, 51], "too": [2, 4, 8, 16, 22, 23, 28], "low": [2, 4, 8, 22, 49], "short": [2, 4, 5, 6, 8, 28], "combin": [2, 4, 8, 11, 13, 14, 15, 19, 29, 38, 39, 44, 45, 51], "worth": [2, 4, 8, 16, 19, 22, 26, 50, 51], "its": [2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 17, 18, 19, 23, 25, 26, 27, 28, 29, 33, 34, 37, 38, 48, 49, 51, 52], "own": [2, 4, 5, 6, 8, 9, 19, 20, 24, 26, 50, 51], "through": [2, 4, 8, 13, 14, 15, 17, 18, 19, 21, 22, 25, 26, 28, 33, 34, 48, 51, 52], "process": [2, 4, 8, 13, 14, 15, 17, 23], "much": [2, 4, 8, 23, 28, 29, 49], "sort": [2, 4, 8, 50, 51], "person": [2, 4, 8], "might": [2, 4, 8, 16, 18, 19, 22, 33, 34, 49, 50, 51], "choos": [2, 4, 5, 6, 8, 16, 17, 19, 21, 37, 39, 44, 45, 48, 49, 52], "bit": [2, 4, 8, 16, 28, 48, 52], "difficult": [2, 4, 8, 28, 51], "visual": [2, 4, 5, 6, 8, 23, 48], "know": [2, 4, 8, 11, 16, 20, 29, 52], "calcul": [2, 4, 5, 6, 8, 10, 13, 14, 15, 16, 17, 18, 21, 22, 23, 25, 27, 33, 34, 36, 39, 43, 44, 45, 46, 48, 49, 50, 52], "possibl": [2, 4, 5, 6, 8, 9, 10, 11, 17, 18, 19, 25, 33, 34, 35, 40, 48], "three": [2, 4, 5, 6, 8, 10, 16, 17, 19, 23, 26, 27, 28, 35, 48, 51], "high": [2, 4, 8, 16, 28, 49, 50], "area": [2, 4, 8, 19, 25, 28, 29], "maximum": [2, 4, 8, 11, 16, 17, 28, 51], "whole": [2, 4, 8, 9], "action": [2, 4, 5, 6, 8, 10, 12, 19, 43, 46, 51, 52], "left": [2, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 28, 33, 34, 36, 38, 39, 40, 43, 44, 45, 46, 51, 52], "raw": [2, 4, 8, 9, 28, 29, 30], "blue": [2, 4, 8, 9, 11, 16, 19, 21, 28, 35, 37, 39, 40, 44, 45, 48, 49], "overlaid": [2, 4, 8, 9], "right": [2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 26, 28, 29, 33, 34, 35, 36, 38, 39, 40, 43, 44, 45, 46, 51, 52], "made": [2, 4, 8, 9, 16, 19, 28, 41, 51], "moment": [2, 4, 5, 6, 8, 10, 19, 23, 40], "netf": [2, 4, 8, 9], "lambda": [2, 4, 8, 9, 16, 18, 19, 33, 34, 43, 46, 50], "abil": [2, 4, 8, 12, 16, 29], "handl": [2, 4, 5, 6, 8, 17], "complex": [2, 4, 5, 6, 8, 12, 18, 19, 33, 34, 37, 51], "divid": [2, 4, 8, 10, 18, 19, 22, 25, 28, 33, 34, 40, 48, 50], "multipl": [2, 4, 8, 9, 10, 11, 13, 14, 15, 19, 26, 28, 31, 35, 36, 50, 51, 52], "refer": [2, 4, 9, 10, 13, 14, 15, 16, 18, 25, 26, 29, 30, 31, 33, 34, 36, 48, 50, 52], "As": [2, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 23, 25, 28, 29, 33, 34, 36, 37, 40, 43, 46, 48, 52], "simpli": [2, 4, 9, 12, 16, 18, 19, 25, 33, 34, 48, 51, 52], "loop": [2, 4, 5, 6, 9, 10, 18, 19, 21, 22, 25, 26, 27, 33, 34, 39, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52], "visit": [2, 4, 5, 6, 9], "j": [2, 4, 5, 6, 9, 10, 13, 14, 15, 18, 19, 22, 23, 25, 27, 28, 33, 34, 38, 39, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52], "product": [2, 4, 5, 6, 9, 18, 19, 26, 27, 33, 34, 37, 50, 51], "sum": [2, 4, 5, 6, 9, 10, 12, 13, 14, 15, 18, 19, 22, 23, 25, 26, 27, 28, 33, 34, 38, 40, 43, 44, 46, 49, 50, 51], "form": [2, 4, 5, 6, 9, 10, 12, 13, 14, 15, 18, 19, 29, 31, 33, 34, 37, 39, 43, 44, 45, 46, 48, 50, 51, 52], "z": [2, 4, 5, 6, 9, 10, 12, 13, 14, 15, 18, 19, 25, 29, 30, 33, 34, 36, 37, 39, 40, 43, 44, 45, 46], "subroutin": [2, 4, 5, 6, 9], "def": [2, 4, 5, 6, 9, 10, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 33, 34, 36, 39, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52], "my_dens": [2, 4, 5, 6, 9], "a_in": [2, 4, 5, 6, 9], "comput": [2, 4, 5, 6, 9, 10, 16, 17, 18, 21, 23, 25, 26, 27, 28, 30, 33, 34, 36, 39, 40, 44, 45, 48, 49, 50, 51, 52], "arg": [2, 4, 5, 6, 9, 10, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 33, 34, 36, 39, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52], "ndarrai": [2, 4, 5, 6, 9, 10, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 33, 34, 36, 39, 40, 43, 44, 45, 46, 48, 49, 50, 51], "per": [2, 4, 5, 6, 9, 19, 25, 26, 48, 51, 52], "e": [2, 4, 5, 6, 9, 10, 13, 14, 15, 17, 18, 19, 26, 33, 34, 36, 37, 39, 40, 43, 44, 45, 46, 49, 52], "relu": [2, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 51, 52], "return": [2, 4, 5, 6, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 33, 34, 36, 39, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52], "a_out": [2, 4, 5, 6, 9], "my_sequenti": [2, 4, 5, 6, 9], "a2": [2, 4, 5, 6, 9, 51], "w1_tmp": [2, 4, 5, 6, 9], "93": [2, 4, 9, 11, 16, 18, 19], "81": [2, 4, 9, 11, 16, 18, 27, 50], "b1_tmp": [2, 4, 5, 6, 9], "96": [2, 4, 9, 11, 16, 25, 29], "w2_tmp": [2, 4, 5, 6, 9], "59": [2, 4, 9, 11, 16, 18, 19, 29, 33, 34], "56": [2, 4, 6, 8, 9, 11, 16, 18, 19, 28, 30, 33, 34], "b2_tmp": [2, 4, 5, 6, 9], "41": [2, 4, 5, 9, 10, 11, 16, 18, 19, 50, 51], "write": [2, 4, 9, 13, 14, 15, 17, 19, 20, 21, 24, 50, 51], "routin": [2, 4, 9, 11, 16, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 40, 43, 46, 51], "my_predict": [2, 4, 5, 6, 9, 50], "p": [2, 4, 9, 13, 14, 15, 18, 19, 27, 33, 34, 49, 50], "x_tst": [2, 4, 5, 6, 9], "x_tstn": [2, 4, 9], "rememb": [2, 4, 9, 16, 18, 19, 33, 34, 52], "ident": [2, 4, 9, 18, 19, 33, 34, 43, 46, 51], "hopefulli": [2, 4, 9, 11], "reveal": [2, 4, 9, 21], "fairli": [2, 4, 9, 19, 26, 28], "up": [2, 4, 9, 11, 18, 19, 20, 24, 26, 27, 28, 33, 34, 37, 40, 51, 52], "sigmoid": [4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 33, 34, 37, 38, 39, 40, 43, 44, 45, 46], "09": [4, 6, 10, 13, 18, 19, 23, 28, 29, 31, 36, 50], "37": [4, 5, 6, 7, 10, 11, 13, 16, 17, 18, 19, 28, 30, 33, 52], "701075": 4, "40": [4, 5, 10, 11, 16, 19, 27, 28, 31, 50, 53], "040068": 4, "054266": 4, "47": [4, 11, 16, 18, 19, 25, 27, 31, 33, 34, 50], "064825": 4, "871m": 4, "74m": 4, "63m": 4, "61m": 4, "80m": 4, "81m": 4, "73m": 4, "78m": 4, "44m": 4, "47m": 4, "45m": 4, "43": [4, 8, 11, 16, 18, 19, 28, 33, 50], "howerv": 4, "sequential_2": 4, "46": [4, 11, 16, 18, 19, 27, 33, 34, 50], "53": [4, 10, 11, 16, 18, 19, 25, 27, 28, 30, 33, 34, 50], "64": [4, 5, 6, 10, 11, 13, 16, 18, 25, 28, 52], "98": [4, 11, 16, 18, 31], "48": [4, 11, 16, 18, 19, 33, 34, 50], "441m": 4, "58": [4, 6, 11, 13, 16, 18, 33, 50], "exercis": [5, 6, 10, 12, 16, 17, 25, 33, 34, 48, 49, 50, 51, 52], "recogn": [5, 6, 10, 13, 14, 15, 22, 29, 51], "hand": [5, 6, 10, 19, 20, 24, 38], "written": [5, 6, 10, 13, 14, 15, 19, 26, 50], "packag": [5, 6, 10, 14, 15, 16, 17, 25, 26, 33, 34, 49, 51, 52], "problem": [5, 6, 10, 11, 12, 13, 14, 15, 17, 23, 27, 33, 34, 49, 52], "dataset": [5, 6, 10, 11, 13, 14, 15, 17, 18, 27, 31, 33, 34, 48, 49, 50, 51], "model": [5, 6, 10, 12, 13, 14, 15, 22, 23, 27, 28, 29, 30, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 46, 49, 50, 51, 52], "represent": [5, 6, 10, 11, 19, 25, 31, 48], "tensorflow": [5, 6, 7, 9, 10, 11, 12, 16, 50, 51, 52], "forward": [5, 6, 18, 19, 26, 27, 33, 34, 50], "prop": [5, 6], "congratul": [5, 6, 27, 50, 51, 52], "broadcast": [5, 6, 19, 26], "tutori": [5, 6], "need": [5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 29, 33, 34, 48, 49, 51, 52], "fundament": [5, 6, 10, 16, 17, 19, 25, 33, 34, 49], "scientif": [5, 6, 10, 16, 19, 21, 22, 23, 26, 27, 33, 34, 52], "popular": [5, 6, 10, 16, 21, 22, 23, 27, 51], "librari": [5, 6, 10, 14, 15, 16, 17, 19, 21, 22, 23, 25, 26, 27, 33, 34, 36, 49, 52], "layer": [5, 6, 9, 10, 12, 13, 14, 15, 16, 50, 51, 52], "autil": [5, 6, 10, 12], "inlin": [5, 6, 17, 18, 19, 25, 33, 34, 48, 49], "simpl": [5, 6, 7, 11, 16, 19, 20, 21, 22, 24, 28, 29, 35, 38], "logist": [5, 6, 8, 35], "regress": [5, 6, 12, 13, 14, 15, 16, 21, 22, 28, 42], "extend": [5, 6, 10, 12, 19, 26, 27, 35, 43, 46], "linear": [5, 6, 10, 11, 13, 14, 15, 16, 18, 21, 22, 26, 28, 29, 33, 34, 36, 37, 38, 40, 50, 51, 52], "boundari": [5, 6, 11, 16, 29, 33, 34, 39, 40, 44, 45], "polynomi": [5, 6, 16, 18, 19, 33, 34, 37], "even": [5, 6, 29, 48], "scenario": [5, 6, 22, 29], "imag": [5, 6, 10, 23, 48, 52], "prefer": [5, 6, 19, 26, 50, 51], "classif": [5, 6, 10, 13, 14, 15, 16, 18, 33, 34, 36, 38], "task": [5, 6, 10, 17, 18, 19, 25, 33, 34, 36, 38, 48, 49, 52], "autom": [5, 6, 10, 23], "wide": [5, 6, 10, 52], "todai": [5, 6, 10], "zip": [5, 6, 10, 50, 52], "code": [5, 6, 10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 31, 33, 34, 36, 39, 41, 44, 45, 48, 49, 50, 51, 52], "postal": [5, 6, 10], "mail": [5, 6, 10], "envelop": [5, 6, 10], "amount": [5, 6, 10, 16, 18, 19, 29, 33, 34, 43, 46, 52], "bank": [5, 6, 10], "load_data": [5, 6, 10, 18, 19, 25, 33, 34, 48, 49, 51], "function": [5, 6, 7, 10, 11, 12, 16, 17, 23, 26, 27, 28, 30, 31, 33, 34, 37, 40, 41, 48, 49, 50, 51, 52], "limit": [5, 6, 19, 35, 51], "pixel": [5, 6, 10, 48], "grayscal": [5, 6, 10], "float": [5, 6, 10, 17, 18, 19, 22, 23, 25, 27, 33, 34, 40, 49, 50, 51, 52], "indic": [5, 6, 10, 11, 13, 14, 15, 17, 19, 25, 26, 27, 28, 35, 48, 50, 51, 52], "intens": [5, 6, 10, 11, 48], "locat": [5, 6, 10, 16, 19, 21, 35, 40, 48], "grid": [5, 6, 10, 18, 19, 33, 34], "unrol": [5, 6, 10], "400": [5, 6, 10, 16, 27, 28, 29, 50, 52], "dimension": [5, 6, 10, 18, 19, 21, 26, 31, 33, 34, 35, 48, 49, 50], "becom": [5, 6, 10, 16, 19, 20, 22, 24, 29, 49, 52], "give": [5, 6, 10, 17, 18, 19, 21, 22, 25, 33, 34, 37, 48, 50], "u": [5, 6, 10, 18, 19, 22, 29, 33, 34, 48, 51, 52], "everi": [5, 6, 10, 16, 18, 19, 23, 25, 27, 33, 34, 40, 48, 49, 52], "begin": [5, 6, 10, 13, 14, 15, 16, 18, 19, 23, 25, 27, 28, 33, 34, 38, 39, 40, 43, 44, 45, 46, 49, 50, 52], "vdot": [5, 6, 10, 13, 14, 15, 18, 19, 33, 34, 50], "end": [5, 6, 10, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 33, 34, 38, 39, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52], "part": [5, 6, 10, 11, 16, 17, 18, 19, 25, 33, 34, 48, 49, 50], "subset": [5, 6, 10, 17, 19, 26], "mnist": [5, 6, 10], "http": [5, 6, 10, 18, 19, 29, 33, 34, 36, 50, 51], "yann": [5, 6, 10], "lecun": [5, 6, 10], "com": [5, 6, 10, 51], "exdb": [5, 6, 10], "view": [5, 6, 18, 22, 23, 28, 48], "get": [5, 6, 10, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 33, 34, 36, 37, 38, 40, 42, 48, 49, 51, 52], "place": [5, 6, 10, 13, 14, 15, 17, 18, 19, 25, 33, 34, 49], "what": [5, 6, 10, 11, 16, 17, 18, 19, 21, 22, 23, 25, 28, 29, 33, 34, 36, 37, 39, 40, 43, 44, 45, 46, 49, 51], "00000000e": 5, "56059680e": 5, "94035948e": 5, "37438725e": 5, "13403799e": 5, "03": [5, 6, 10, 13, 18, 19, 23, 27, 28, 29, 30, 33, 36, 51, 52], "86104473e": 5, "02": [5, 6, 10, 13, 18, 19, 23, 28, 29, 30, 33, 36], "87412865e": 5, "87572508e": 5, "90963542e": 5, "64039011e": 5, "78191381e": 5, "30347316e": 5, "27655229e": 5, "05": [5, 10, 13, 16, 18, 19, 23, 27, 28, 29, 33, 36, 49], "16421569e": 5, "20052179e": 5, "40444581e": 5, "84542484e": 5, "03826593e": 5, "66540339e": 5, "73853746e": 5, "78729541e": 5, "74293607e": 5, "24676403e": 5, "77562977e": 5, "06315478e": 5, "34715414e": 5, "28335523e": 5, "26286765e": 5, "38651604e": 5, "15651552e": 5, "82800381e": 5, "57849775e": 5, "00109761e": 5, "69710638e": 5, "30928598e": 5, "00383757e": 5, "64157356e": 5, "49256553e": 5, "60408259e": 5, "78319036e": 5, "10620915e": 5, "36410675e": 5, "95509940e": 5, "68537241e": 5, "00755014e": 5, "42031710e": 5, "03136838e": 5, "50968614e": 5, "43122379e": 5, "42599738e": 5, "68918777e": 5, "68374643e": 5, "01256958e": 5, "03795598e": 5, "04481574e": 5, "66424973e": 5, "59875260e": 5, "10606987e": 5, "52456076e": 5, "77539831e": 5, "92890120e": 5, "65626503e": 5, "63166079e": 5, "91720680e": 5, "64100526e": 5, "12180405e": 5, "01900656e": 5, "56102907e": 5, "01762651e": 5, "04748346e": 5, "51055252e": 5, "16044665e": 5, "87012352e": 5, "40931373e": 5, "23305249e": 5, "78203465e": 5, "36720163e": 5, "04320956e": 5, "98003217e": 5, "59409041e": 5, "16751770e": 5, "81021923e": 5, "16566793e": 5, "23773318e": 5, "55477482e": 5, "14867477e": 5, "20401348e": 5, "09173902e": 5, "71058007e": 5, "56250000e": 5, "27724104e": 5, "51466503e": 5, "30532561e": 5, "81664862e": 5, "02836583e": 5, "57137601e": 5, "84667194e": 5, "86865128e": 5, "18688725e": 5, "36492601e": 5, "70751123e": 5, "52644165e": 5, "03180133e": 5, "39028101e": 5, "43742611e": 5, "80290033e": 5, "03635621e": 5, "27262443e": 5, "61706648e": 5, "79865383e": 5, "03676705e": 5, "04490400e": 5, "60586724e": 5, "38173339e": 5, "14879493e": 5, "12622549e": 5, "04248366e": 5, "85907627e": 5, "31712963e": 5, "20680947e": 5, "48136063e": 5, "51383408e": 5, "28404366e": 5, "98971950e": 5, "40410539e": 5, "74520505e": 5, "94389110e": 5, "02844844e": 5, "01648066e": 5, "80488426e": 5, "92123945e": 5, "74122413e": 5, "20098039e": 5, "55215142e": 5, "23907271e": 5, "76068376e": 5, "68645493e": 5, "36411169e": 5, "59006723e": 5, "24701797e": 5, "17356610e": 5, "88929739e": 5, "93511951e": 5, "29999794e": 5, "79821705e": 5, "41862388e": 5, "75147704e": 5, "73632241e": 5, "12778350e": 5, "72353349e": 5, "09937426e": 5, "61793751e": 5, "22872879e": 5, "30812662e": 5, "26501773e": 5, "24441863e": 5, "18971913e": 5, "36563862e": 5, "68349741e": 5, "99079299e": 5, "00293583e": 5, "05704402e": 5, "27299224e": 5, "22099249e": 5, "83053002e": 5, "34069138e": 5, "75151144e": 5, "55674190e": 5, "26512627e": 5, "95366966e": 5, "47114481e": 5, "20048679e": 5, "02798203e": 5, "76572712e": 5, "51415556e": 5, "17339359e": 5, "21948410e": 5, "93210937e": 5, "82013974e": 5, "45758734e": 5, "23874268e": 5, "23341725e": 5, "20020340e": 5, "45324959e": 5, "31859739e": 5, "88831870e": 5, "77765012e": 5, "59136710e": 5, "14869281e": 5, "53186275e": 5, "17353553e": 5, "29167177e": 5, "14402914e": 5, "87038450e": 5, "04583435e": 5, "74885876e": 5, "90037446e": 5, "00769478e": 5, "00851440e": 5, "37905042e": 5, "15455291e": 5, "69624864e": 5, "32506127e": 5, "36366422e": 5, "26031454e": 5, "51994485e": 5, "73889910e": 5, "62121228e": 5, "91134498e": 5, "23055726e": 5, "06260315e": 5, "76070942e": 5, "50581917e": 5, "20939216e": 5, "72618320e": 5, "13151411e": 5, "54641066e": 5, "88214912e": 5, "71077412e": 5, "33524928e": 5, "90964718e": 5, "89176960e": 5, "last": [5, 6, 10, 13, 14, 15, 18, 19, 23, 26, 28, 29, 34, 44, 45, 46, 50, 51, 52], "wai": [5, 6, 10, 11, 13, 14, 15, 17, 18, 19, 20, 24, 25, 26, 27, 28, 29, 33, 34, 36, 40, 48, 49], "pleas": [5, 6, 10, 17, 18, 19, 21, 25, 27, 31, 33, 34, 48, 49, 52], "mani": [5, 6, 10, 11, 16, 17, 18, 19, 23, 25, 26, 27, 28, 30, 31, 33, 34, 40, 49, 50, 51, 52], "str": [5, 6, 10, 18, 19, 33, 34], "select": [5, 6, 10, 11, 13, 14, 15, 17, 19, 20, 22, 24, 27, 28, 42, 48, 50, 51, 52], "map": [5, 6, 10, 11, 12, 21, 25, 29, 33, 34, 36, 37, 52], "displai": [5, 6, 10, 13, 14, 15, 18, 19, 21, 25, 27, 29, 33, 34, 42, 43, 46, 48, 49, 50, 51, 52], "togeth": [5, 6, 10, 12, 19, 26, 48, 51], "simplefilt": [5, 6, 10, 12], "categori": [5, 6, 10, 11, 12, 13, 14, 15, 16], "futurewarn": [5, 6, 10], "do": [5, 6, 10, 11, 16, 17, 18, 19, 22, 25, 26, 28, 29, 33, 34, 48, 49, 50, 51, 52, 53], "modifi": [5, 6, 10, 12, 17, 18, 19, 23, 25, 27, 28, 29, 33, 34, 40, 48, 49, 52, 53], "anyth": [5, 6, 10, 17, 18, 19, 25, 33, 34, 48], "tight_layout": [5, 6, 10, 18, 19, 28, 35], "pad": [5, 6, 10, 52], "enumer": [5, 6, 10], "flat": [5, 6, 10], "random_index": [5, 6, 10], "randint": [5, 6, 10], "x_random_reshap": [5, 6, 10], "t": [5, 6, 10, 11, 12, 18, 19, 23, 25, 27, 28, 33, 34, 40, 43, 46, 50, 51, 52], "imshow": [5, 6, 10, 48], "cmap": [5, 6, 10, 19], "grai": [5, 6, 10], "set_axis_off": [5, 6, 10, 48], "figur": [5, 6, 10, 17, 18, 19, 25, 28, 33, 34, 48, 49, 51], "activ": [5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 51, 52], "sinc": [5, 6, 10, 11, 12, 17, 18, 19, 21, 22, 25, 33, 34, 36, 49, 50, 51, 52], "times20": [5, 6, 10], "If": [5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 25, 28, 29, 33, 34, 48, 49, 50, 51, 52], "s_": [5, 6, 10, 52], "therefor": [5, 6, 10, 17, 18, 19, 25, 33, 34, 37, 48, 50], "layer3": [5, 6, 10], "b3": [5, 6, 10, 51], "maintain": [5, 6, 10], "convent": [5, 6, 10, 13, 14, 15, 23], "deriv": [5, 6, 10, 12, 19, 20, 23, 24, 28, 38, 50, 51], "statment": [5, 6], "also": [5, 6, 10, 11, 12, 13, 14, 15, 18, 19, 21, 23, 25, 26, 28, 33, 34, 36, 37, 48, 49, 50, 51, 52], "add": [5, 6, 10, 13, 14, 15, 17, 18, 19, 25, 26, 29, 33, 34, 35, 36, 40, 42, 43, 46, 50], "illumin": [5, 6, 10, 19, 38], "unq_c1": [5, 6, 10, 16, 17, 18, 19, 25, 33, 34, 48, 49, 50, 51, 52], "grade": [5, 6, 10, 16, 17, 18, 19, 20, 24, 25, 33, 34, 48, 49, 50, 52], "my_model": [5, 6, 10], "10025": [5, 6, 10], "dense_1": [5, 6, 16], "390": [5, 6, 10, 16], "dense_2": [5, 6, 16], "431": [5, 6, 16], "click": [5, 6, 10, 12, 16, 17, 18, 19, 20, 21, 22, 24, 25, 28, 33, 34, 35, 36, 40, 42, 48, 49, 50, 51, 52], "becaus": [5, 6, 13, 14, 15, 18, 19, 22, 26, 33, 34, 51, 52], "weight": [5, 6, 7, 9, 10, 11, 12, 17, 21, 27, 28, 29, 30, 50, 52], "auto": [5, 6, 10], "gener": [5, 6, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 26, 27, 28, 29, 31, 33, 34, 36, 40, 42, 50, 51, 52], "hint": [5, 6, 10, 12, 16, 17, 18, 19, 21, 25, 33, 34, 48, 49, 50, 51, 52], "public_test": [5, 6, 10, 17, 18, 19, 25, 33, 34, 48, 49, 50, 51, 52], "test_c1": [5, 6], "pass": [5, 10, 11, 16, 17, 18, 19, 25, 28, 33, 34, 48, 49, 50, 51, 52], "l3_num_param": [5, 6], "l3": [5, 6, 10, 16], "further": [5, 6, 10, 11, 16, 19, 23, 26, 35, 36, 37, 42, 50, 51], "verifi": [5, 6, 10, 18, 19, 25, 33, 34, 50], "One": [5, 6, 10, 11, 13, 14, 15, 17, 18, 19, 21, 26, 29, 33, 34, 35, 38, 48, 49, 50], "access": [5, 6, 19, 21, 26], "directli": [5, 6, 19, 26, 27, 50, 52], "39": [5, 6, 10, 11, 14, 15, 16, 17, 18, 19, 25, 26, 27, 31, 33, 34, 36, 44, 45, 46, 50], "kernel": 5, "08530456": 5, "2747036": 5, "08510572": 5, "12527409": 5, "2926382": 5, "34840912": 5, "21684825": 5, "08979291": 5, "5360281": 5, "19300771": 5, "44613487": 5, "1397686": 5, "42860353": 5, "5345983": 5, "22546476": 5, "explain": [5, 6, 19, 26], "001": [5, 6, 10, 13, 14, 15, 16, 18, 19, 33, 34], "epoch": [5, 6, 11, 13, 14, 15, 16, 51], "1m": [5, 10, 11, 13, 16], "6348": 5, "4996": [5, 16], "2m": [5, 10, 11, 16, 18, 19, 22, 23, 25, 27, 33, 34, 38, 43, 46], "3573": [5, 16], "2490": [5, 16], "1787": [5, 16], "1338": 5, "1047": [5, 16, 51], "0848": [5, 16], "0708": 5, "0600": 5, "0520": [5, 16], "0456": [5, 16], "0405": [5, 16], "0365": [5, 16], "0332": [5, 13, 16], "0304": 5, "0280": [5, 16], "0260": [5, 16], "0243": [5, 16], "0228": [5, 16], "0x7f2d2b00a650": 5, "www": [5, 6], "org": [5, 6, 18, 19, 26, 29, 31, 33, 34, 36, 50, 51], "api_doc": [5, 6], "__": [5, 6, 18, 19, 26, 27, 29, 33, 34, 36], "01574531": 5, "98137283": 5, "interpret": [5, 6, 10, 13, 14, 15, 18, 19, 33, 34, 37, 51], "nearli": [5, 6, 19, 23, 31, 38, 43, 46], "v": [5, 6, 10, 16, 18, 19, 23, 25, 26, 27, 28, 30, 36, 37, 38, 49, 50], "sampl": [5, 6, 10, 17, 23, 48, 51, 52], "rect": [5, 6, 10, 28], "bottom": [5, 6, 10, 18, 19, 23], "top": [5, 6, 10, 12, 48, 50, 51, 52], "suptitl": [5, 6, 10, 16, 28, 30], "unq_c2": [5, 6, 10, 16, 17, 18, 19, 25, 33, 34, 48, 49, 51, 52], "quick": [5, 6, 27], "arang": [5, 6, 18, 19, 23, 26, 27, 29, 36, 37, 39, 44, 45, 49], "w_tst": [5, 6], "b_tst": [5, 6], "a_tst": [5, 6], "54735762": [5, 6], "57932425": [5, 6], "61063923": [5, 6], "column": [5, 6, 16, 19, 26, 27, 28, 29, 30, 36, 48, 49, 50, 51], "test_c2": [5, 6], "a3": [5, 6, 13, 14, 15, 51], "w3_tmp": [5, 6], "b3_tmp": [5, 6], "both": [5, 6, 12, 13, 14, 15, 16, 18, 20, 22, 23, 24, 25, 26, 28, 30, 33, 34, 35, 36, 38, 39, 42, 44, 45, 49, 50, 51, 52], "my_yhat": [5, 6], "tf_predict": [5, 6], "tf_yhat": [5, 6], "speed": [5, 6, 16, 19, 26, 27, 28, 29, 42, 50], "given": [5, 6, 11, 13, 14, 15, 17, 18, 19, 22, 26, 27, 28, 29, 33, 34, 35, 36, 37, 48, 49, 50, 51, 52], "matmul": [5, 6, 50], "multipli": [5, 6, 19, 26, 27, 28, 40], "compat": [5, 6, 50], "diagram": [5, 6, 16, 23, 50], "z1": [5, 6], "full": [5, 6, 50, 51, 52], "xw": [5, 6], "unfamiliar": [5, 6], "compos": [5, 6, 12, 16, 51], "new": [5, 6, 10, 11, 12, 16, 18, 19, 25, 28, 29, 33, 34, 38, 40, 48, 49, 50, 51, 52], "my_dense_v": [5, 6], "unq_c3": [5, 6, 16, 17, 18, 19, 33, 34], "57199613": [5, 6], "61301418": [5, 6], "65248946": [5, 6], "5962827": [5, 6], "64565631": [5, 6], "6921095": [5, 6], "62010643": [5, 6], "67699586": [5, 6], "72908792": [5, 6], "float64": [5, 16, 25, 26, 50, 52], "plu": [5, 6, 50], "test_c3": [5, 6], "my_sequential_v": [5, 6], "again": [5, 6, 10, 11, 12, 16, 23, 28, 29, 51, 52], "tensorshap": 5, "befor": [5, 6, 16, 18, 19, 22, 23, 25, 28, 33, 34, 40, 41, 42, 49, 50], "just": [5, 6, 12, 17, 18, 19, 21, 25, 26, 28, 33, 34, 40, 48, 49, 50, 52], "misclassifi": [5, 6, 16], "titl": [5, 6, 18, 19, 21, 25, 29, 39, 44, 45, 49, 50, 51], "off": [5, 6, 10, 12, 28, 48], "successfulli": [5, 6, 10, 11, 22, 52], "j_1": [5, 6], "j_2": [5, 6], "wise": [5, 6, 13, 14, 15, 19, 26, 28, 51], "sens": [5, 6, 19, 37], "expans": [5, 6], "Its": [5, 6, 19, 20, 24, 26, 52], "basic": [5, 6, 16, 19, 20, 24, 26, 43, 46], "stretch": [5, 6], "smaller": [5, 6, 19, 23, 25, 28, 31, 42], "replic": [5, 6, 51], "specif": [5, 6, 16, 48, 52], "trail": [5, 6], "rightmost": [5, 6], "equal": [5, 6, 16, 28, 50, 52], "condit": [5, 6, 17, 52], "met": [5, 6, 17, 52], "valueerror": [5, 6, 18], "operand": [5, 6, 19, 26, 34], "except": [5, 6, 14, 15, 19, 26], "thrown": [5, 6], "incompat": [5, 6], "along": [5, 6, 17, 29, 51], "graphic": [5, 6, 19, 20, 24, 28, 29, 37], "text": [5, 6, 10, 12, 13, 14, 15, 16, 17, 18, 19, 23, 25, 27, 28, 33, 34, 38, 40, 43, 46, 50, 52], "notion": [5, 6, 27], "argument": [5, 6, 11, 13, 14, 15, 18, 19, 21, 26], "actual": [5, 6, 18, 19, 21, 23, 25, 29, 33, 34], "mechan": [5, 6], "guess": [5, 6, 48], "na": [5, 6, 19, 26], "958652": 6, "466353": 6, "467621": 6, "212660": 6, "nameerror": [6, 14, 15, 18, 34, 44, 45, 46], "traceback": [6, 14, 15, 18, 34, 44, 45, 46], "recent": [6, 14, 15, 18, 34, 44, 45, 46], "call": [6, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 30, 31, 33, 34, 36, 41, 44, 45, 46, 48, 50, 52], "modulenotfounderror": [6, 34, 44, 45, 46], "No": [6, 13, 14, 15, 17, 18, 19, 34, 44, 45, 46], "enough": [6, 52], "unpack": [6, 52], "got": [6, 18, 19, 33, 34], "indexerror": 6, "100x100": 6, "88": [8, 11, 16, 18, 50], "neuron": 9, "softmax": [10, 11, 16], "placement": 10, "widget": [10, 11, 12, 13, 14, 15, 16, 18, 19, 22, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46], "lab_utils_softmax": [10, 13, 14, 15], "plt_softmax": [10, 13, 14, 15], "set_printopt": [10, 11, 18, 19, 27, 28, 29, 30, 31, 36, 43, 46], "precis": [10, 11, 18, 19, 27, 28, 29, 30, 31, 36, 43, 46, 49, 51], "rectifi": [10, 12], "quad": [10, 12, 18, 19, 33, 34, 40, 48, 50], "plt_act_trio": [10, 12], "applic": [10, 12, 18, 19, 21, 27, 28, 33, 34, 50], "awar": [10, 12], "continu": [10, 12, 17, 19, 29, 36, 38, 52], "situat": [10, 12, 19, 28, 42], "relationship": [10, 12, 19, 21, 25, 28], "addition": [10, 12, 51], "why": [10, 16, 19, 26, 28], "contribut": [10, 12, 13, 14, 15, 22], "without": [10, 11, 18, 19, 21, 28, 33, 34, 43, 46, 48, 50, 51, 52], "interf": [10, 12], "support": [10, 27, 52], "answer": [10, 16], "fed": 10, "distribut": [10, 13, 14, 15, 16, 28, 49], "a_j": [10, 13, 14, 15], "frac": [10, 13, 14, 15, 16, 18, 19, 22, 23, 25, 27, 28, 33, 34, 36, 37, 38, 39, 40, 43, 44, 45, 46, 48, 49, 50], "z_j": [10, 13, 14, 15], "sum_": [10, 13, 14, 15, 16, 18, 19, 26, 28, 33, 34, 39, 43, 44, 45, 46, 48, 49, 50, 51], "k": [10, 13, 14, 15, 50, 51], "z_k": [10, 13, 14, 15], "my_softmax": [10, 13, 14, 15], "ez": [10, 13, 14, 15], "exp": [10, 13, 14, 15, 18, 19, 33, 34, 36, 49], "atf": 10, "nn": [10, 13, 14, 15, 16], "test_my_softmax": 10, "denomin": 10, "ez_sum": 10, "share": [10, 28], "Or": [10, 50], "exponenti": [10, 13, 14, 15, 18, 19, 33, 34, 36], "magnifi": [10, 13, 14, 15], "close": [10, 13, 14, 15, 16, 18, 19, 22, 28, 29, 30, 31, 33, 34, 35, 36, 38, 42, 43, 46, 50, 52], "ten": [10, 51], "choic": [10, 16, 19, 25, 50], "5000": [10, 16, 18, 19, 23, 29, 33, 34, 40, 51], "91": [10, 11, 16, 52], "widgvi": 10, "group": [10, 16, 48], "rather": [10, 11, 12, 19, 23, 27, 28, 38, 49], "than": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 23, 25, 26, 27, 28, 29, 33, 34, 38, 39, 44, 45, 49, 50, 51, 52], "implic": 10, "effect": [10, 48], "from_logit": [10, 11, 13, 14, 15, 16], "true": [10, 11, 13, 14, 15, 16, 19, 23, 27, 28, 29, 30, 35, 36, 43, 46, 48, 49, 51, 52], "sparsecategoricalcrossentropi": [10, 11, 13, 14, 15, 16], "doe": [10, 12, 16, 19, 21, 22, 26, 28, 31, 35, 36, 38, 42, 43, 46, 50, 51, 52], "impact": [10, 16, 23, 28, 29], "target": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 27, 28, 29, 30, 31, 33, 34, 38, 39, 40, 43, 44, 45, 46, 51, 52], "sparsecategorialcrossentropi": 10, "desir": [10, 12, 13, 14, 15, 21], "inputlay": [10, 51], "160": [10, 11, 16, 50], "575": [10, 16], "unless": 10, "replac": [10, 16, 48], "test_model": 10, "157": [10, 11, 16], "7094": 10, "7480": 10, "4428": [10, 16], "3463": [10, 16], "2977": 10, "2630": 10, "2361": [10, 16], "2131": [10, 16], "2004": [10, 50, 51], "1805": [10, 16], "1692": [10, 16], "1580": [10, 16], "1507": [10, 16], "1396": [10, 11], "1289": 10, "1255": [10, 16], "1154": [10, 51], "1102": 10, "1016": 10, "0970": [10, 16], "0926": 10, "0891": 10, "0828": [10, 16], "0785": 10, "0755": [10, 16], "0713": [10, 16], "0701": [10, 16], "0617": 10, "0578": 10, "0550": 10, "0511": 10, "0499": 10, "0462": 10, "0437": 10, "0422": [10, 16], "0396": 10, "0366": [10, 11], "0344": 10, "0312": [10, 16], "0294": [10, 16], "2770": 10, "roughli": [10, 16, 28], "track": [10, 19, 25, 50, 52], "monitor": [10, 19, 25], "ideal": [10, 16, 19, 42, 48], "decreas": [10, 16, 18, 19, 23, 25, 28, 33, 34, 40, 52], "iter": [10, 13, 14, 15, 16, 17, 18, 19, 25, 27, 28, 29, 30, 33, 34, 40, 43, 46, 48, 50, 52], "algorithm": [10, 16, 17, 18, 19, 23, 25, 28, 30, 31, 33, 34, 39, 40, 43, 44, 45, 46, 48, 49, 50, 52], "saw": [10, 17], "varieti": [10, 16, 29, 52], "metric": [10, 16], "captur": [10, 16, 19, 26, 49], "plot_loss_tf": 10, "1015": [10, 16], "image_of_two": 10, "display_digit": 10, "largest": [10, 13, 14, 15], "argmax": [10, 13, 14, 15, 16], "77": [10, 11, 16, 18, 19, 25, 27, 50, 52], "requir": [10, 12, 13, 14, 15, 19, 20, 24, 26, 29, 31, 38, 48], "suffici": [10, 11], "prediction_p": 10, "3f": [10, 16, 18, 19, 25, 33, 34, 50, 52], "42e": [10, 18, 19, 28], "49e": [10, 18], "98e": [10, 18], "76e": [10, 18, 19], "61e": [10, 18, 19], "97e": [10, 13, 18], "44e": [10, 18], "22e": [10, 18, 27], "000": [10, 18, 19, 21, 22, 23, 25, 31, 33, 34, 52], "integ": [10, 13, 14, 15, 48], "want": [10, 18, 19, 25, 28, 33, 34, 39, 44, 45, 48, 49, 52], "elimin": [10, 19, 29, 38], "display_error": 10, "store": [11, 18, 19, 21, 23, 25, 26, 27, 28, 33, 34, 40, 48, 50, 52], "lab_utils_multiclass_tf": 11, "py": [11, 14, 15, 17, 18, 19, 22, 23, 25, 29, 33, 34, 49], "directori": [11, 14, 15, 22, 23], "sklearn": [11, 13, 14, 15, 16, 19, 28, 30, 31, 41, 51], "make_blob": [11, 13, 14, 15], "classifi": [11, 17, 18, 19, 33, 34, 37, 49], "photo": [11, 48], "subject": 11, "dog": [11, 51], "cat": [11, 51], "hors": 11, "sentenc": 11, "speech": 11, "noun": 11, "verb": 11, "adject": 11, "etc": 11, "associ": [11, 13, 14, 15, 19, 25, 27, 29, 30, 31], "highest": [11, 16, 17, 49], "multiclass": [11, 13, 14, 15], "four": [11, 19, 26, 27, 52], "scikit": [11, 16, 51], "center": [11, 13, 14, 15, 16, 28, 52], "std": [11, 16, 28], "n_sampl": [11, 13, 14, 15, 17], "cluster_std": [11, 13, 14, 15], "random_st": [11, 13, 14, 15, 16, 51], "plt_mc": 11, "x0": [11, 19, 37, 39, 40, 44, 45], "x1": [11, 19, 37, 39, 40, 44, 45], "color": [11, 16, 17, 18, 19, 21, 28, 30, 48], "present": [11, 17, 18, 19, 25, 33, 34, 48, 49, 51], "real": [11, 16, 19, 25], "world": [11, 16], "sever": [11, 16, 27, 28, 49, 51, 52], "correct": [11, 17, 18, 19, 25, 29, 33, 34, 36, 49], "uniqu": 11, "unlik": [11, 13, 14, 15, 19, 27, 36], "notic": [11, 13, 14, 15, 19, 26, 28, 29, 43, 46, 48, 52], "stabl": [11, 13, 14, 15, 18, 19, 29, 33, 34, 36], "8158": 11, "6976": 11, "5989": 11, "961u": 11, "5179": [11, 16], "4369": [11, 16], "3756": [11, 16], "3154": [11, 16], "2621": 11, "991u": 11, "2188": [11, 16], "983u": 11, "1791": [11, 16], "974u": [11, 13], "1446": 11, "984u": 11, "1129": [11, 16], "993u": 11, "0827": 11, "0516": [11, 16], "0225": [11, 16], "9967": 11, "970u": 11, "9681": 11, "980u": 11, "9392": 11, "989u": 11, "9092": 11, "966u": [11, 13], "8771": 11, "995u": 11, "8461": 11, "8099": 11, "988u": 11, "7771": 11, "7485": 11, "7215": 11, "6967": 11, "6742": 11, "6540": 11, "6352": 11, "6187": 11, "6030": [11, 16], "5884": 11, "5746": [11, 16], "997u": 11, "5621": [11, 16], "5512": 11, "999u": 11, "5414": 11, "5323": 11, "5236": [11, 16], "5150": [11, 16], "5072": 11, "5006": 11, "982u": 11, "4944": 11, "992u": 11, "4888": [11, 16], "4830": 11, "4775": [11, 16], "4725": [11, 16], "998u": 11, "4673": [11, 16], "4624": 11, "987u": 11, "4574": [11, 16], "4530": [11, 16], "4491": 11, "4451": [11, 16], "4414": [11, 16], "986u": 11, "4374": [11, 16], "55": [11, 16, 18, 50, 51], "4336": [11, 16], "4295": [11, 16], "57": [11, 16, 18, 25, 33], "965u": 11, "4261": [11, 16], "4225": 11, "4193": 11, "60": [11, 16, 18, 19, 33, 50, 52], "4161": [11, 16], "61": [11, 16, 18, 19, 25, 30, 50, 51], "4131": [11, 16], "62": [11, 16, 18, 19, 28, 31, 51], "4098": [11, 16], "63": [11, 13, 16, 18], "4067": [11, 16], "4029": [11, 16], "65": [11, 16, 18, 19, 25, 28, 48, 51], "3994": [11, 16], "3957": [11, 16], "67": [11, 16, 18, 31, 50], "3920": 11, "68": [11, 16, 18, 19], "3878": [11, 16], "3837": [11, 16], "3792": [11, 16], "3755": [11, 16], "72": [11, 13, 16, 18, 19, 33, 34, 36], "3718": [11, 16], "73": [11, 16, 18, 27], "971u": 11, "3683": 11, "74": [11, 13, 16, 18, 25], "3643": [11, 16], "3600": [11, 16], "3550": [11, 16], "3491": [11, 16], "78": [11, 16, 18, 19, 28, 29, 33], "3425": [11, 16], "954u": 11, "3367": [11, 16], "930u": [11, 16], "3293": [11, 16], "3228": [11, 16], "3156": [11, 16], "83": [11, 16, 18, 51], "3080": [11, 16], "84": [11, 16, 18, 50], "3006": [11, 16], "2933": [11, 16], "2864": [11, 16], "2792": [11, 16], "2720": 11, "2645": [11, 16], "90": [11, 16, 50], "2570": [11, 16], "958u": [11, 16], "2498": [11, 16], "996u": 11, "2432": [11, 16], "2354": [11, 16], "2274": [11, 16], "2194": [11, 16], "2127": [11, 16], "97": [11, 16, 18, 19, 25, 28, 30], "2060": [11, 16], "969u": 11, "1995": 11, "1950": [11, 16], "1894": [11, 16], "101": [11, 16, 19, 25], "1850": [11, 16], "102": [11, 16, 50], "1804": [11, 16], "103": [11, 16], "1758": [11, 16], "104": [11, 16], "956u": 11, "1709": [11, 16], "105": [11, 16], "977u": 11, "1662": [11, 16], "106": [11, 16, 52], "1616": [11, 16], "107": [11, 16, 50], "952u": 11, "1575": [11, 16], "108": [11, 16], "1527": 11, "109": [11, 16], "1480": [11, 16], "110": [11, 16, 18, 28, 30, 50], "1439": 11, "111": [11, 16, 18], "112": [11, 16], "1357": [11, 16], "113": [11, 16], "1315": 11, "114": [11, 16], "1277": 11, "115": [11, 16], "994u": 11, "1240": 11, "116": [11, 16], "1207": 11, "117": [11, 16, 49], "1171": 11, "118": [11, 16, 18, 19, 33], "1139": 11, "119": [11, 16], "1110": [11, 51], "120": [11, 16, 23, 50], "1084": 11, "121": [11, 16, 18, 19], "1058": 11, "122": [11, 16, 19], "1029": [11, 16], "123": [11, 16, 29], "1001": 11, "124": [11, 16], "0975": 11, "125": [11, 16, 50], "0951": [11, 16], "126": [11, 14, 15, 16], "0925": 11, "127": [11, 14, 15, 16], "0902": 11, "128": [11, 14, 15, 16, 48, 51], "0882": 11, "129": [11, 14, 15, 16], "0862": 11, "130": [11, 14, 15, 16], "0840": 11, "131": [11, 14, 15, 16], "0826": 11, "132": [11, 14, 15, 16, 50], "0807": 11, "133": [11, 14, 15, 16, 50], "0790": 11, "134": [11, 14, 15, 16, 30], "0772": [11, 16], "135": [11, 14, 15, 16], "0757": 11, "136": [11, 14, 15, 16], "0741": [11, 16], "137": [11, 16], "0728": 11, "138": [11, 16], "0714": [11, 16], "139": [11, 16], "0700": [11, 16], "140": [11, 16, 50, 52], "0685": 11, "141": [11, 16, 50], "0670": [11, 16], "142": [11, 16], "0657": 11, "143": [11, 16], "0645": 11, "144": [11, 16], "0634": 11, "145": [11, 16, 18], "0622": 11, "146": [11, 16], "0611": 11, "147": [11, 16], "0601": 11, "148": [11, 16], "0591": [11, 16], "149": [11, 16, 50], "0582": 11, "150": [11, 16, 25, 52], "0575": [11, 16], "0570": 11, "152": [11, 16], "0563": [11, 16], "153": [11, 16], "0553": [11, 16], "154": [11, 16], "0541": [11, 16], "155": [11, 16], "0530": 11, "156": [11, 16], "0519": [11, 16], "0510": [11, 16], "158": [11, 16], "0502": 11, "159": [11, 16, 50, 52], "0496": [11, 16], "0490": [11, 16, 29], "161": [11, 16], "0481": 11, "162": [11, 16], "0473": 11, "163": [11, 16], "0466": [11, 16], "164": [11, 16], "0458": 11, "165": [11, 16], "0452": 11, "166": [11, 16], "0445": 11, "167": [11, 16], "0440": [11, 16], "168": [11, 16], "0434": 11, "169": [11, 16], "0429": [11, 16], "170": [11, 16, 50], "0423": 11, "171": [11, 16, 27], "0418": 11, "172": [11, 16], "0414": [11, 16], "173": [11, 16], "0413": 11, "174": [11, 16], "0408": [11, 16], "0401": 11, "176": [11, 16], "0393": 11, "177": [11, 16], "0388": [11, 16], "178": [11, 16, 27], "0384": [11, 16], "179": [11, 16], "979u": [11, 16], "180": [11, 16, 23, 50], "0377": 11, "181": [11, 16], "0369": [11, 16], "183": [11, 16], "962u": 11, "0363": [11, 16], "184": [11, 16], "0359": 11, "185": [11, 16, 50], "975u": [11, 16], "0353": [11, 16], "186": [11, 16], "981u": 11, "0348": [11, 16], "187": [11, 16], "0345": 11, "188": [11, 16, 50], "0343": [11, 16], "189": [11, 16], "0339": 11, "190": [11, 16], "973u": 11, "0337": [11, 16], "191": [11, 16], "990u": 11, "0333": [11, 16], "192": [11, 16], "0330": 11, "193": [11, 16], "0325": [11, 16], "194": [11, 16, 52], "0321": [11, 16], "195": [11, 16], "0317": [11, 16], "196": [11, 16], "0314": 11, "197": [11, 16], "0310": [11, 16], "198": [11, 16], "0306": 11, "199": [11, 16, 23], "0303": [11, 16], "0300": [11, 16], "0x7fd95c610950": 11, "With": [11, 18, 19, 23, 25, 27, 28, 29, 33, 34, 40, 52], "plt_cat_mc": 11, "partit": 11, "space": [11, 18, 19, 33, 34, 36, 48, 52], "had": [11, 19, 28, 29, 38, 39, 44, 45, 51], "troubl": [11, 12], "did": [11, 16, 17, 18, 19, 25, 33, 34, 50], "pull": [11, 50], "down": [11, 19, 20, 24, 51, 52], "don": [11, 12, 18, 19, 25, 28, 33, 34, 50], "help": [11, 17, 18, 19, 20, 24, 25, 33, 34, 48, 49, 51, 52], "gain": [11, 17, 48], "intuit": [11, 19, 21, 42, 43, 46, 48], "about": [11, 19, 29, 42, 48, 51, 52], "solv": [11, 13, 14, 15, 27, 52], "gather": 11, "plt_layer_relu": 11, "transform": [11, 14, 15, 18, 19, 28, 33, 34, 48, 51], "xl2": 11, "plt_output_layer_linear": 11, "x0_rng": 11, "amax": 11, "x1_rng": 11, "x_0": [11, 18, 19, 26, 29, 35, 37, 39, 40, 44, 45], "x_1": [11, 18, 19, 33, 34, 35, 37, 39, 40, 44, 45], "background": 11, "bar": 11, "necessarili": 11, "fall": [11, 16, 22, 50], "greater": [11, 19, 25, 52], "peak": [11, 28, 29, 30], "contour": [11, 18, 19, 22, 23, 28, 33, 34, 40, 49], "transit": [11, 12], "_j": [11, 13, 14, 15, 27, 28], "inflect": 11, "separ": [11, 13, 14, 15, 16, 18, 19, 26, 27, 33, 34, 38, 48, 51, 52], "translat": [11, 18, 19, 25, 33, 34], "think": [11, 19, 25, 29], "evalu": [11, 16, 21, 25, 27, 28, 33, 34, 49, 50, 51], "_0": [11, 18, 19, 27, 33, 34], "_1": [11, 12, 27], "green": [11, 21, 48], "orang": [11, 16, 19, 28, 36, 40], "upper": [11, 16, 18, 19, 33, 34, 39, 40, 44, 45], "corner": 11, "lower": [11, 19, 26, 49], "resid": 11, "purpl": 11, "aspect": [11, 16], "obviou": [11, 29], "coordin": [11, 52], "done": [11, 16, 51, 52], "impli": [11, 29], "across": 11, "happen": [11, 23, 28], "under": [11, 16, 19, 37], "hood": 11, "gridspec": 12, "leakyrelu": 12, "slider": [12, 13, 14, 15, 22], "lab_utils_relu": 12, "userwarn": 12, "piec": [12, 19, 38], "piecewis": 12, "slope": [12, 19, 23, 25, 38], "portion": [12, 22], "abruptli": 12, "At": [12, 19, 25, 28, 48, 52], "exist": [12, 17, 50], "prior": [12, 19, 40], "disabl": 12, "sometim": 12, "tangibl": 12, "program": [12, 19, 26], "fix": [12, 23, 28], "segment": 12, "3rd": [12, 19, 26], "leav": [12, 28], "until": [12, 17, 18, 19, 23, 25, 27, 28, 33, 34, 40, 43, 46, 50, 52], "slide": [12, 19, 23, 38, 43, 46], "quicker": 12, "worri": 12, "_": [12, 16, 18, 19, 25, 27, 28, 33, 34, 40, 50, 51, 52], "plt_relu_ex": 12, "goal": [12, 16, 18, 25, 26, 27, 33, 34, 50, 52], "appreci": 12, "behavior": [12, 19, 38, 49], "turn": [12, 16, 17], "mark": 12, "cut": 12, "interv": [12, 18, 19, 23, 25, 27, 33, 34, 40], "prevent": [12, 18, 19, 23, 25, 27, 33, 34, 40, 52], "quiet": 12, "adjust": [12, 19, 21, 25, 27, 28, 29, 52], "keep": [12, 17, 19, 25, 52], "reach": [12, 17, 22, 28, 52], "_2": [12, 17], "stitch": 12, "ipython": [13, 14, 15], "markdown": [13, 14, 15, 19, 20, 24], "latex": [13, 14, 15], "lead": [13, 14, 15, 19, 23, 38, 52], "cleaner": [13, 14, 15], "succinct": [13, 14, 15], "thu": [13, 14, 15, 49], "break": [13, 14, 15, 52], "length": [13, 14, 15, 21], "align": [13, 14, 15, 18, 19, 23, 25, 26, 27, 28, 33, 34, 38, 39, 40, 43, 44, 45, 46, 49], "bmatrix": [13, 14, 15, 50], "z_1": [13, 14, 15], "z_": [13, 14, 15, 18, 19, 33, 34], "exponeni": [13, 14, 15], "sm": [13, 14, 15], "few": [13, 14, 15, 16, 17, 18, 19, 22, 23, 28, 33, 34, 48, 50], "span": [13, 14, 15], "z0": [13, 14, 15], "a0": [13, 14, 15], "cross": [13, 14, 15, 16, 19, 21, 28, 37, 39, 40, 44, 45, 49], "entropi": [13, 14, 15, 17], "nbsphinx": [13, 14, 15, 19, 27, 29, 38, 43, 46], "math": [13, 14, 15, 18, 19, 23, 25, 26, 27, 29, 33, 34, 38, 40, 43, 46, 51, 52], "l": [13, 14, 15, 51, 52], "a_1": [13, 14, 15], "a_n": [13, 14, 15], "otherwis": [13, 14, 15, 16, 17, 18, 19, 33, 34, 49, 50, 52], "_k": [13, 14, 15, 50], "averag": [13, 14, 15, 16, 19, 25, 28, 50, 51, 52], "former": [13, 14, 15, 28], "straightforward": [13, 14, 15, 48], "latter": [13, 14, 15, 28, 52], "2000": [13, 14, 15, 16, 18, 19, 21, 22, 23, 29, 31, 33, 34, 40, 50, 51, 52], "direct": [13, 14, 15, 23, 27, 50, 53], "8312": 13, "3203": [13, 16], "1408": 13, "0847": [13, 16], "944u": [13, 16], "0626": 13, "0515": 13, "0447": [13, 16], "0402": 13, "922u": 13, "0361": 13, "0x7fd399415490": 13, "p_nonpref": [13, 14, 15], "smallest": [13, 14, 15, 19, 25], "39e": [13, 18, 19], "02e": [13, 18], "73e": [13, 18, 27], "30e": [13, 18], "46e": [13, 18], "35e": [13, 18, 19], "9999994": 13, "1378247e": 13, "accur": [13, 14, 15, 22, 27, 28], "obtain": [13, 14, 15, 48, 51], "histor": [13, 14, 15, 18, 19, 33, 34], "reason": [13, 14, 15, 16, 19, 38, 52], "logit": [13, 14, 15], "addit": [13, 14, 15, 16, 19, 26, 50, 51, 52], "inform": [13, 14, 15, 17, 19, 20, 24, 50, 51, 52], "preferred_model": [13, 14, 15], "0936": [13, 16], "4933": [13, 16], "2809": 13, "1506": [13, 16], "0916": 13, "0694": 13, "0592": 13, "0527": 13, "919u": [13, 16], "0489": 13, "0457": [13, 16], "0x7fd23c552050": 13, "posit": [13, 14, 15, 18, 19, 23, 25, 26, 28, 33, 34, 35, 36, 48, 49, 52], "sent": [13, 14, 15], "p_prefer": [13, 14, 15], "410254": 13, "030992": 13, "sm_prefer": [13, 14, 15], "55e": [13, 18], "34e": [13, 18], "82e": [13, 18, 19, 23], "38e": [13, 18, 19, 28, 49], "94e": [13, 18], "05e": [13, 18], "92e": [13, 18, 27], "9999995": 13, "5196424e": 13, "potenti": [13, 14, 15, 19, 25, 29, 36, 52], "format": [13, 14, 15, 17, 18, 19, 20, 21, 24, 26, 33, 34, 36, 51, 52], "hot": [13, 14, 15, 16, 17, 50, 51], "encod": [13, 14, 15, 16, 17, 48], "becam": [13, 14, 15], "filenotfounderror": [14, 15], "file": [14, 15, 16, 17, 18, 19, 22, 23, 25, 29, 33, 34, 49, 50, 52], "usr": [14, 15], "lib": [14, 15], "python3": [14, 15], "dist": [14, 15, 51], "rc": [14, 15], "rc_params_from_fil": [14, 15], "use_default_templ": [14, 15], "fals": [14, 15, 19, 35, 42, 48, 49, 50, 51, 52], "_apply_styl": [14, 15], "__init__": [14, 15], "856": [14, 15, 16], "fname": [14, 15], "fail_on_error": [14, 15], "842": [14, 15, 16], "843": [14, 15, 16], "rcparam": [14, 15], "844": [14, 15, 16], "854": [14, 15, 16, 25], "updat": [14, 15, 17, 18, 19, 22, 23, 25, 27, 28, 30, 33, 34, 40, 42, 43, 46, 48, 50, 52], "dict": [14, 15], "855": [14, 15, 16], "config_from_fil": [14, 15], "_rc_params_in_fil": [14, 15], "858": [14, 15, 16], "782": [14, 15, 16], "781": [14, 15, 16], "rc_temp": [14, 15], "_open_file_or_url": [14, 15], "fd": [14, 15], "783": [14, 15, 16], "contextlib": [14, 15], "_generatorcontextmanag": [14, 15], "__enter__": [14, 15], "self": [14, 15], "gen": [14, 15], "stopiter": [14, 15], "759": [14, 15, 16], "758": [14, 15, 16], "utf": [14, 15], "open": [14, 15, 19, 25, 30, 31, 52], "760": [14, 15, 16], "yield": [14, 15, 52], "errno": [14, 15], "caus": [14, 15, 19, 27, 42], "oserror": [14, 15], "ioerror": [14, 15], "err": [14, 15, 16, 19, 27, 34, 43, 46], "rais": [14, 15], "found": [14, 15, 16, 18, 19, 23, 25, 27, 28, 29, 30, 33, 34, 49, 50], "valid": [14, 15, 16, 19, 26, 49, 52], "url": [14, 15], "techniqu": [16, 28, 52], "split": [16, 17, 51], "a193d3749ddd44ab9a248e25413be6f9": 16, "tune": [16, 19, 42], "regular": [16, 33, 34, 42, 50], "categor": [16, 19, 35, 36, 38, 42, 43, 46], "scikitlearn": 16, "mine": 16, "linear_model": [16, 19, 30, 31, 41], "linearregress": [16, 31], "ridg": 16, "preprocess": [16, 28, 30, 51], "standardscal": [16, 30, 51], "polynomialfeatur": 16, "model_select": [16, 51], "train_test_split": [16, 51], "mean_squared_error": 16, "public_tests_a1": 16, "backend": 16, "set_floatx": 16, "assigment_util": 16, "sai": [16, 17, 18, 19, 21, 28, 33, 34, 37, 39, 44, 45, 48, 49], "Not": [16, 17, 18, 19, 33, 34, 35], "quit": [16, 18, 19, 22, 28, 29, 33, 34, 36], "abl": [16, 17, 18, 19, 33, 34, 49, 52], "deploi": 16, "origin": [16, 18, 19, 21, 28, 29, 30, 33, 34, 37, 39, 40, 44, 45, 48, 50, 51, 52], "advis": 16, "reserv": 16, "doubl": 16, "x_ideal": 16, "y_ideal": 16, "gen_data": 16, "y_test": [16, 51], "test_siz": 16, "intermix": 16, "those": [16, 18, 19, 30, 33, 34, 40, 48, 49, 50, 52], "quadrat": [16, 19, 29, 38], "nois": [16, 19, 42], "curv": [16, 19, 23, 28, 29, 38, 42], "loc": [16, 18, 19, 33, 34, 39, 44, 45, 50], "j_": 16, "2m_": 16, "m_": [16, 49], "eval_ms": 16, "scalar": [16, 18, 19, 21, 22, 23, 25, 26, 27, 28, 33, 34, 36, 39, 40, 43, 44, 45, 46, 50, 51], "y_hat": 16, "y_tmp": [16, 19, 40, 43, 46], "test_eval_ms": 16, "err_i": [16, 18, 19, 33, 40, 43, 46], "minim": [16, 19, 22, 23, 43, 46, 48, 50, 52], "linear_regress": 16, "lmodel": 16, "lin_model": 16, "err_train": 16, "mse": [16, 52], "err_test": 16, "substanti": [16, 51], "less": [16, 18, 19, 29, 33, 34, 38, 52], "171215": 16, "poor": 16, "job": 16, "overfit": [16, 18, 33, 34, 51], "poorli": 16, "linspac": [16, 18, 19], "y_pred": [16, 19, 30, 31, 41], "plt_train_test": 16, "guid": [16, 17, 22], "meant": [16, 17, 49], "propos": 16, "tabl": [16, 27, 28, 51], "depend": [16, 19, 25, 48, 52, 53], "architectur": [16, 52], "gaug": 16, "twice": [16, 48, 52], "x_": [16, 18, 19, 27, 28, 29, 33, 34, 40, 43, 46, 49], "y_": [16, 49], "x_cv": 16, "y_cv": 16, "b5a2bd42e8f44b2c80c693a2cc870fa": 16, "clear": [16, 19, 23, 28, 29, 35], "guidanc": 16, "By": [16, 48, 52], "degrad": 16, "rel": [16, 23, 29, 50, 51], "datapoint": [16, 17], "cv": [16, 49], "dlorang": [16, 28, 30], "capabl": [16, 19, 26, 50], "course1": 16, "engin": [16, 51, 52], "week3": [16, 18, 19], "knowledg": 16, "tell": [16, 17, 19, 26], "repeatedli": [16, 48], "go": [16, 17, 19, 26, 27, 37, 52, 53], "simplic": [16, 27], "max_degre": 16, "err_cv": 16, "optimal_degre": 16, "argmin": [16, 48, 51], "plt_optimal_degre": 16, "underfit": [16, 19, 42], "On": [16, 23, 28, 31, 49], "solid": 16, "straight": [16, 18, 19, 21, 33, 34], "intersect": [16, 19, 37], "hew": 16, "conform": 16, "fail": [16, 49], "smooth": [16, 19, 38], "significantli": [16, 19, 28, 29, 43, 46, 48], "trend": 16, "methodologi": 16, "lambda_rang": 16, "1e": [16, 29, 50, 52], "num_step": 16, "lambda_": [16, 18, 19, 33, 34, 43, 46, 50], "optimal_reg_idx": 16, "plt_tune_regular": 16, "move": [16, 23, 48, 52], "vertic": [16, 19, 40], "collect": [16, 17, 49, 51, 52], "m_rang": 16, "tune_m": 16, "plt_tune_m": 16, "converg": [16, 18, 19, 23, 25, 27, 28, 29, 33, 34, 40, 43, 46, 48, 50, 51, 52], "That": [16, 17, 19, 25, 26, 31, 37, 39, 44, 45, 48], "percentag": [16, 18, 19, 33, 34], "emphasi": 16, "class": [16, 17, 18, 19, 25, 26, 27, 33], "gen_blob": 16, "popul": [16, 19, 25], "320": 16, "plt_train_eq_dist": 16, "six": [16, 19, 26], "cluster": 16, "identifi": [16, 17, 19, 25, 35, 48], "validataion": 16, "triangl": [16, 19, 21], "interest": [16, 19, 28, 38, 50], "ambigu": 16, "either": [16, 19, 20, 22, 24, 26, 36, 37], "member": 16, "distanc": [16, 23, 48, 51], "fraction": [16, 17], "incorrect": 16, "hat": [16, 52], "neq": 16, "complet": [16, 17, 18, 19, 22, 23, 25, 26, 28, 30, 33, 34, 48, 49, 50, 51, 52], "eval_cat_err": 16, "cerr": 16, "squeez": 16, "333": 16, "250": [16, 22], "test_eval_cat_err": 16, "rate": [16, 18, 19, 23, 25, 27, 33, 34, 40, 50, 51, 52], "lr": 16, "1106": 16, "4281": 16, "3345": 16, "3m": 16, "2896": 16, "2867": 16, "2918": 16, "2497": 16, "2298": 16, "2307": 16, "2071": 16, "2115": 16, "2070": 16, "2366": 16, "2261": 16, "2224": 16, "2055": 16, "2044": 16, "2006": [16, 50, 51], "2168": 16, "2047": 16, "2237": 16, "2113": 16, "2025": 16, "2107": 16, "1935": 16, "1963": 16, "2424": 16, "1969": 16, "1904": 16, "2173": 16, "2074": 16, "1768": 16, "1794": 16, "1733": 16, "1955": 16, "1870": 16, "2128": 16, "1987": 16, "1895": 16, "2073": 16, "2148": 16, "1774": 16, "1886": 16, "1763": 16, "1769": 16, "2020": 16, "1889": 16, "2035": 16, "1761": 16, "1838": 16, "1953": 16, "1882": 16, "1860": 16, "1919": 16, "1848": 16, "1630": 16, "2008": [16, 50, 51], "1936": 16, "1824": 16, "2092": 16, "2287": 16, "1877": 16, "1716": 16, "1917": 16, "1703": 16, "1750": 16, "1836": 16, "1696": 16, "1542": 16, "1715": 16, "1545": 16, "1593": 16, "1844": 16, "1881": 16, "1614": 16, "1762": 16, "1779": 16, "1658": 16, "1639": 16, "1629": 16, "1475": 16, "1452": 16, "1473": 16, "1490": 16, "1650": 16, "1706": 16, "1704": 16, "1764": 16, "1855": 16, "1685": 16, "1569": 16, "1645": 16, "1737": 16, "1600": 16, "1483": 16, "1555": 16, "1678": 16, "1435": 16, "1419": 16, "1494": 16, "4m": 16, "1538": 16, "1682": 16, "1687": 16, "1436": 16, "1366": 16, "1485": 16, "1400": 16, "1444": 16, "1403": 16, "1465": 16, "1549": 16, "1402": 16, "1337": 16, "1422": 16, "1560": 16, "1319": 16, "1389": 16, "1404": 16, "1299": 16, "1247": 16, "1244": [16, 28], "1260": 16, "1158": 16, "1343": 16, "1306": 16, "1294": 16, "1297": 16, "1342": 16, "1232": 16, "1199": 16, "1192": 16, "1477": 16, "1780": 16, "1673": 16, "1292": 16, "1296": 16, "1221": 16, "1300": 16, "1316": 16, "1274": 16, "1266": 16, "1185": 16, "1197": 16, "1148": 16, "1137": 16, "1427": 16, "1420": 16, "1327": 16, "1276": 16, "1099": 16, "1205": 16, "1307": 16, "1476": 16, "1349": 16, "1183": 16, "1225": 16, "1134": 16, "1081": 16, "1245": 16, "1346": 16, "1233": 16, "1113": 16, "1040": 16, "1155": 16, "1049": 16, "1111": 16, "1079": 16, "1021": [16, 51], "1048": 16, "0971": 16, "0985": [16, 51], "1026": 16, "0991": [16, 51], "0890": 16, "0880": 16, "1006": [16, 51], "0974": 16, "1141": 16, "1423": 16, "1381": 16, "201": [16, 52], "1105": 16, "202": 16, "1005": 16, "203": [16, 19, 25], "0846": 16, "204": 16, "1125": 16, "205": 16, "206": 16, "1219": 16, "207": 16, "1161": 16, "208": 16, "209": [16, 22], "1178": 16, "210": 16, "1017": 16, "211": [16, 50], "1051": 16, "212": 16, "1014": [16, 51], "213": 16, "1096": 16, "214": 16, "1087": 16, "215": 16, "216": [16, 48], "1044": 16, "217": 16, "218": [16, 18, 19, 33, 34], "219": 16, "1093": 16, "220": [16, 23, 31], "1041": [16, 51], "221": 16, "0956": 16, "222": 16, "1109": 16, "223": 16, "224": 16, "225": 16, "0968": 16, "226": 16, "227": 16, "1092": 16, "228": 16, "229": 16, "1032": 16, "230": 16, "1153": 16, "231": 16, "1237": 16, "232": [16, 27, 28], "0978": 16, "233": 16, "1074": 16, "234": 16, "1059": [16, 51], "235": 16, "1122": [16, 50], "236": 16, "237": 16, "0879": 16, "238": 16, "0913": 16, "239": 16, "0831": 16, "240": [16, 51], "0752": 16, "241": 16, "0733": 16, "242": 16, "0886": 16, "243": 16, "0837": 16, "244": 16, "0866": 16, "245": 16, "0933": 16, "246": [16, 50], "0976": 16, "247": 16, "1150": [16, 50], "248": 16, "0904": 16, "249": 16, "1073": [16, 51], "251": 16, "1022": 16, "252": 16, "0987": 16, "253": 16, "254": 16, "0813": 16, "255": [16, 48], "0924": 16, "256": [16, 51, 52], "0799": 16, "257": 16, "0947": 16, "258": 16, "259": 16, "0788": 16, "1018": [16, 51], "261": 16, "0942": 16, "262": 16, "0780": 16, "263": 16, "0821": 16, "264": 16, "0795": 16, "265": 16, "266": 16, "0948": 16, "267": 16, "0767": 16, "268": 16, "0720": 16, "269": 16, "0742": 16, "270": 16, "0747": 16, "271": [16, 28], "0726": 16, "272": 16, "0984": 16, "273": 16, "274": 16, "0836": 16, "275": 16, "0783": 16, "276": 16, "277": 16, "278": 16, "279": 16, "0990": 16, "280": 16, "281": 16, "0808": 16, "282": 16, "0798": 16, "283": 16, "285": 16, "0631": 16, "286": [16, 27], "0651": 16, "287": 16, "0602": 16, "288": 16, "289": 16, "0659": 16, "290": 16, "0682": 16, "291": 16, "0745": 16, "292": 16, "293": 16, "294": 16, "295": [16, 30, 31], "296": 16, "297": 16, "0800": 16, "298": 16, "0803": 16, "299": 16, "0765": 16, "301": 16, "0544": 16, "302": 16, "0718": 16, "303": 16, "0877": 16, "304": 16, "0687": 16, "305": 16, "0671": 16, "306": 16, "307": [16, 49], "0773": 16, "308": 16, "0779": 16, "309": 16, "0696": 16, "310": 16, "0883": 16, "311": 16, "312": 16, "0707": 16, "313": 16, "0603": 16, "314": 16, "315": 16, "0660": 16, "316": 16, "0586": 16, "317": 16, "0618": 16, "318": 16, "0588": 16, "319": 16, "0674": 16, "0598": 16, "321": 16, "322": 16, "323": 16, "324": 16, "325": 16, "326": 16, "0749": 16, "327": 16, "0746": 16, "328": 16, "0698": 16, "329": 16, "0691": 16, "330": 16, "331": 16, "0558": 16, "332": 16, "0653": 16, "0593": 16, "334": 16, "0606": 16, "335": 16, "336": 16, "337": 16, "0628": 16, "338": 16, "339": 16, "0723": 16, "340": [16, 21, 23], "0647": 16, "341": 16, "0688": 16, "342": 16, "0793": 16, "343": 16, "0595": 16, "344": 16, "0528": 16, "345": 16, "0552": 16, "346": 16, "0534": 16, "347": 16, "0471": 16, "348": 16, "0491": 16, "349": 16, "0524": 16, "350": 16, "351": 16, "0690": 16, "352": 16, "0864": 16, "353": 16, "0999": [16, 51], "354": 16, "1094": 16, "355": 16, "1189": 16, "356": 16, "357": 16, "0655": 16, "358": 16, "0652": 16, "359": 16, "360": 16, "0545": 16, "361": [16, 29, 50], "0549": 16, "362": 16, "0581": 16, "363": [16, 28, 30], "0506": 16, "364": 16, "0579": 16, "365": 16, "0583": 16, "366": [16, 50], "0607": 16, "367": 16, "0428": 16, "368": 16, "0495": 16, "369": 16, "0721": 16, "370": 16, "0817": 16, "371": 16, "372": 16, "373": 16, "0526": 16, "374": 16, "0463": 16, "375": [16, 33], "376": [16, 51], "0441": 16, "377": 16, "378": 16, "0391": 16, "379": 16, "380": 16, "0461": 16, "381": 16, "0442": 16, "382": [16, 50], "383": 16, "0509": 16, "384": 16, "0479": 16, "385": 16, "386": 16, "387": 16, "0394": 16, "388": 16, "389": [16, 30, 31], "0525": 16, "0666": 16, "391": 16, "392": 16, "0551": 16, "393": [16, 48], "0689": 16, "394": [16, 30, 31], "0663": 16, "395": [16, 51], "0844": 16, "396": 16, "0704": 16, "397": 16, "398": 16, "399": 16, "401": 16, "1717": 16, "402": 16, "1648": 16, "403": 16, "404": 16, "1326": 16, "405": 16, "1367": 16, "406": 16, "1098": 16, "407": 16, "408": 16, "1798": 16, "409": 16, "1268": 16, "410": 16, "1123": 16, "411": [16, 28], "412": 16, "0774": 16, "413": 16, "0661": 16, "414": 16, "415": 16, "0580": 16, "416": 16, "0572": 16, "417": 16, "418": 16, "0546": 16, "419": 16, "0573": 16, "420": 16, "421": 16, "0658": 16, "422": [16, 52], "0686": 16, "423": 16, "424": 16, "425": 16, "0465": 16, "426": [16, 27], "0435": 16, "427": 16, "0362": 16, "428": 16, "0411": 16, "429": 16, "0374": 16, "430": [16, 22], "0412": 16, "432": 16, "433": [16, 52], "434": 16, "0436": 16, "435": 16, "0482": 16, "436": 16, "0420": 16, "437": 16, "0347": 16, "438": 16, "0390": 16, "439": 16, "0328": 16, "440": 16, "0371": 16, "441": 16, "0334": 16, "442": 16, "443": [16, 50], "0370": 16, "444": 16, "445": 16, "0329": 16, "446": 16, "0318": 16, "447": 16, "448": 16, "449": 16, "0346": 16, "450": [16, 25], "0340": 16, "451": 16, "452": 16, "453": 16, "0406": 16, "454": 16, "455": 16, "0584": 16, "456": 16, "457": 16, "458": 16, "0468": 16, "459": [16, 27], "0373": 16, "460": [16, 27], "461": 16, "462": 16, "0284": 16, "463": 16, "464": 16, "465": 16, "0302": 16, "466": 16, "467": 16, "0350": 16, "468": 16, "469": 16, "0305": 16, "470": 16, "471": 16, "472": 16, "0543": 16, "473": 16, "0477": 16, "474": 16, "0630": 16, "475": 16, "1523": 16, "476": 16, "3248": 16, "477": 16, "478": 16, "1623": 16, "479": 16, "1206": 16, "480": [16, 22, 52], "0955": 16, "481": 16, "1595": 16, "482": 16, "1626": 16, "483": 16, "1170": 16, "484": 16, "1481": 16, "485": [16, 30, 31], "486": 16, "0590": 16, "487": 16, "488": 16, "489": 16, "490": 16, "0539": 16, "491": 16, "0451": 16, "492": [16, 30, 31], "493": 16, "0484": 16, "494": 16, "0639": 16, "495": 16, "0497": 16, "496": 16, "0787": 16, "497": 16, "0805": 16, "498": 16, "499": 16, "0504": 16, "0478": 16, "501": 16, "502": 16, "0419": 16, "503": 16, "504": 16, "0352": 16, "505": 16, "0368": 16, "506": [16, 52], "507": 16, "0375": 16, "508": 16, "509": [16, 28, 30, 31], "510": 16, "0364": 16, "511": 16, "512": 16, "0290": 16, "513": 16, "514": 16, "0320": 16, "515": 16, "0271": 16, "516": 16, "517": 16, "0308": 16, "518": 16, "519": 16, "0444": 16, "520": 16, "0381": 16, "521": 16, "0356": 16, "522": 16, "0324": 16, "523": 16, "0292": 16, "524": 16, "525": 16, "526": 16, "527": 16, "0351": 16, "528": 16, "529": 16, "530": 16, "531": 16, "532": 16, "533": 16, "0387": 16, "534": [16, 52], "0431": 16, "535": 16, "536": 16, "537": 16, "0285": 16, "538": 16, "0278": 16, "539": 16, "0274": 16, "540": [16, 30, 31], "0338": 16, "541": 16, "0262": 16, "542": 16, "0283": 16, "543": 16, "0265": 16, "544": 16, "0267": 16, "545": 16, "546": 16, "0256": 16, "547": 16, "548": 16, "0323": 16, "549": 16, "550": 16, "0288": 16, "551": 16, "552": 16, "0315": 16, "553": 16, "554": 16, "0376": 16, "555": 16, "556": 16, "0296": 16, "557": 16, "0307": 16, "558": 16, "0270": 16, "559": 16, "0268": 16, "560": 16, "561": 16, "0251": 16, "562": 16, "563": 16, "0249": 16, "564": 16, "565": 16, "0297": 16, "566": 16, "567": 16, "0432": 16, "568": 16, "0483": 16, "569": 16, "570": 16, "1063": 16, "571": 16, "1035": 16, "572": 16, "1415": 16, "573": 16, "1534": 16, "574": 16, "1474": 16, "576": 16, "577": 16, "0770": 16, "578": 16, "0637": 16, "579": 16, "580": 16, "581": 16, "582": 16, "583": 16, "584": 16, "0309": 16, "585": 16, "586": 16, "587": 16, "0266": 16, "588": 16, "589": 16, "0276": 16, "590": 16, "591": 16, "592": [16, 19, 25], "593": 16, "594": 16, "0259": 16, "595": 16, "596": 16, "0258": 16, "597": 16, "598": 16, "0254": 16, "599": 16, "600": [16, 25, 27, 28, 29, 50, 51], "0241": 16, "601": 16, "0269": 16, "602": 16, "0287": 16, "603": 16, "0257": 16, "604": 16, "605": 16, "0232": 16, "606": 16, "0281": 16, "607": 16, "0247": 16, "608": 16, "609": 16, "0237": 16, "610": 16, "0253": 16, "611": 16, "612": 16, "0235": 16, "613": 16, "614": 16, "0236": 16, "615": 16, "616": 16, "617": 16, "0231": 16, "618": 16, "619": 16, "620": 16, "621": 16, "622": [16, 50], "623": 16, "1078": 16, "624": 16, "1180": 16, "625": [16, 51], "626": 16, "627": 16, "628": 16, "0327": 16, "629": 16, "0389": 16, "630": [16, 22], "631": 16, "0342": 16, "632": 16, "0272": 16, "633": 16, "0240": 16, "634": 16, "635": 16, "636": 16, "637": 16, "0222": 16, "638": 16, "0223": 16, "639": 16, "0215": 16, "640": 16, "641": 16, "0248": 16, "642": 16, "643": 16, "0213": 16, "644": 16, "0277": 16, "645": 16, "646": 16, "647": 16, "648": 16, "0357": 16, "649": 16, "650": 16, "0255": 16, "651": 16, "652": 16, "653": [16, 50], "0242": 16, "654": 16, "0239": 16, "655": 16, "0218": 16, "656": 16, "0227": 16, "657": 16, "658": 16, "659": 16, "660": 16, "0233": 16, "661": 16, "0246": 16, "662": [16, 25], "0313": 16, "663": 16, "0238": 16, "664": 16, "665": 16, "0205": 16, "666": 16, "667": 16, "668": 16, "669": 16, "670": 16, "671": 16, "672": 16, "673": 16, "674": 16, "1732": 16, "675": 16, "0889": 16, "676": 16, "677": 16, "678": 16, "0532": 16, "679": 16, "0577": 16, "680": 16, "681": 16, "682": 16, "1581": 16, "683": 16, "684": 16, "1065": 16, "685": 16, "1236": 16, "686": 16, "1184": 16, "687": [16, 27], "1218": 16, "688": [16, 27], "689": [16, 27], "1437": 16, "690": [16, 27], "0897": 16, "691": [16, 27], "0665": 16, "692": [16, 27], "693": [16, 18, 19, 27, 33, 34], "694": [16, 27, 51], "0425": 16, "695": [16, 27], "696": 16, "697": 16, "698": 16, "699": 16, "0367": 16, "700": [16, 27, 28, 29], "0311": 16, "701": 16, "702": 16, "703": 16, "704": 16, "705": 16, "0282": 16, "706": 16, "0263": 16, "707": 16, "0286": 16, "708": 16, "0275": 16, "709": 16, "710": 16, "0252": 16, "711": 16, "712": 16, "0261": 16, "713": 16, "714": 16, "715": 16, "716": 16, "717": 16, "0264": 16, "718": 16, "719": 16, "0234": 16, "720": 16, "721": 16, "722": [16, 52], "0244": 16, "723": 16, "724": 16, "725": 16, "0224": 16, "726": 16, "727": 16, "728": 16, "729": 16, "0220": 16, "730": [16, 22], "731": 16, "732": 16, "733": 16, "0208": 16, "734": 16, "735": 16, "736": 16, "0230": 16, "737": 16, "738": 16, "739": 16, "740": 16, "741": 16, "742": 16, "743": 16, "0210": 16, "744": 16, "0216": 16, "745": 16, "746": 16, "747": 16, "0193": 16, "748": 16, "749": 16, "0217": 16, "750": [16, 25], "751": 16, "0203": 16, "752": 16, "0194": 16, "753": 16, "754": [16, 50], "755": 16, "0206": 16, "756": 16, "0192": 16, "757": 16, "761": 16, "0204": 16, "762": 16, "0219": 16, "763": 16, "764": 16, "0699": 16, "765": 16, "766": 16, "767": 16, "768": 16, "1082": 16, "769": 16, "770": 16, "771": 16, "772": 16, "0589": 16, "773": [16, 50], "774": 16, "775": 16, "776": 16, "0932": 16, "777": 16, "1891": 16, "778": 16, "1356": 16, "779": 16, "780": 16, "0973": 16, "0768": 16, "0761": 16, "1075": 16, "784": 16, "0789": 16, "785": [16, 27], "0467": 16, "786": 16, "787": 16, "0360": 16, "788": 16, "789": 16, "790": 16, "0291": 16, "791": 16, "792": 16, "793": [16, 50], "794": 16, "795": 16, "0250": 16, "796": 16, "797": 16, "798": 16, "799": 16, "800": [16, 27, 28, 29], "0298": 16, "801": 16, "802": 16, "803": 16, "804": 16, "805": 16, "806": 16, "807": [16, 19, 25], "808": 16, "809": 16, "810": 16, "811": 16, "812": 16, "813": 16, "814": 16, "815": 16, "816": 16, "817": 16, "818": 16, "819": 16, "820": 16, "821": 16, "822": 16, "823": 16, "0299": 16, "824": 16, "825": 16, "826": 16, "827": 16, "828": 16, "829": 16, "830": 16, "831": 16, "832": 16, "833": 16, "0221": 16, "834": 16, "835": 16, "836": 16, "837": 16, "838": 16, "0229": 16, "839": 16, "840": [16, 52], "841": 16, "845": 16, "846": 16, "847": 16, "848": 16, "849": 16, "850": 16, "851": 16, "852": [16, 27], "853": 16, "0211": 16, "857": 16, "859": 16, "860": 16, "0214": 16, "861": 16, "862": 16, "863": 16, "864": 16, "0198": 16, "865": 16, "0200": 16, "866": 16, "0273": 16, "867": 16, "868": 16, "869": 16, "870": 16, "871": 16, "0354": 16, "872": 16, "873": 16, "874": 16, "0201": 16, "875": [16, 49], "876": 16, "877": 16, "878": 16, "879": 16, "880": 16, "881": 16, "0729": 16, "882": 16, "0460": 16, "883": 16, "0439": 16, "884": 16, "0811": 16, "885": 16, "886": 16, "887": 16, "0289": 16, "888": 16, "889": 16, "890": 16, "891": 16, "892": 16, "893": 16, "0196": 16, "894": 16, "895": 16, "0189": 16, "896": 16, "897": 16, "898": 16, "899": 16, "900": [16, 25, 27, 28, 29], "901": 16, "0199": 16, "902": 16, "903": 16, "0185": 16, "904": 16, "905": 16, "906": 16, "907": 16, "0190": 16, "908": 16, "909": 16, "910": 16, "911": 16, "912": 16, "913": 16, "1883": [16, 51], "914": 16, "2096": 16, "915": 16, "1323": 16, "916": 16, "917": 16, "1167": 16, "918": 16, "0621": 16, "919": 16, "0929": 16, "920": [16, 19, 25, 48], "921": 16, "922": 16, "923": 16, "924": 16, "0712": 16, "925": 16, "926": 16, "0385": 16, "927": 16, "928": 16, "929": [16, 50], "930": 16, "931": 16, "932": 16, "0322": 16, "933": 16, "934": 16, "0493": 16, "935": 16, "936": 16, "937": 16, "938": 16, "939": 16, "940": 16, "941": 16, "942": 16, "943": 16, "944": 16, "945": 16, "946": 16, "947": 16, "948": 16, "949": 16, "950": 16, "951": 16, "0293": 16, "952": [16, 28], "953": 16, "954": 16, "0395": 16, "955": 16, "956": 16, "957": 16, "958": 16, "959": 16, "960": 16, "961": 16, "962": 16, "963": 16, "964": 16, "965": 16, "966": 16, "0197": 16, "967": 16, "968": 16, "0188": 16, "969": 16, "970": 16, "0169": 16, "971": 16, "0161": 16, "972": 16, "0176": 16, "973": 16, "974": 16, "975": 16, "976": 16, "977": 16, "978": 16, "979": 16, "0522": 16, "980": 16, "0851": 16, "981": 16, "982": 16, "0380": 16, "983": 16, "984": 16, "985": 16, "986": 16, "987": 16, "988": [16, 50], "0170": 16, "989": 16, "0166": 16, "990": 16, "0175": 16, "991": 16, "0149": 16, "992": 16, "0152": 16, "993": 16, "0153": 16, "994": 16, "0142": 16, "995": [16, 52], "996": 16, "997": 16, "998": 16, "999": 16, "0155": 16, "0172": 16, "0x7f9a783a0390": 16, "model_test": 16, "4840": 16, "instanc": [16, 49, 52], "increment": [16, 17, 50, 51], "model_predict": 16, "xl": 16, "plt_nn": 16, "hard": 16, "outlier": [16, 19, 42, 49], "miscategor": 16, "training_cerr_complex": 16, "cv_cerr_complex": 16, "003": 16, "unq_c4": [16, 17, 18, 19, 33, 34], "model_": 16, "885u": 16, "7306": 16, "849u": 16, "4468": 16, "865u": 16, "2902": [16, 50], "856u": 16, "848u": 16, "9710": 16, "858u": 16, "7947": 16, "6499": 16, "860u": 16, "5378": 16, "857u": 16, "4652": 16, "864u": 16, "4184": 16, "861u": 16, "3860": 16, "845u": 16, "3641": 16, "847u": 16, "3487": 16, "839u": 16, "3316": 16, "838u": 16, "3201": 16, "833u": 16, "3110": 16, "840u": 16, "3026": 16, "836u": 16, "2953": 16, "846u": 16, "2880": 16, "859u": 16, "2824": 16, "2768": 16, "2716": [16, 50], "844u": 16, "2690": 16, "2618": 16, "841u": 16, "2606": 16, "2560": 16, "2516": 16, "825u": 16, "2500": 16, "814u": 16, "818u": 16, "866u": 16, "2406": 16, "884u": 16, "2386": 16, "928u": 16, "2371": 16, "908u": 16, "2355": 16, "878u": 16, "2328": 16, "915u": 16, "2311": 16, "2289": 16, "929u": 16, "2271": 16, "917u": 16, "2278": 16, "923u": 16, "2269": 16, "925u": 16, "2244": 16, "920u": 16, "2250": 16, "932u": 16, "2228": 16, "877u": 16, "2227": 16, "889u": 16, "2230": 16, "936u": 16, "2198": 16, "870u": 16, "896u": 16, "2156": 16, "817u": 16, "2165": 16, "2155": 16, "822u": 16, "2130": 16, "823u": 16, "2121": 16, "2122": 16, "2105": 16, "816u": 16, "2116": 16, "805u": 16, "829u": 16, "2084": 16, "819u": 16, "826u": 16, "2101": 16, "830u": 16, "2095": 16, "834u": 16, "2085": 16, "853u": 16, "2120": 16, "2087": 16, "950u": 16, "2090": 16, "905u": 16, "2053": 16, "914u": 16, "2061": 16, "935u": 16, "2075": 16, "2067": 16, "811u": 16, "2039": 16, "2036": 16, "821u": 16, "2062": 16, "827u": 16, "2017": 16, "807u": 16, "808u": 16, "802u": 16, "1999": 16, "801u": 16, "2028": 16, "794u": 16, "810u": 16, "2042": 16, "800u": 16, "2016": 16, "2068": 16, "809u": 16, "2005": [16, 51], "2011": [16, 50, 51], "1998": 16, "812u": 16, "1992": 16, "2001": [16, 50, 51], "1997": 16, "806u": 16, "2015": [16, 50, 51], "804u": 16, "2031": 16, "1991": 16, "820u": 16, "803u": 16, "2010": [16, 26, 50, 51], "835u": 16, "2018": 16, "2026": 16, "1988": 16, "1974": 16, "1966": 16, "843u": 16, "1978": 16, "1962": 16, "1979": 16, "1944": 16, "813u": 16, "815u": 16, "1934": 16, "2009": [16, 50, 51], "1943": 16, "797u": 16, "1951": 16, "1964": 16, "1957": 16, "1970": 16, "1960": 16, "1973": 16, "1961": 16, "799u": 16, "1949": 16, "1946": 16, "850u": 16, "1926": 16, "837u": 16, "1925": 16, "890u": 16, "1933": 16, "881u": 16, "1942": 16, "924u": 16, "1976": 16, "1939": 16, "957u": 16, "1931": 16, "1947": [16, 28], "1941": 16, "872u": 16, "1922": 16, "854u": 16, "903u": 16, "1948": 16, "852u": 16, "1921": 16, "1920": 16, "1899": 16, "1913": 16, "832u": 16, "1914": 16, "934u": 16, "1898": 16, "976u": 16, "1905": 16, "937u": 16, "1910": 16, "912u": 16, "1930": 16, "1907": 16, "1940": 16, "868u": 16, "1893": 16, "1879": 16, "1924": 16, "1887": 16, "1876": 16, "1861": 16, "1977": 16, "1906": 16, "1872": 16, "1885": 16, "1867": 16, "867u": 16, "1866": 16, "1884": 16, "871u": 16, "1890": 16, "1880": 16, "1863": 16, "1857": 16, "1859": 16, "1856": 16, "1869": 16, "1837": 16, "1846": 16, "1841": [16, 50], "1902": 16, "851u": 16, "1834": 16, "1843": 16, "1878": 16, "1851": 16, "828u": 16, "831u": 16, "1849": 16, "1874": 16, "1822": 16, "786u": 16, "1923": 16, "796u": 16, "1832": 16, "793u": 16, "1871": 16, "788u": 16, "1826": 16, "1820": 16, "1829": 16, "1828": 16, "1842": 16, "1830": 16, "1833": 16, "1796": 16, "1819": 16, "842u": 16, "1827": 16, "1831": 16, "1835": 16, "1812": 16, "1817": 16, "1801": 16, "1868": 16, "1815": 16, "1847": 16, "1816": 16, "1797": 16, "1807": 16, "1813": 16, "1793": 16, "1784": 16, "824u": 16, "1823": 16, "1788": 16, "899u": 16, "898u": 16, "1818": 16, "1811": 16, "900u": 16, "1814": 16, "1854": 16, "1785": 16, "880u": 16, "1775": 16, "1792": 16, "873u": 16, "876u": 16, "863u": 16, "1800": 16, "1783": 16, "1790": 16, "1803": 16, "938u": 16, "1808": 16, "941u": 16, "933u": 16, "916u": 16, "1789": 16, "1802": 16, "1786": 16, "1781": 16, "1821": 16, "1799": 16, "1776": 16, "943u": 16, "1771": [16, 50], "1773": 16, "1770": 16, "798u": 16, "1766": 16, "785u": 16, "777u": 16, "784u": 16, "1809": 16, "1767": 16, "875u": 16, "909u": 16, "891u": 16, "904u": 16, "906u": 16, "1765": 16, "883u": 16, "1753": 16, "1759": 16, "893u": 16, "1778": 16, "887u": 16, "1760": 16, "1756": 16, "1777": 16, "1754": 16, "918u": 16, "894u": 16, "1739": 16, "888u": 16, "1757": 16, "913u": 16, "1755": 16, "855u": 16, "783u": 16, "1752": 16, "1742": 16, "1746": 16, "1772": 16, "1748": 16, "1744": 16, "1745": 16, "1751": 16, "1749": 16, "1735": 16, "1741": 16, "1719": 16, "862u": 16, "1730": 16, "1738": 16, "1729": 16, "1747": 16, "953u": 16, "1731": 16, "1810": 16, "939u": 16, "1740": 16, "946u": 16, "1743": [16, 50], "1713": 16, "1734": 16, "1723": 16, "886u": 16, "1736": 16, "1725": 16, "1727": 16, "902u": 16, "1718": 16, "1728": 16, "1722": 16, "869u": 16, "882u": 16, "1721": 16, "1710": 16, "790u": 16, "1707": 16, "782u": 16, "1720": 16, "1711": 16, "1700": 16, "1705": 16, "1699": 16, "1712": 16, "1701": 16, "1697": 16, "1694": 16, "1693": 16, "1726": 16, "1795": 16, "1698": 16, "1708": 16, "1702": 16, "1690": 16, "1680": 16, "1714": 16, "1676": 16, "1684": 16, "1695": 16, "1689": 16, "1681": 16, "1691": 16, "1672": 16, "1659": 16, "1668": 16, "1683": 16, "1679": 16, "1688": 16, "1669": 16, "1675": 16, "892u": 16, "1686": 16, "1670": 16, "1677": 16, "945u": 16, "1664": 16, "1660": 16, "1674": 16, "1667": 16, "1647": 16, "1661": 16, "1644": 16, "1654": 16, "1671": 16, "879u": 16, "1666": 16, "1655": 16, "1665": 16, "948u": 16, "947u": 16, "1628": 16, "0x7f9a6c7769d0": 16, "model_s_test": 16, "dense_3": 16, "dense_4": 16, "model_predict_": 16, "pretti": [16, 19, 28, 36, 38], "training_cerr_simpl": 16, "cv_cerr_simpl": 16, "062": 16, "087": 16, "littl": [16, 22, 51, 52], "higher": [16, 18, 19, 25, 28, 33, 34, 37, 39, 44, 45], "better": [16, 18, 19, 21, 25, 26, 29, 33, 34, 37, 39, 40, 44, 45], "moder": 16, "reconstruct": [16, 48], "kernel_regular": 16, "unq_c5": [16, 18, 19, 33, 34], "model_r": 16, "4464": 16, "7086": 16, "3465": 16, "0870": 16, "0137": 16, "9718": 16, "9481": 16, "8934": 16, "8171": 16, "7715": 16, "7611": 16, "7521": 16, "7430": 16, "7474": 16, "7045": 16, "7056": 16, "7182": 16, "7126": 16, "6868": 16, "6733": 16, "6572": 16, "6630": 16, "6508": 16, "6395": 16, "6603": 16, "7651": 16, "6369": 16, "6122": 16, "6002": 16, "6216": 16, "6096": 16, "6260": 16, "6151": 16, "6551": 16, "6538": 16, "6324": 16, "5940": 16, "5739": 16, "5686": 16, "5697": 16, "5845": 16, "5564": 16, "5791": 16, "5855": 16, "5822": 16, "5683": 16, "5278": 16, "5762": 16, "5532": 16, "5313": 16, "5409": 16, "5302": 16, "5362": 16, "5209": 16, "5680": 16, "5131": 16, "5216": 16, "5181": 16, "5470": 16, "5524": 16, "5482": 16, "5393": 16, "5135": 16, "5322": 16, "5148": 16, "5021": 16, "5041": 16, "5086": 16, "5108": 16, "5156": 16, "5115": 16, "5003": 16, "4989": 16, "5097": 16, "5001": 16, "5060": 16, "4977": 16, "5227": 16, "5380": 16, "5101": 16, "5247": 16, "4910": 16, "4799": 16, "4877": 16, "4816": 16, "4969": 16, "4812": 16, "4776": 16, "4696": 16, "4759": 16, "4731": 16, "4599": 16, "4623": 16, "4669": 16, "4545": 16, "4709": 16, "4961": 16, "4954": 16, "4874": 16, "4739": 16, "4682": 16, "5125": 16, "4548": 16, "4610": 16, "4702": 16, "4565": 16, "4568": 16, "4550": 16, "4541": 16, "4450": 16, "4411": 16, "4398": 16, "4482": 16, "4724": 16, "4591": 16, "4686": 16, "4736": 16, "5020": 16, "4630": 16, "4543": 16, "4465": 16, "4328": 16, "4386": 16, "4348": 16, "4419": 16, "4371": 16, "4542": 16, "4331": 16, "4236": 16, "4470": 16, "4431": 16, "4460": 16, "4480": 16, "4627": 16, "4332": 16, "4201": 16, "4340": 16, "4382": 16, "4264": 16, "4260": 16, "4603": 16, "4396": 16, "4239": 16, "4208": 16, "4169": 16, "4391": 16, "4230": 16, "4316": 16, "4312": 16, "4280": 16, "4210": 16, "4066": 16, "4302": 16, "4433": 16, "4284": 16, "4102": 16, "4265": 16, "4454": 16, "4595": 16, "4779": 16, "4529": 16, "4206": 16, "4214": 16, "4343": 16, "4415": 16, "4200": 16, "4323": 16, "4162": 16, "4130": 16, "4324": 16, "4232": 16, "4093": 16, "4030": 16, "4055": 16, "4087": 16, "4134": 16, "4165": 16, "3974": 16, "3971": 16, "4116": 16, "4153": 16, "4132": 16, "4158": 16, "4026": 16, "3953": 16, "4191": 16, "3963": 16, "4080": 16, "4032": 16, "4268": 16, "3954": 16, "3980": 16, "4088": 16, "4571": 16, "4315": 16, "4097": 16, "4166": 16, "4393": 16, "4124": 16, "4216": 16, "4118": 16, "4038": 16, "4036": 16, "3945": 16, "4068": 16, "3940": 16, "4194": 16, "3976": 16, "3873": 16, "4034": 16, "4334": 16, "4213": 16, "4377": 16, "3912": 16, "4028": 16, "4112": 16, "4021": 16, "4107": 16, "3893": 16, "3889": 16, "3881": 16, "3966": 16, "4168": 16, "4049": 16, "3863": 16, "3890": 16, "3908": 16, "3888": 16, "3984": 16, "3993": 16, "4078": 16, "3814": 16, "3897": 16, "3995": 16, "3910": 16, "4142": 16, "3950": 16, "4073": 16, "4041": 16, "3808": 16, "4020": 16, "3885": 16, "3947": 16, "3841": 16, "4000": [16, 18, 19, 23, 29, 33, 34, 40], "4665": 16, "4367": 16, "3989": 16, "4251": 16, "4346": 16, "4114": 16, "3832": 16, "3787": 16, "3874": 16, "3891": 16, "4039": 16, "3776": 16, "3903": 16, "3870": 16, "3825": 16, "3812": 16, "3938": 16, "3764": 16, "3800": 16, "3876": 16, "3853": 16, "4070": 16, "3956": 16, "3915": 16, "3877": 16, "3760": 16, "3892": 16, "3911": 16, "3697": 16, "4007": 16, "3768": 16, "3884": 16, "3926": 16, "4250": 16, "3894": 16, "3858": 16, "3804": 16, "3810": 16, "3883": 16, "3922": 16, "3879": 16, "3801": 16, "3715": 16, "3690": 16, "3733": 16, "3843": 16, "3822": 16, "3789": 16, "3742": 16, "3791": 16, "3836": 16, "3935": 16, "3927": 16, "4023": 16, "4109": 16, "3807": 16, "3919": 16, "3763": 16, "3669": 16, "3724": 16, "4101": 16, "3930": 16, "3933": 16, "3975": 16, "3737": 16, "3719": 16, "3868": 16, "3749": 16, "3693": 16, "3644": 16, "3633": 16, "3662": 16, "4182": 16, "4027": 16, "3757": 16, "3691": 16, "3651": 16, "3961": 16, "4104": 16, "4556": 16, "4061": 16, "3714": 16, "3674": 16, "3638": 16, "3991": 16, "3732": 16, "3608": 16, "3611": 16, "3565": 16, "3797": 16, "3772": 16, "3616": 16, "3748": 16, "4119": 16, "3712": 16, "3780": 16, "3642": 16, "3681": 16, "3574": 16, "3717": 16, "3531": 16, "3664": 16, "3819": 16, "3605": 16, "3635": 16, "3932": 16, "3799": 16, "3771": 16, "3753": 16, "3727": 16, "3584": 16, "3613": 16, "3617": 16, "3545": 16, "3698": 16, "3630": 16, "3818": 16, "3842": 16, "3936": 16, "3794": 16, "3626": 16, "3576": 16, "3730": 16, "3806": 16, "3629": 16, "3673": 16, "3534": 16, "3942": 16, "3729": 16, "3723": 16, "3682": 16, "3655": 16, "3707": 16, "3631": 16, "3523": 16, "3592": 16, "3501": 16, "3474": 16, "3725": 16, "3735": 16, "3537": 16, "3685": 16, "3609": 16, "3533": 16, "3551": 16, "3492": 16, "3628": 16, "3558": 16, "3624": 16, "3632": 16, "3509": 16, "3559": 16, "3495": 16, "3765": 16, "3667": 16, "4002": 16, "4147": 16, "3473": 16, "3688": 16, "4113": 16, "3998": 16, "3604": 16, "3805": 16, "3670": 16, "3594": 16, "3802": 16, "3782": 16, "3564": 16, "3470": 16, "3539": 16, "3401": 16, "3561": 16, "3510": 16, "3548": 16, "3525": 16, "3736": 16, "4008": 16, "3497": 16, "3444": 16, "3610": 16, "3546": 16, "3586": 16, "3645": 16, "3684": 16, "3834": 16, "3581": 16, "3402": 16, "3503": 16, "3488": 16, "3514": 16, "3482": 16, "3461": 16, "3535": 16, "3595": 16, "3676": 16, "3475": 16, "3659": 16, "3416": 16, "3484": 16, "3420": 16, "3476": 16, "3793": 16, "3761": 16, "3456": 16, "3398": 16, "3614": 16, "3618": 16, "3422": 16, "3591": 16, "3597": 16, "3934": 16, "4010": 16, "3746": 16, "3709": 16, "3648": 16, "3654": 16, "3436": 16, "3411": 16, "3460": 16, "3396": 16, "3513": 16, "3706": 16, "3578": 16, "3826": 16, "3486": 16, "3443": 16, "3528": 16, "3515": 16, "3615": 16, "3448": 16, "3620": 16, "3439": 16, "3493": 16, "3499": 16, "3386": 16, "3500": 16, "3619": 16, "3435": [16, 50], "3557": 16, "4221": 16, "3583": 16, "3376": 16, "3540": 16, "3571": 16, "3536": 16, "3407": 16, "3348": 16, "3374": 16, "3489": 16, "3452": 16, "3429": 16, "4209": 16, "3978": 16, "3419": 16, "3529": 16, "3504": 16, "3590": 16, "3738": 16, "3516": 16, "3480": 16, "3599": 16, "3668": 16, "3593": 16, "3483": 16, "3287": 16, "4033": 16, "3413": 16, "3359": 16, "3319": 16, "3567": 16, "3774": 16, "3777": 16, "3455": 16, "3428": 16, "3522": 16, "3543": 16, "3427": 16, "3329": 16, "3478": 16, "3361": 16, "3457": 16, "3430": 16, "3403": 16, "3568": 16, "3541": 16, "3520": 16, "3340": 16, "3299": 16, "3352": 16, "3466": 16, "3784": 16, "4009": 16, "3426": 16, "3406": 16, "3369": 16, "3356": 16, "3549": 16, "3399": 16, "3363": 16, "3415": 16, "3424": 16, "3321": 16, "3471": 16, "3554": 16, "3445": 16, "3390": 16, "3378": 16, "3355": 16, "3517": 16, "3256": 16, "3269": 16, "3518": 16, "3458": 16, "3854": 16, "3291": 16, "3360": 16, "3587": 16, "4233": 16, "3999": 16, "3512": 16, "3524": 16, "3441": 16, "3547": 16, "3519": 16, "3650": 16, "3722": 16, "3423": 16, "3472": 16, "3447": 16, "3786": 16, "3409": 16, "3318": 16, "3281": 16, "3304": 16, "3277": 16, "3511": 16, "4063": 16, "3317": 16, "3496": 16, "3339": 16, "3589": 16, "3521": 16, "3301": 16, "3454": 16, "3377": 16, "3882": 16, "3705": 16, "3279": 16, "3393": 16, "3259": 16, "3296": 16, "3298": 16, "3286": 16, "3392": 16, "3368": 16, "3307": 16, "3382": 16, "3734": 16, "3788": 16, "3315": 16, "3506": 16, "3276": 16, "3280": 16, "3552": 16, "3773": 16, "3324": 16, "3241": 16, "3331": 16, "3625": 16, "3300": 16, "3694": 16, "3308": 16, "3247": 16, "4228": 16, "3434": 16, "3238": 16, "3268": 16, "3740": 16, "3566": 16, "3347": 16, "3272": 16, "3351": 16, "3570": 16, "3220": 16, "3364": 16, "3658": 16, "3400": 16, "3381": 16, "3421": 16, "3686": 16, "3783": 16, "3459": 16, "3653": 16, "3222": 16, "3334": 16, "3601": 16, "3410": 16, "3373": 16, "3479": 16, "3270": 16, "3598": 16, "4354": 16, "3778": 16, "3704": 16, "3713": 16, "3285": 16, "3294": 16, "3266": 16, "3464": 16, "3721": 16, "3743": 16, "3283": 16, "4247": 16, "3323": 16, "3453": 16, "3582": 16, "3751": 16, "3507": 16, "3225": 16, "3342": 16, "3188": 16, "3240": 16, "3440": 16, "3357": 16, "3297": 16, "3231": 16, "3178": 16, "3111": 16, "3343": 16, "3389": 16, "3572": 16, "3215": 16, "3322": 16, "3159": 16, "3218": 16, "3196": 16, "3408": 16, "3208": 16, "3292": 16, "3362": 16, "3865": 16, "3795": 16, "3494": 16, "3260": 16, "3278": 16, "3219": 16, "3267": 16, "3263": 16, "3288": 16, "3174": 16, "3253": 16, "3199": 16, "3354": 16, "3282": 16, "3532": 16, "3505": 16, "0x7f9a684e19d0": 16, "model_r_test": 16, "dense_5": 16, "dense_6": 16, "dense_7": 16, "ddd": 16, "complexregular": 16, "model_predict_r": 16, "training_cerr_reg": 16, "cv_cerr_reg": 16, "test_cerr_reg": 16, "072": 16, "066": 16, "wors": [16, 19, 25, 39, 44, 45], "finish": [16, 18, 19, 33, 34, 50], "1055": 16, "4858": 16, "3211": 16, "3000": [16, 18, 19, 23, 29, 33, 34, 40], "2910": 16, "2648": 16, "2734": 16, "2646": 16, "2929": 16, "2762": 16, "3013": 16, "2616": 16, "2628": 16, "2574": 16, "2740": 16, "2536": 16, "2622": 16, "2747": 16, "2742": 16, "2539": 16, "2712": 16, "2506": 16, "2504": 16, "2647": 16, "2773": 16, "2587": 16, "2579": 16, "2446": 16, "2664": 16, "2508": 16, "2304": 16, "2398": 16, "2703": 16, "2665": 16, "2429": 16, "2581": 16, "2825": 16, "2437": 16, "2321": 16, "2325": 16, "2283": 16, "2255": 16, "2451": 16, "2477": 16, "2280": 16, "2741": 16, "2435": 16, "2698": 16, "2489": 16, "2588": 16, "2569": 16, "2475": 16, "2257": 16, "2267": 16, "2697": 16, "2643": 16, "2571": 16, "2815": 16, "2878": 16, "2394": 16, "2338": 16, "2546": 16, "2465": 16, "2550": 16, "2502": 16, "2468": 16, "2368": 16, "2341": 16, "2314": 16, "2401": 16, "2478": 16, "2346": 16, "2324": 16, "2297": 16, "2306": 16, "2300": 16, "2262": 16, "2189": 16, "2184": 16, "2201": 16, "2176": 16, "2427": 16, "2428": 16, "2501": 16, "2412": 16, "2254": 16, "2411": 16, "2359": 16, "2533": 16, "2353": 16, "2218": 16, "2232": 16, "2330": 16, "2145": 16, "2264": 16, "2220": 16, "2372": 16, "2141": 16, "2125": 16, "2180": 16, "2147": 16, "2193": 16, "2160": 16, "2187": 16, "2099": 16, "2094": 16, "2216": 16, "2138": 16, "2163": 16, "2217": 16, "2144": 16, "2080": 16, "2124": 16, "2100": 16, "2081": 16, "2205": 16, "2077": 16, "2204": 16, "2146": 16, "2133": 16, "2234": 16, "2182": 16, "2191": 16, "2164": 16, "2110": 16, "2196": 16, "2014": [16, 50], "2024": 16, "2171": 16, "2202": 16, "2135": 16, "2072": 16, "2288": 16, "2118": 16, "2185": 16, "2109": 16, "2058": 16, "2134": 16, "2032": 16, "2208": 16, "2098": 16, "1989": 16, "2045": 16, "2013": [16, 50], "2033": 16, "2129": 16, "2040": 16, "2046": 16, "2082": 16, "2199": 16, "2089": 16, "2078": 16, "2152": 16, "2030": 16, "1952": 16, "2066": 16, "2206": 16, "2373": 16, "2167": 16, "1968": 16, "2069": 16, "2012": [16, 50], "2153": 16, "2126": 16, "1984": 16, "1975": 16, "1996": 16, "2038": 16, "1912": 16, "1990": 16, "1909": 16, "1985": 16, "1983": 16, "1901": 16, "1900": 16, "1954": 16, "1994": 16, "1927": 16, "2143": 16, "1956": 16, "1892": 16, "1911": 16, "1932": 16, "1916": 16, "1839": 16, "1982": 16, "2091": 16, "1972": 16, "1840": 16, "1958": 16, "1937": 16, "1852": 16, "1806": 16, "1865": 16, "1627": 16, "1617": 16, "1657": 16, "1651": 16, "1724": 16, "1635": 16, "1608": 16, "1646": 16, "1633": 16, "1641": 16, "1642": 16, "1636": 16, "1959": 16, "1634": 16, "1640": 16, "1624": 16, "1601": 16, "1609": 16, "1643": 16, "1632": 16, "1638": 16, "1606": 16, "1572": 16, "1576": 16, "1588": 16, "1631": 16, "1597": 16, "1637": 16, "1590": 16, "1591": 16, "1622": 16, "1570": 16, "1652": 16, "1612": 16, "1610": 16, "1566": 16, "1564": 16, "1552": 16, "1611": 16, "1574": 16, "1579": 16, "1583": 16, "1563": 16, "1604": 16, "1543": 16, "1602": 16, "1585": 16, "1553": 16, "1607": 16, "1603": 16, "1598": 16, "1561": 16, "1536": 16, "1615": 16, "1653": 16, "1587": 16, "1592": 16, "1620": 16, "1577": 16, "1578": 16, "1551": 16, "1586": 16, "1532": 16, "1573": 16, "1582": 16, "1565": 16, "1516": 16, "1537": 16, "1596": 16, "1531": 16, "1526": 16, "1557": 16, "1491": 16, "1497": 16, "1562": 16, "1554": 16, "1515": 16, "1504": 16, "1482": 16, "1533": 16, "1520": 16, "1547": 16, "1503": 16, "1535": 16, "1517": 16, "1550": 16, "1513": 16, "1528": 16, "1541": 16, "1509": 16, "1519": 16, "1508": 16, "1584": 16, "1518": 16, "1512": 16, "1567": 16, "1618": 16, "1656": 16, "1605": 16, "1594": 16, "1514": 16, "1558": 16, "1464": 16, "1500": [16, 25], "1530": 16, "1539": 16, "1493": 16, "1471": 16, "1487": 16, "1488": 16, "1499": 16, "1495": 16, "1522": 16, "1556": 16, "1455": 16, "1599": 16, "1505": 16, "1521": 16, "1501": 16, "1492": 16, "1461": 16, "1548": 16, "1498": 16, "1529": 16, "1460": 16, "1445": 16, "1450": 16, "1414": 16, "1559": 16, "1496": 16, "4887": 16, "6159": 16, "5300": 16, "4991": 16, "4763": 16, "4761": 16, "4651": 16, "4366": 16, "4115": 16, "4421": 16, "4607": 16, "4457": 16, "4180": 16, "3981": 16, "3689": 16, "3560": 16, "4461": 16, "4211": 16, "4046": 16, "3446": 16, "3379": 16, "3303": 16, "3230": 16, "3333": 16, "3151": 16, "3105": 16, "3330": 16, "3114": 16, "3034": 16, "3687": 16, "3205": 16, "3175": 16, "3176": 16, "2945": 16, "3038": 16, "3079": 16, "3161": 16, "3109": 16, "3183": 16, "2994": 16, "3003": 16, "3084": 16, "3209": 16, "2936": 16, "2986": 16, "3233": 16, "3035": 16, "3108": 16, "3007": 16, "2822": 16, "3095": 16, "2903": 16, "2827": 16, "3167": 16, "2846": 16, "3049": 16, "3257": 16, "2916": 16, "3189": 16, "2951": 16, "3002": 16, "3384": 16, "2800": 16, "2805": 16, "2771": 16, "2853": 16, "2788": 16, "2871": 16, "2790": 16, "2960": 16, "2729": 16, "2967": 16, "3043": 16, "2981": 16, "2808": 16, "2722": 16, "2721": 16, "2803": 16, "2898": 16, "2991": 16, "2872": 16, "2926": 16, "2694": 16, "2795": 16, "3005": 16, "2835": 16, "2709": 16, "2765": 16, "2873": 16, "3138": 16, "2971": 16, "2687": 16, "2962": 16, "2732": 16, "2779": 16, "2684": 16, "2700": [16, 50], "2724": 16, "2769": 16, "2847": 16, "2696": 16, "2718": 16, "2793": 16, "2713": 16, "2727": 16, "2656": 16, "2780": 16, "2863": 16, "2836": 16, "2751": 16, "2735": 16, "2831": 16, "2756": 16, "2754": 16, "2655": 16, "2590": 16, "2796": 16, "2658": 16, "2601": 16, "2806": 16, "2837": 16, "2661": 16, "2565": 16, "2663": 16, "2869": 16, "2567": 16, "2627": 16, "2783": 16, "2639": 16, "2750": 16, "2544": 16, "2743": 16, "2641": 16, "2676": 16, "2561": 16, "2634": 16, "2984": 16, "2652": 16, "2517": 16, "2660": 16, "2635": 16, "2600": 16, "2638": 16, "2654": 16, "2613": 16, "2633": 16, "2562": 16, "2620": 16, "2624": 16, "2482": 16, "2564": 16, "2612": 16, "2889": 16, "2680": 16, "2667": 16, "2484": 16, "2593": 16, "2573": 16, "2707": 16, "2673": 16, "2518": 16, "2584": 16, "2528": 16, "2575": 16, "2596": 16, "2605": 16, "2526": 16, "2695": 16, "2602": 16, "2919": 16, "2728": 16, "2527": 16, "2540": 16, "2679": 16, "2653": 16, "2496": 16, "2681": 16, "2748": 16, "2691": 16, "2595": 16, "2488": 16, "2693": 16, "2487": 16, "2879": 16, "2592": 16, "2568": 16, "2578": 16, "2585": 16, "2594": 16, "2434": 16, "2623": 16, "2675": 16, "2444": 16, "2785": 16, "2503": 16, "2636": 16, "2736": 16, "2964": 16, "2774": 16, "2554": 16, "2507": 16, "2486": 16, "2906": 16, "2615": 16, "2479": 16, "2625": 16, "2469": 16, "2454": 16, "2682": 16, "2556": 16, "2563": 16, "2738": 16, "2753": 16, "2483": 16, "2725": 16, "2609": [16, 50], "2632": 16, "2413": 16, "2631": 16, "2671": 16, "2726": 16, "2537": 16, "2699": 16, "2456": 16, "2887": 16, "2854": 16, "2674": 16, "2514": 16, "2513": 16, "2746": 16, "2364": 16, "2547": 16, "2383": 16, "2511": 16, "2466": 16, "2559": 16, "2464": 16, "2670": 16, "2617": 16, "2426": 16, "2408": 16, "2495": 16, "2407": 16, "2553": 16, "2450": 16, "2358": 16, "2492": 16, "2510": 16, "2410": 16, "2705": 16, "2525": 16, "2586": 16, "2545": 16, "2499": 16, "2672": 16, "2391": 16, "2473": 16, "2449": 16, "2405": 16, "2400": 16, "2378": 16, "2360": 16, "2445": 16, "2462": 16, "2455": [16, 50], "2678": 16, "2458": 16, "2448": 16, "2629": 16, "2611": 16, "2939": 16, "2452": 16, "2363": 16, "2472": 16, "2387": 16, "2385": 16, "2420": 16, "2382": 16, "2577": 16, "2335": 16, "2558": 16, "2403": 16, "2397": 16, "2380": 16, "2531": 16, "2474": 16, "2443": 16, "2402": 16, "2610": 16, "2524": 16, "2309": 16, "2316": 16, "2349": 16, "2417": 16, "2423": 16, "2414": 16, "2281": 16, "2626": 16, "2327": 16, "2332": 16, "2843": 16, "2692": 16, "2460": 16, "2337": 16, "2344": 16, "2491": 16, "2367": 16, "2357": 16, "2572": 16, "2541": 16, "2463": 16, "2651": 16, "2532": 16, "2399": 16, "2438": 16, "2343": 16, "2389": 16, "2409": 16, "2248": 16, "2315": 16, "2582": 16, "2552": 16, "2392": 16, "2296": 16, "2342": 16, "2471": 16, "2418": 16, "2442": 16, "2277": 16, "2395": 16, "2603": 16, "2301": 16, "2313": 16, "2329": 16, "2245": 16, "2322": 16, "2333": 16, "2522": 16, "2820": 16, "2668": 16, "2390": 16, "2642": 16, "2433": 16, "2302": 16, "2481": 16, "2356": 16, "2379": 16, "2352": 16, "2253": 16, "2476": 16, "2331": 16, "2347": 16, "2320": 16, "2425": 16, "2644": 16, "2270": 16, "2334": 16, "2384": 16, "2365": 16, "2362": 16, "2305": 16, "2348": 16, "2377": 16, "2212": 16, "2265": 16, "2351": 16, "2447": 16, "2542": 16, "2308": 16, "2376": 16, "2243": 16, "2318": 16, "2226": 16, "2273": 16, "2282": 16, "2276": 16, "2293": 16, "2249": 16, "2279": 16, "2225": 16, "2200": 16, "2195": 16, "2239": 16, "2419": 16, "2251": 16, "2223": 16, "2268": 16, "2284": 16, "2242": 16, "2416": 16, "2303": 16, "2381": 16, "2340": 16, "2275": 16, "2266": 16, "2236": 16, "2431": 16, "2319": 16, "2523": 16, "2374": 16, "2207": 16, "2415": 16, "2480": 16, "2393": 16, "2290": 16, "2240": 16, "2441": 16, "2213": 16, "2294": 16, "2169": 16, "2183": 16, "2162": 16, "2203": 16, "2263": 16, "2299": 16, "2186": 16, "2222": 16, "2350": 16, "2178": 16, "2286": 16, "2238": 16, "2211": 16, "2166": 16, "2295": 16, "2291": 16, "2172": 16, "2210": 16, "2229": 16, "2339": 16, "2136": 16, "2388": 16, "2241": 16, "2247": 16, "2097": 16, "2256": 16, "2231": 16, "2170": 16, "2233": 16, "2369": 16, "2436": 16, "2192": 16, "2190": 16, "2323": 16, "2157": 16, "2259": 16, "2123": 16, "2375": 16, "2285": 16, "3029": 16, "9929": [16, 23], "8433": 16, "7880": 16, "7536": 16, "7371": 16, "7107": 16, "6678": 16, "6252": 16, "6112": 16, "6137": 16, "6009": 16, "6011": 16, "5670": 16, "6132": 16, "5749": 16, "5784": 16, "5563": 16, "5225": 16, "5401": 16, "5363": 16, "5324": 16, "5579": 16, "6280": 16, "5199": 16, "4948": 16, "5123": 16, "5159": 16, "5261": 16, "5373": 16, "5253": 16, "5117": 16, "4785": 16, "4753": 16, "4653": 16, "4723": 16, "4891": 16, "4732": 16, "4861": 16, "4719": 16, "4829": 16, "4672": 16, "4401": 16, "4549": 16, "4341": 16, "4406": 16, "4350": 16, "4590": 16, "4822": 16, "4671": 16, "4562": 16, "4492": 16, "4325": 16, "4285": 16, "4278": 16, "4370": 16, "4308": 16, "4205": 16, "4198": 16, "4399": 16, "4173": 16, "4231": 16, "4440": 16, "4192": 16, "4298": 16, "4079": 16, "4279": 16, "3996": 16, "3867": 16, "3779": 16, "4175": 16, "4077": 16, "3857": 16, "3677": 16, "4203": 16, "3973": 16, "3845": 16, "3824": 16, "3907": 16, "4135": 16, "4511": 16, "3951": 16, "3796": 16, "3678": 16, "3692": 16, "3816": 16, "3767": 16, "3855": 16, "3661": 16, "3872": 16, "3924": 16, "3909": 16, "3759": 16, "3585": 16, "3813": 16, "3649": 16, "3640": 16, "3485": 16, "3803": 16, "3544": 16, "3660": 16, "3902": 16, "3820": 16, "3766": 16, "3955": 16, "3758": 16, "3442": 16, "3438": 16, "3652": 16, "3450": 16, "3720": 16, "3385": 16, "3728": 16, "3580": 16, "3596": 16, "3612": 16, "3602": 16, "3358": 16, "3414": 16, "3365": 16, "3468": 16, "3313": 16, "3412": 16, "3556": 16, "3462": 16, "3388": 16, "4042": 16, "3634": 16, "3341": 16, "3346": 16, "3432": 16, "3320": 16, "3418": 16, "3284": 16, "3451": 16, "3696": 16, "3327": 16, "3311": 16, "3295": 16, "3404": 16, "3817": 16, "3372": 16, "3265": 16, "3181": 16, "3202": 16, "3239": 16, "3312": 16, "3254": 16, "3197": 16, "3371": 16, "3258": 16, "3119": 16, "3160": 16, "3173": 16, "3273": 16, "3224": 16, "3210": 16, "3467": 16, "3143": 16, "3217": 16, "3200": 16, "3192": 16, "3179": 16, "3344": 16, "3136": 16, "3193": 16, "3120": 16, "3234": 16, "3262": 16, "3170": 16, "3187": 16, "3096": 16, "3101": 16, "3094": 16, "3168": 16, "3326": 16, "3229": 16, "3146": 16, "3090": 16, "3129": 16, "3163": 16, "3125": 16, "3132": 16, "3145": 16, "3349": 16, "3165": 16, "3275": 16, "3068": 16, "3195": 16, "3431": 16, "3148": 16, "3069": 16, "3062": 16, "3055": 16, "3063": 16, "3191": 16, "3133": 16, "3118": 16, "3383": 16, "3302": 16, "3083": [16, 50], "3117": 16, "3085": 16, "3289": 16, "3106": 16, "3087": 16, "3072": 16, "3020": 16, "3237": 16, "3158": 16, "3216": 16, "3171": 16, "3147": 16, "3166": 16, "3134": 16, "3405": 16, "3157": 16, "3059": 16, "3127": 16, "3047": 16, "3169": 16, "3098": 16, "3041": 16, "3023": 16, "3306": 16, "3144": 16, "3028": 16, "3128": 16, "3036": 16, "2980": 16, "3243": 16, "3048": 16, "3031": 16, "3221": 16, "2998": 16, "3077": 16, "3022": 16, "3124": 16, "3180": 16, "2988": 16, "3011": 16, "3172": 16, "3107": 16, "2985": 16, "2946": 16, "3033": 16, "2954": 16, "3015": 16, "2957": 16, "3070": 16, "3121": 16, "3336": 16, "3204": 16, "3091": 16, "3226": 16, "3058": 16, "3274": 16, "3044": 16, "2970": 16, "2993": 16, "2922": 16, "2914": 16, "3024": 16, "3074": 16, "3123": 16, "3039": 16, "3194": 16, "3001": 16, "2973": 16, "2899": 16, "2931": 16, "3086": 16, "3075": 16, "2965": 16, "3137": 16, "3082": 16, "2938": 16, "2975": 16, "3131": 16, "3182": 16, "2890": 16, "3149": 16, "3099": 16, "2911": 16, "2859": 16, "3012": 16, "3089": 16, "3103": 16, "3206": 16, "3102": 16, "3004": 16, "2979": 16, "2924": 16, "2917": 16, "3073": 16, "2949": 16, "3042": 16, "2905": 16, "2891": 16, "2982": 16, "2915": 16, "3395": 16, "3112": 16, "2862": 16, "2934": 16, "3051": 16, "2940": 16, "2996": 16, "2956": 16, "3045": 16, "2943": 16, "2978": 16, "2959": 16, "2968": 16, "2944": 16, "2955": 16, "2958": 16, "2976": 16, "3190": 16, "2935": 16, "2830": 16, "3067": 16, "3335": 16, "2923": 16, "3025": 16, "3009": 16, "3046": 16, "2987": 16, "3019": 16, "3050": 16, "3130": 16, "3245": 16, "3008": 16, "3366": 16, "3078": 16, "2834": 16, "3100": 16, "3139": 16, "2937": [16, 50], "2948": 16, "3027": 16, "2900": 16, "2883": 16, "3232": 16, "3264": 16, "2912": 16, "2908": 16, "3391": 16, "2797": 16, "2839": 16, "2877": 16, "2821": 16, "2999": 16, "3538": 16, "2894": 16, "2950": 16, "3185": 16, "2876": 16, "2885": 16, "2857": 16, "2989": 16, "2895": 16, "2840": 16, "3037": 16, "3152": 16, "2866": 16, "3153": 16, "2812": 16, "2802": 16, "3207": 16, "3251": 16, "2823": 16, "2778": 16, "2865": 16, "3246": 16, "2983": 16, "2804": [16, 50], "3328": 16, "3227": 16, "3623": 16, "3255": 16, "2925": [16, 50], "2855": 16, "2801": 16, "2881": 16, "3140": 16, "3104": [16, 26], "2850": 16, "2966": 16, "3066": 16, "2828": 16, "2810": 16, "2752": 16, "3142": 16, "2829": 16, "2819": 16, "2868": 16, "3016": 16, "2972": 16, "2907": 16, "3021": 16, "3155": 16, "2852": 16, "2763": 16, "2858": 16, "2777": 16, "2745": 16, "2856": 16, "2904": 16, "2952": 16, "3030": 16, "6833": 16, "0731": 16, "9907": 16, "9480": 16, "9363": 16, "8857": 16, "8156": 16, "7781": 16, "7658": 16, "7665": 16, "7486": 16, "7418": 16, "7066": 16, "7251": 16, "7118": 16, "7096": 16, "6862": 16, "6676": 16, "6589": 16, "6815": 16, "6695": 16, "6469": 16, "6573": 16, "7559": 16, "6332": 16, "6171": 16, "6046": 16, "6245": 16, "6138": 16, "6378": 16, "6188": 16, "6609": 16, "6587": 16, "6282": 16, "5878": 16, "5705": 16, "5768": 16, "5892": 16, "5575": 16, "5815": 16, "5930": 16, "5921": 16, "5793": 16, "5428": 16, "5718": 16, "5572": 16, "5398": 16, "5474": 16, "5298": 16, "5358": 16, "5206": 16, "5577": 16, "5207": 16, "5387": 16, "5452": 16, "5715": 16, "5423": 16, "5137": 16, "5286": 16, "5152": 16, "5087": 16, "5046": 16, "5054": 16, "5075": 16, "4994": 16, "4990": 16, "4936": 16, "4913": 16, "5040": 16, "4984": 16, "5025": 16, "5214": 16, "5492": 16, "5427": 16, "4850": 16, "4701": 16, "4800": 16, "4764": 16, "5024": 16, "4932": 16, "4790": 16, "4675": 16, "4867": 16, "4786": 16, "4648": 16, "4594": 16, "4748": 16, "4674": 16, "4644": 16, "4918": 16, "4890": 16, "4837": 16, "4679": 16, "4611": 16, "5015": 16, "4619": 16, "4631": 16, "4570": 16, "4484": 16, "4437": 16, "4412": 16, "4397": 16, "4498": 16, "4729": 16, "4633": 16, "4572": 16, "4637": 16, "4878": 16, "4727": 16, "4443": 16, "4442": 16, "4486": 16, "4718": 16, "4376": 16, "4273": 16, "4512": 16, "4458": 16, "4567": 16, "4510": 16, "4523": 16, "4632": 16, "4445": 16, "4293": 16, "4528": 16, "4282": 16, "4272": 16, "4712": 16, "4223": 16, "4212": 16, "4222": 16, "4262": 16, "4304": 16, "4283": 16, "4475": 16, "4155": 16, "4685": 16, "4743": 16, "4517": 16, "4378": 16, "4403": 16, "4219": 16, "4462": 16, "4400": 16, "4150": 16, "4090": 16, "4143": 16, "4018": 16, "4258": 16, "4186": 16, "4047": 16, "3990": 16, "3965": 16, "4085": 16, "3972": 16, "4638": 16, "4349": 16, "4181": 16, "4402": 16, "4352": 16, "4110": 16, "4062": 16, "3970": 16, "4177": 16, "4025": 16, "4103": 16, "4064": 16, "4357": 16, "4695": 16, "4031": 16, "3921": 16, "3898": 16, "4240": 16, "4148": 16, "3937": 16, "3967": 16, "4092": 16, "4170": 16, "3849": 16, "3901": 16, "4171": 16, "4139": 16, "4082": 16, "3862": 16, "3929": 16, "4006": 16, "3875": 16, "4683": 16, "4416": 16, "4051": 16, "4056": 16, "3850": 16, "3856": 16, "3944": 16, "3852": 16, "3848": 16, "3844": 16, "4071": 16, "3769": 16, "3866": 16, "3943": 16, "3861": 16, "3952": 16, "4127": 16, "3886": 16, "3913": 16, "3864": 16, "3703": 16, "3827": 16, "3809": 16, "3744": 16, "3701": 16, "3833": 16, "4095": 16, "3739": 16, "3923": 16, "3680": 16, "3700": 16, "3900": 16, "3750": 16, "3606": 16, "3622": 16, "4017": 16, "3754": 16, "3899": 16, "4105": 16, "4582": 16, "3699": 16, "3679": 16, "3988": 16, "3752": 16, "4060": 16, "3663": 16, "3716": 16, "3627": 16, "3781": 16, "3577": 16, "3647": 16, "3846": 16, "3575": 16, "3949": 16, "3646": 16, "3859": 16, "3745": 16, "3666": 16, "3588": 16, "3665": 16, "3555": 16, "3469": 16, "3526": 16, "3747": 16, "4012": 16, "3839": 16, "3708": 16, "3490": 16, "3671": 16, "3925": 16, "3417": 16, "3710": 16, "3968": 16, "3370": 16, "3394": 16, "3829": 16, "3821": 16, "3387": 16, "3433": 16, "3397": 16, "3579": 16, "3905": 16, "3235": 16, "3290": 16, "3437": 16, "3310": 16, "3244": 16, "3214": 16, "3986": 16, "3959": 16, "3198": 16, "3481": 16, "3569": 16, "3553": 16, "3212": 16, "3695": 16, "3639": 16, "3380": 16, "3508": 16, "4271": 16, "3261": 16, "3249": 16, "3314": 16, "3325": 16, "3502": 16, "3252": 16, "4199": 16, "3498": 16, "3375": 16, "3271": 16, "4084": 16, "3338": 16, "3353": 16, "3135": 16, "3305": 16, "7673": 16, "0016": 16, "9683": 16, "9504": 16, "9524": 16, "9500": 16, "9075": 16, "8961": 16, "8946": 16, "8974": 16, "8728": 16, "8463": 16, "8204": 16, "8321": 16, "8348": 16, "7978": 16, "8064": 16, "9342": 16, "8211": 16, "7755": 16, "7600": 16, "7868": 16, "7830": 16, "7856": 16, "7800": 16, "7882": 16, "7801": 16, "7287": 16, "7261": 16, "7039": 16, "7075": 16, "7193": 16, "7282": 16, "6996": 16, "7192": 16, "7187": 16, "7053": 16, "6948": 16, "6840": 16, "7291": 16, "6932": 16, "6735": 16, "6519": 16, "6518": 16, "6390": 16, "6783": 16, "6402": 16, "6405": 16, "6299": 16, "6480": 16, "6389": 16, "6844": 16, "6454": 16, "6270": 16, "6366": 16, "6236": 16, "6371": 16, "6222": 16, "6146": 16, "6082": 16, "6147": 16, "6117": 16, "6084": 16, "6092": 16, "6094": 16, "6126": 16, "6040": 16, "6133": 16, "6300": 16, "6068": 16, "6239": 16, "6064": 16, "5895": 16, "5818": 16, "5913": 16, "5868": 16, "6109": 16, "5764": 16, "5730": 16, "5754": 16, "5625": 16, "5611": 16, "5659": 16, "5567": 16, "5676": 16, "5687": 16, "5978": 16, "5910": 16, "5811": 16, "5651": 16, "6104": 16, "5725": 16, "5698": 16, "5614": 16, "5551": 16, "5539": 16, "5501": 16, "5429": 16, "5430": 16, "5422": 16, "5442": 16, "5777": 16, "5710": 16, "5637": 16, "5547": 16, "5517": 16, "5536": 16, "5413": 16, "5441": 16, "5283": 16, "5392": 16, "5473": 16, "5317": 16, "5325": 16, "5271": 16, "5412": 16, "5121": 16, "5440": 16, "5316": 16, "5315": 16, "5231": 16, "5339": 16, "5477": 16, "5526": 16, "5221": 16, "5245": 16, "5446": 16, "5251": 16, "5246": 16, "5433": 16, "5319": 16, "5268": 16, "5142": 16, "5240": 16, "5151": 16, "5228": 16, "5165": 16, "5224": 16, "5168": 16, "5120": 16, "5204": 16, "5509": 16, "5090": 16, "5220": 16, "5481": 16, "5321": 16, "5145": 16, "5157": 16, "5067": 16, "5133": 16, "4920": 16, "5140": 16, "5034": 16, "5260": 16, "5079": 16, "4972": 16, "4897": 16, "5047": 16, "5136": 16, "4979": 16, "4941": 16, "4839": 16, "4993": 16, "5013": 16, "4866": 16, "4781": 16, "4782": 16, "4815": 16, "4885": 16, "4851": 16, "5004": 16, "4760": 16, "4938": 16, "4986": 16, "5147": 16, "4868": 16, "4768": 16, "4778": [16, 50], "4962": 16, "4872": 16, "4827": 16, "4634": 16, "4772": 16, "4859": 16, "4898": 16, "4762": 16, "5080": 16, "5122": 16, "4841": 16, "4845": 16, "5012": 16, "5028": 16, "5129": 16, "4769": 16, "4821": 16, "4804": 16, "5055": 16, "5058": 16, "4825": 16, "4596": 16, "4687": 16, "4737": 16, "4740": 16, "4754": 16, "4668": 16, "5030": 16, "4835": 16, "4646": 16, "4846": 16, "4620": 16, "4765": 16, "4625": 16, "4722": 16, "5219": 16, "4987": 16, "4643": 16, "4906": 16, "4997": 16, "4965": 16, "4502": 16, "4831": 16, "4564": 16, "4576": 16, "4575": 16, "4813": 16, "4504": 16, "4533": 16, "4667": 16, "4691": 16, "4670": 16, "4534": 16, "4645": 16, "4711": 16, "4496": 16, "4710": 16, "4771": 16, "4555": 16, "4483": 16, "4747": 16, "4580": 16, "4420": 16, "4358": 16, "4479": 16, "4500": 16, "4424": 16, "4383": 16, "4381": 16, "4733": 16, "5019": 16, "4697": 16, "4579": 16, "4432": 16, "4404": 16, "4418": 16, "4917": 16, "4656": 16, "4601": 16, "4738": 16, "4287": 16, "4270": 16, "4243": 16, "4407": 16, "4658": 16, "4713": 16, "4444": 16, "4326": 16, "4509": 16, "4547": 16, "4893": 16, "4384": 16, "4330": 16, "4365": 16, "4385": 16, "4615": 16, "4185": 16, "4252": 16, "4946": 16, "4597": 16, "4478": 16, "4379": 16, "4361": 16, "4257": 16, "4339": 16, "4364": 16, "4726": 16, "4503": 16, "4217": 16, "4301": 16, "4372": 16, "4187": 16, "4314": 16, "4578": 16, "4202": 16, "4094": 16, "4122": 16, "4146": 16, "4176": 16, "4254": 16, "4266": 16, "4151": 16, "4197": 16, "4438": 16, "4072": 16, "5m": 16, "4689": 16, "4488": 16, "4106": 16, "4589": 16, "4453": 16, "4091": 16, "4065": 16, "4224": 16, "4290": 16, "4647": 16, "4229": 16, "4145": 16, "4521": 16, "4735": 16, "4337": 16, "4605": 16, "4435": 16, "4305": 16, "4635": 16, "4035": 16, "3948": 16, "4074": 16, "4128": 16, "3983": 16, "4207": 16, "4362": 16, "4050": 16, "4447": 16, "4303": 16, "4075": 16, "4297": 16, "4195": 16, "4409": 16, "4895": 16, "4390": 16, "3958": 16, "3997": 16, "4019": 16, "4425": 16, "4539": 16, "4204": 16, "4120": 16, "4159": 16, "4826": 16, "3979": 16, "4081": 16, "4111": 16, "4452": 16, "4275": 16, "4059": 16, "3815": 16, "4048": 16, "3811": 16, "3960": 16, "4288": 16, "4345": 16, "4220": 16, "4076": 16, "4375": 16, "4320": 16, "5052": 16, "3904": 16, "4189": 16, "4069": 16, "3887": 16, "3916": 16, "4167": 16, "4429": 16, "4494": 16, "4014": 16, "3785": 16, "3906": 16, "3896": 16, "3928": 16, "4057": 16, "3840": 16, "4237": 16, "3770": 16, "4123": 16, "3941": 16, "4190": 16, "4650": 16, "4335": 16, "4052": 16, "4144": 16, "4641": 16, "4016": 16, "4226": 16, "4368": 16, "4577": 16, "3895": 16, "4157": 16, "4174": 16, "4294": 16, "3871": 16, "3711": 16, "4380": 16, "3657": 16, "3977": 16, "4259": 16, "4538": 16, "3775": 16, "3798": 16, "4551": 16, "4149": 16, "3828": 16, "3726": 16, "4117": 16, "4137": 16, "3847": 16, "4013": 16, "4526": 16, "3914": 16, "3982": 16, "3851": 16, "3831": 16, "3675": 16, "4015": 16, "3636": 16, "3835": 16, "8240": 16, "2941": 16, "6617": 16, "5529": 16, "4126": 16, "3823": 16, "1076": 16, "0964": 16, "0697": 16, "0372": 16, "0143": 16, "9934": 16, "9875": 16, "9638": 16, "9312": 16, "0507": 16, "9802": 16, "9319": 16, "8973": 16, "9171": 16, "9031": 16, "9235": 16, "8815": 16, "8816": 16, "8773": 16, "8623": 16, "8511": 16, "8529": 16, "8421": 16, "8842": 16, "8582": 16, "8142": 16, "8262": 16, "8449": 16, "8335": 16, "8717": 16, "8457": 16, "8543": 16, "8180": 16, "7972": 16, "7949": 16, "7942": 16, "7766": 16, "7629": 16, "8018": 16, "7752": 16, "7784": 16, "7531": 16, "7732": 16, "7617": 16, "8013": 16, "7902": 16, "7824": 16, "7560": 16, "7429": 16, "7496": 16, "7481": 16, "7445": 16, "7267": 16, "7464": 16, "7317": 16, "7238": 16, "7240": 16, "7393": 16, "7151": 16, "7296": 16, "7194": 16, "7079": 16, "7165": 16, "7136": 16, "7057": 16, "7064": 16, "6878": 16, "6923": 16, "6891": 16, "6944": 16, "6866": 16, "7030": 16, "6955": 16, "6906": 16, "6777": 16, "6716": 16, "6764": 16, "6624": 16, "6602": 16, "6746": 16, "7013": 16, "6920": 16, "6594": 16, "6660": 16, "6576": 16, "7019": 16, "7179": 16, "6857": 16, "6916": 16, "6818": 16, "6770": 16, "6666": 16, "6476": 16, "6423": 16, "6374": 16, "6376": 16, "6437": 16, "6745": 16, "6791": 16, "6592": 16, "6358": 16, "6411": 16, "6409": 16, "6261": 16, "6329": 16, "6430": 16, "6203": 16, "6177": 16, "6144": 16, "6298": 16, "6359": 16, "6049": 16, "6333": 16, "6214": 16, "6172": 16, "6090": 16, "6361": 16, "6228": 16, "6284": 16, "6560": 16, "6105": 16, "6155": 16, "6563": 16, "6206": 16, "6107": 16, "5987": 16, "6050": 16, "5992": 16, "5925": 16, "5953": 16, "5899": 16, "5960": 16, "5963": 16, "6052": 16, "6213": 16, "6517": 16, "6613": 16, "5941": 16, "5938": 16, "6148": 16, "6169": 16, "6042": 16, "6015": 16, "5850": 16, "5979": 16, "5919": 16, "5865": 16, "5903": 16, "5936": 16, "5742": 16, "5849": 16, "5820": 16, "5750": 16, "5998": 16, "5778": 16, "5776": 16, "5760": 16, "5767": 16, "5964": 16, "5766": 16, "5787": 16, "5706": 16, "5642": 16, "5839": 16, "5801": 16, "5664": 16, "5593": 16, "5601": 16, "5562": 16, "5592": 16, "5657": 16, "5633": 16, "5573": 16, "6330": 16, "5756": 16, "5743": 16, "5912": 16, "5682": 16, "5552": 16, "5513": 16, "5765": 16, "5582": 16, "5613": 16, "5630": 16, "5490": 16, "5616": 16, "5407": 16, "5426": 16, "5774": 16, "6289": 16, "6246": 16, "6114": 16, "5505": 16, "5558": 16, "5640": 16, "5807": [16, 50], "5607": 16, "5305": 16, "5389": 16, "5349": 16, "5480": 16, "5265": 16, "5461": 16, "5600": 16, "5605": 16, "5376": 16, "5612": 16, "5493": 16, "5328": 16, "5379": 16, "5341": 16, "5596": 16, "5894": 16, "5886": 16, "5514": 16, "5542": 16, "5488": 16, "5537": 16, "5158": 16, "5175": 16, "5335": 16, "5297": 16, "5438": 16, "5211": 16, "5301": 16, "5242": 16, "5581": 16, "5602": 16, "5229": 16, "5244": 16, "5264": 16, "5609": 16, "5308": 16, "5233": 16, "5243": 16, "5256": 16, "5166": 16, "5176": 16, "5311": 16, "5326": 16, "5327": 16, "5149": 16, "5062": 16, "5167": 16, "5128": 16, "5197": 16, "5031": 16, "5038": 16, "5014": 16, "5330": 16, "5399": 16, "5837": 16, "5624": 16, "5508": 16, "5066": 16, "5103": 16, "5294": 16, "5344": 16, "5519": 16, "5338": 16, "4924": 16, "4912": 16, "4919": 16, "4882": 16, "4927": 16, "5200": 16, "5069": 16, "5078": 16, "5059": 16, "4981": 16, "4945": 16, "4901": 16, "5085": 16, "5091": 16, "5016": 16, "5009": 16, "5345": 16, "4916": 16, "4995": 16, "4880": 16, "4875": 16, "4973": 16, "4983": 16, "4931": 16, "4857": 16, "5029": 16, "4865": 16, "5074": 16, "5396": 16, "5307": 16, "4899": 16, "4963": 16, "5063": 16, "4968": 16, "4818": 16, "4820": 16, "5112": 16, "4922": 16, "4894": 16, "4871": 16, "5102": 16, "4744": 16, "4824": 16, "4802": 16, "4928": 16, "4960": 16, "4728": 16, "4741": 16, "5050": 16, "4834": 16, "4844": 16, "4811": 16, "4876": 16, "4849": 16, "4659": 16, "4843": 16, "4955": 16, "4792": 16, "4975": 16, "5037": 16, "5104": 16, "4688": 16, "4700": 16, "5044": 16, "5010": 16, "4604": 16, "4600": 16, "4704": 16, "4734": 16, "4810": 16, "5280": 16, "4852": 16, "4716": 16, "5223": 16, "4745": 16, "5035": 16, "5107": 16, "5189": 16, "4660": 16, "5081": 16, "4698": 16, "4998": 16, "4666": 16, "4664": 16, "4773": 16, "5681": 16, "4930": 16, "4552": 16, "4649": 16, "5127": 16, "4980": 16, "5039": 16, "5173": 16, "4757": 16, "4569": 16, "4640": 16, "4801": 16, "4854": 16, "4746": 16, "4856": 16, "4507": 16, "4873": 16, "4694": 16, "4654": 16, "4593": 16, "4417": 16, "4472": 16, "4598": 16, "4789": 16, "4522": 16, "4681": 16, "4750": 16, "4524": 16, "4767": 16, "4426": 16, "4448": 16, "4586": 16, "4613": 16, "4621": 16, "4471": 16, "5203": 16, "4563": 16, "4847": 16, "4794": 16, "4588": 16, "4756": 16, "4629": 16, "4466": 16, "4427": 16, "4749": 16, "4422": 16, "4395": 16, "4469": 16, "4957": 16, "4487": 16, "4537": 16, "5116": 16, "4663": 16, "4519": [16, 19, 25], "4559": 16, "4516": 16, "4514": 16, "4976": 16, "4299": 16, "4439": 16, "4430": 16, "4699": 16, "4661": 16, "4525": 16, "4363": 16, "4520": 16, "4310": 16, "4911": 16, "4413": 16, "4540": 16, "4527": 16, "4560": 16, "4387": 16, "4333": 16, "4322": 16, "4513": 16, "4677": 16, "4481": 16, "4505": 16, "4474": 16, "4833": 16, "4501": 16, "4292": 16, "4311": [16, 50], "4394": 16, "4449": 16, "4248": 16, "5218": 16, "4587": 16, "4657": 16, "4234": 16, "4783": 16, "4373": 16, "4585": 16, "4573": 16, "4274": 16, "4313": 16, "4356": 16, "4717": 16, "4218": 16, "4860": 16, "5388": 16, "5497": 16, "4788": 16, "4141": 16, "4518": 16, "4227": 16, "4707": 16, "4490": 16, "4342": 16, "4351": 16, "4410": 16, "4515": 16, "4477": 16, "4319": 16, "4269": 16, "4179": 16, "4100": 16, "4344": 16, "4485": 16, "4140": 16, "4296": 16, "4253": 16, "4129": 16, "4617": 16, "4489": 16, "4879": 16, "4154": 16, "4249": 16, "4441": 16, "4108": 16, "4277": 16, "5126": 16, "4276": 16, "4125": 16, "4121": 16, "4241": 16, "4044": 16, "4242": 16, "4581": 16, "plot_iter": 16, "seem": [16, 28], "plt_compar": 16, "howev": [16, 19, 29, 36, 38, 48, 51, 52], "tool": [16, 27], "untrain": 16, "differenti": 16, "insight": 16, "propens": 16, "toward": [16, 23, 52], "scratch": 17, "whether": [17, 18, 19, 33, 34, 52], "mushroom": 17, "edibl": 17, "poison": 17, "refresh": [17, 25], "matric": [17, 18, 25, 26, 33, 34, 39, 44, 45, 49, 50], "famou": [17, 19, 25, 33, 34, 49], "helper": [17, 18, 19, 25, 33, 34, 37, 39, 40, 44, 45, 49, 52], "suppos": [17, 18, 19, 25, 33, 34, 37, 50], "compani": 17, "grow": [17, 23], "sell": 17, "wild": 17, "base": [17, 18, 19, 23, 26, 29, 31, 33, 34, 35, 48, 49, 50, 52], "physic": 17, "attribut": [17, 18, 19, 33, 34], "sold": [17, 21, 22, 23, 31], "safe": [17, 52], "illustr": 17, "purpos": [17, 50], "cap": 17, "stalk": 17, "solitari": 17, "brown": 17, "taper": 17, "ye": [17, 19, 35], "enlarg": 17, "eas": 17, "root": 17, "pick": [17, 29], "accord": [17, 50], "branch": 17, "repeat": [17, 18, 19, 23, 25, 27, 28, 33, 34, 40, 43, 46, 50, 51], "stop": [17, 19, 26], "criteria": 17, "maxim": [17, 52], "ve": [17, 18, 19, 33, 34, 37], "chosen": [17, 27, 29, 49], "depth": 17, "compute_entropi": 17, "measur": [17, 19, 22, 23, 38, 51, 52], "impur": 17, "p_1": 17, "h": [17, 18, 19, 25, 33, 34], "sure": [17, 48], "empti": 17, "stuck": [17, 18, 19, 25, 33, 34, 48, 49], "correctli": [17, 18, 19, 25, 26, 33, 34, 48, 49], "p1": 17, "0log0": 17, "log2": 17, "logarithm": 17, "structur": [17, 18, 19, 25, 26, 27, 33, 34, 48, 49, 50, 51, 52], "overal": [17, 18, 19, 25, 33, 34, 48, 49], "formula": [17, 18, 21, 28, 33, 34, 40], "still": [17, 18, 19, 25, 27, 28, 29, 33, 34, 48, 49], "compute_entropy_test": 17, "split_dataset": 17, "node_indic": 17, "chose": 17, "left_indic": 17, "right_indic": 17, "n_featur": 17, "block": [17, 18, 19, 21, 25, 33, 34], "root_indic": 17, "plai": [17, 52], "around": [17, 20, 28, 49], "split_dataset_test": 17, "information_gain": 17, "compute_information_gain": 17, "proport": 17, "respect": [17, 18, 19, 22, 23, 28, 33, 34, 39, 44, 45, 50, 52], "starter": [17, 18, 19, 33, 34, 48], "cost": [17, 27, 28, 29, 33, 34, 38, 40, 48, 50], "x_node": 17, "y_node": 17, "x_left": 17, "y_left": 17, "x_right": 17, "y_right": 17, "node_entropi": 17, "left_entropi": 17, "right_entropi": 17, "w_left": 17, "w_right": 17, "weighted_entropi": 17, "minu": 17, "featu": 17, "info_gain0": 17, "info_gain1": 17, "info_gain2": 17, "compute_information_gain_test": 17, "034851554559677034": 17, "12451124978365313": 17, "2780719051126377": 17, "get_best_split": 17, "best_featur": 17, "num_featur": [17, 50], "max_info_gain": 17, "info_gain": 17, "seen": [17, 19, 28, 37], "far": [17, 19, 23, 29, 35], "get_best_split_test": 17, "success": [17, 23], "build_tree_recurs": 17, "branch_nam": 17, "max_depth": 17, "current_depth": 17, "recurs": 17, "subgroup": 17, "string": [17, 18, 19, 20, 21, 24], "leaf": 17, "child": 17, "cm": [18, 19], "longdoubl": [18, 19, 38], "niter": [18, 19], "10000": [18, 19, 23, 25, 29, 33, 34, 40], "win": [18, 19], "bin": [18, 19], "wx": [18, 19, 21, 22, 23, 25, 31, 38], "meshgrid": [18, 19], "theta": [18, 19, 25, 27, 33, 34, 52], "isscalar": [18, 19], "elif": [18, 19], "isinst": [18, 19], "tupl": [18, 19, 21, 26, 52], "dosn": [18, 19], "exit": [18, 19], "dmodel_w": [18, 19], "dmodel_b": [18, 19], "cf": [18, 19], "dcost_w": [18, 19], "dcost_w_result": [18, 19], "wi": [18, 19], "dcost_b": [18, 19], "compute_gradi": [18, 19, 23, 25, 27, 33, 34], "gradient_dec": [18, 19], "alpha": [18, 19, 23, 25, 27, 29, 33, 34, 37, 40, 43, 46, 52], "constrain": [18, 19], "cost_i": [18, 19], "ab": [18, 19, 25], "dcw": [18, 19], "dcb": [18, 19], "theta_in": [18, 19], "grad_dec_result": [18, 19], "theta_f": [18, 19], "wf": [18, 19], "bf": [18, 19], "yscale": [18, 19], "xlabel": [18, 19, 21, 25, 29, 33, 34, 49], "ylabel": [18, 19, 21, 25, 29, 33, 34, 49], "ylim": [18, 19], "predcit": [18, 19], "tmp": [18, 19], "ipykernel_4320": 18, "3281116716": 18, "runtimewarn": [18, 19], "encount": [18, 19, 21, 25, 27], "33e": 18, "40e": 18, "20e": [18, 28], "21e": 18, "85e": [18, 23], "81e": [18, 28], "51e": [18, 19], "15e": 18, "66e": 18, "68e": [18, 19], "78e": 18, "91e": [18, 19], "74e": [18, 28], "83e": [18, 19], "54e": [18, 19], "08e": 18, "32e": 18, "77e": 18, "64e": 18, "01e": [18, 23], "12e": [18, 28], "09e": [18, 23], "80e": 18, "10e": 18, "16e": 18, "07e": 18, "60e": [18, 23], "56e": 18, "87e": 18, "41e": [18, 23, 28, 30], "17e": [18, 19], "23e": [18, 19], "28e": [18, 23], "45e": 18, "70e": 18, "27e": [18, 27, 28, 29], "96e": 18, "88e": 18, "50e": [18, 28, 30], "36e": 18, "31e": [18, 23, 28], "71e": 18, "65e": 18, "29e": [18, 19], "59e": [18, 19], "37e": [18, 23], "47e": 18, "95e": [18, 23], "89e": [18, 19], "14e": 18, "75e": 18, "52e": 18, "19e": [18, 23], "79e": 18, "04e": 18, "25e": [18, 23], "58e": [18, 23], "67e": 18, "69e": 18, "99e": [18, 49], "57e": 18, "84e": [18, 19, 23, 28], "00e": [18, 19, 28, 30], "11e": 18, "93e": [18, 23], "90e": [18, 23], "43e": [18, 19, 29], "72e": [18, 28], "53e": 18, "13e": [18, 19, 29], "86e": 18, "26e": 18, "48e": [18, 19], "62e": [18, 23], "06e": [18, 28], "24e": 18, "18e": [18, 23, 28], "3499985218344349": 18, "61872511912435": 18, "07": [18, 19, 23, 27, 28, 29, 33], "__array_function__": 18, "kwarg": 18, "dim": [18, 51], "optionallab": [18, 19], "c1w3a1": [18, 19], "plt_overfit": [18, 19, 42, 43, 46], "overfit_exampl": [18, 19, 42, 43, 46], "ex2data2": [18, 19, 33, 34], "txt": [18, 19, 33, 34], "map_featur": [18, 19, 33, 34], "atleast_1d": [18, 19], "dmodel_w_reg": [18, 19], "lam": [18, 19], "cost_reg": [18, 19], "dcost_w_reg": [18, 19], "compute_gradient_reg": [18, 19, 33, 34], "dcw_reg": [18, 19], "ones": [18, 19, 49], "lam_in": [18, 19], "syntaxerror": 18, "never": [18, 19, 25, 33, 34], "initial_w": [18, 19, 25, 27, 33, 34], "3752155572731053": 18, "6618252552483951": 18, "0028840493199764": [18, 19], "ipykernel_6369": 18, "878878066": 18, "9256284847946785": 18, "7321371677849211": 18, "6598208762641768": 18, "6204053236990379": 18, "5947327181536963": [18, 19], "5769735539510019": 18, "5643870236028828": 18, "555336262275471": 18, "5487540462424862": 18, "5439204525169686": [18, 19], "5403404754899873": 18, "537668730905861": 18, "5356611484735105": 18, "5341432903438514": 18, "5329892209020973": [18, 19], "5321071993517749": 18, "5314298559357999": 18, "53090735989295": 18, "5305026126614626": 18, "5301878305603884": [18, 19], "529942092517406": 18, "5297495655369997": 18, "529598210913902": 18, "5294788345282262": 18, "5293843854020753": [18, 19], "5293094346883392": 18, "5292497866608107": 18, "5292021868554273": 18, "5291641021078087": 18, "5291335540683393": [18, 19], "5291089926830363": 18, "5290891996748446": 18, "52907321463902": 18, "5290602782525139": 18, "5290497884840468": [18, 19], "5290412667161044": 18, "5290343314504222": 18, "5290286778351836": 18, "5290240616761656": 18, "5290202869125287": [18, 19], "5290171957780294": 18, "5290146610500187": 18, "5290125799264344": 18, "529010869175946": 18, "5290094612865763": [18, 19], "5290083013995638": 18, "5290073448624335": 18, "5290065552716438": 18, "5290059029033056": 18, "2715618096527268": [18, 19], "5290053880660263": [18, 19], "artist": [18, 19], "put": [18, 19, 52], "underscor": [18, 19], "meshd": 18, "z_plot": [18, 19], "subprocess": [18, 19], "pathlib": [18, 19], "home_path": [18, 19], "supervised_machine_learning_regression_and_classif": [18, 19, 25], "student": [18, 19, 33, 34], "admit": [18, 19, 33, 34], "univers": [18, 19, 33, 34], "administr": [18, 19, 33, 34], "depart": [18, 19, 33, 34, 50], "chanc": [18, 19, 33, 34], "admiss": [18, 19, 33, 34], "exam": [18, 19, 33, 34], "score": [18, 19, 29, 30, 33, 34, 41, 49], "estim": [18, 19, 25, 33, 34, 50, 52], "load_dataset": [18, 19, 33, 34], "ex2data1": [18, 19, 33, 34], "five": [18, 19, 25, 33, 34, 48, 49], "untermin": 18, "liter": 18, "detect": 18, "alwai": [18, 19, 22, 23, 29, 33, 34, 48, 52], "2d": [18, 19, 33, 34, 48, 49], "plot_data": [18, 19, 33, 34, 35, 37, 39, 40, 44, 45], "pos_label": [18, 19, 33, 34], "neg_label": [18, 19, 33, 34], "rest": [18, 19, 33, 34, 51, 52], "doc": [18, 19, 29, 33, 34, 36], "html": [18, 19, 29, 31, 33, 34, 36, 51], "offer": [18, 19, 33, 34, 36, 50], "convini": [18, 19, 33, 34], "exactli": [18, 19, 33, 34, 52], "mention": [18, 19, 22, 33, 34], "sigmoid_test": [18, 19, 33, 34], "26894142": [18, 19, 33, 34], "73105858": [18, 19, 33, 34], "88079708": [18, 19, 33, 34], "compute_cost": [18, 19, 22, 23, 25, 27, 33, 34], "intermedi": [18, 19, 33, 34], "w_0x": [18, 19, 33, 34], "w_": [18, 19, 27, 29, 33, 34], "\ud835\udc5a": [18, 19, 33, 34, 39, 44, 45], "\ud835\udc5b": [18, 19, 33, 34, 39, 44, 45], "array_lik": [18, 19, 33, 34, 48], "unus": [18, 19, 33, 34], "placehold": [18, 19, 33, 34], "total_cost": [18, 19, 22, 23, 25, 33, 34, 43, 46], "f_wb": [18, 19, 21, 22, 23, 25, 27, 28, 31, 33, 34], "summat": [18, 19, 22, 25, 33, 34, 50, 51], "eg": [18, 19, 25, 33, 34, 37], "limits_": [18, 19, 22, 23, 25, 27, 28, 33, 34, 38, 40, 43, 46], "2i": [18, 19, 25, 33, 34], "loss_sum": [18, 19, 33, 34], "outsid": [18, 19, 25, 33, 34, 52], "Then": [18, 19, 25, 33, 34, 48, 49], "z_wb": [18, 19, 33, 34], "term": [18, 19, 22, 26, 28, 29, 33, 34, 37, 38, 43, 46, 48, 50], "z_wb_ij": [18, 19, 33, 34], "equival": [18, 19, 33, 34, 37, 52], "initial_b": [18, 19, 25, 27, 33, 34], "test_w": [18, 19, 25, 33, 34], "test_b": [18, 19, 25, 33, 34], "compute_cost_test": [18, 19, 25, 33, 34], "lbrace": [18, 19, 23, 25, 27, 28, 33, 34, 40, 43, 46], "newlin": [18, 19, 23, 25, 27, 28, 33, 34], "partial": [18, 19, 23, 25, 27, 28, 33, 34, 40, 43, 46], "w_j": [18, 19, 27, 28, 33, 34, 40, 43, 46], "rbrace": [18, 19, 23, 25, 27, 28, 33, 34, 40, 43, 46], "simultani": [18, 19, 23, 25, 33, 34], "definit": [18, 19, 33, 34, 38], "dj_dw": [18, 19, 23, 25, 27, 28, 33, 34, 40, 43, 46], "dj_db": [18, 19, 23, 25, 27, 28, 33, 34, 40, 43, 46], "f_wb_i": [18, 19, 27, 33, 39, 40, 43, 44, 45, 46], "dj_db_i": [18, 19, 23, 25, 33, 34], "th": [18, 19, 21, 26, 27, 28, 33, 34, 48, 49, 50], "dj_dw_ij": [18, 19, 33, 34], "tolist": [18, 19, 33, 34, 40, 43, 46], "00921658929115": [18, 19, 33, 34], "262842205513591": [18, 19, 33, 34], "ddj_dw": [18, 19, 33, 34], "compute_gradient_test": [18, 19, 25, 33, 34], "5999999999991071": [18, 19, 33, 34], "831353617873795": [18, 19, 33], "37384124953978": [18, 19, 33, 34], "8313536178737957": [18, 19, 33, 34], "assum": [18, 19, 25, 26, 33, 34, 42], "steadi": [18, 19, 23, 25, 33, 34], "gradient_desc": [18, 19, 23, 25, 27, 33, 34, 40], "w_in": [18, 19, 23, 25, 27, 33, 34, 35, 36, 40], "b_in": [18, 19, 23, 25, 27, 33, 34, 35, 36, 40], "cost_funct": [18, 19, 23, 25, 27, 33, 34], "gradient_funct": [18, 19, 23, 25, 27, 33, 34], "num_it": [18, 19, 23, 25, 27, 33, 34, 40], "batch": [18, 25, 27, 33, 34, 40, 52], "constant": [18, 19, 33, 34], "primarili": [18, 19, 23, 25, 27, 33, 34, 40], "j_histori": [18, 19, 23, 25, 27, 33, 34, 40], "w_histori": [18, 19, 25, 33, 34], "100000": [18, 19, 23, 25, 27, 29, 33, 34, 40], "resourc": [18, 19, 23, 25, 27, 33, 34, 40], "exhaust": [18, 19, 23, 25, 27, 33, 34, 40], "ceil": [18, 19, 23, 25, 27, 33, 34, 40], "coupl": [18, 19, 33, 34, 48, 52], "especi": [18, 19, 33, 34], "version": [18, 19, 26, 27, 29, 33, 34, 50, 52], "faster": [18, 19, 23, 28, 29, 33, 34, 50], "seed": [18, 19, 26, 33, 34, 43, 46, 52], "intial_w": [18, 19, 33, 34], "rand": [18, 19, 26, 33, 34, 43, 46], "6000": [18, 19, 23, 29, 33, 34, 40], "7000": [18, 19, 23, 29, 33, 34, 40], "8000": [18, 19, 23, 29, 33, 34, 40], "9000": [18, 19, 23, 29, 33, 34, 40, 50, 51], "9999": [18, 19, 33, 34], "plot_decision_boundari": [18, 19, 33, 34], "qualiti": [18, 19, 33, 34], "parameter": [18, 19, 21, 27, 28, 33, 34, 37], "heurist": [18, 19, 33, 34, 37], "express": [18, 19, 33, 34], "report": [18, 19, 33, 34], "accuraci": [18, 33, 34], "tmp_w": [18, 19, 33, 34], "randn": [18, 19, 33, 34], "tmp_b": [18, 19, 33, 34], "tmp_x": [18, 19, 33, 34], "tmp_p": [18, 19, 33, 34], "predict_test": [18, 19, 33, 34], "000000": [18, 19, 33, 50], "approx": [18, 19, 33, 34, 52], "microchip": [18, 19, 33, 34], "fabric": [18, 19, 33, 34], "plant": [18, 19, 33, 34], "assur": [18, 19, 33, 34], "qa": [18, 19, 33, 34], "goe": [18, 19, 33, 34, 36], "variou": [18, 19, 25, 33, 34, 36], "ensur": [18, 19, 22, 33, 34, 51, 52], "manag": [18, 19, 33, 34], "factori": [18, 19, 33, 34], "accept": [18, 19, 26, 33, 34, 52], "reject": [18, 19, 33, 34], "past": [18, 19, 33, 34, 52], "cannot": [18, 19, 33, 34], "x_2": [18, 19, 33, 34], "sixth": [18, 19, 33, 34], "power": [18, 19, 33, 34], "mathrm": [18, 19, 33, 34, 48], "_featur": [18, 19, 33, 34], "nonlinear": [18, 19, 33, 34], "drawn": [18, 19, 33, 34], "mapped_x": [18, 19, 33, 34], "tranform": [18, 19, 33, 34], "suscept": [18, 19, 33, 34], "yourself": [18, 19, 33, 34, 50], "combat": [18, 19, 33, 34], "compute_cost_reg": [18, 19, 33, 34], "regulat": [18, 19, 33, 34], "control": [18, 19, 22, 28, 33, 34, 43, 46, 49, 52], "cost_without_reg": [18, 19, 33, 34], "reg_cost": [18, 19, 33, 34, 43, 46], "reg_cost_j": [18, 19, 33, 34], "x_map": [18, 19, 33, 34], "compute_cost_reg_test": [18, 19, 33, 34], "6618252552483948": [18, 19, 33, 34], "compon": [18, 19, 33, 34, 38, 40, 51], "x_j": [18, 19, 33, 34], "mbox": [18, 19, 33, 34], "unq_c6": [18, 19, 33, 34], "dj_dw_j_reg": [18, 19, 33, 34], "correspod": [18, 19, 33, 34], "compute_gradient_reg_test": [18, 19, 33, 34], "07138288792343662": [18, 19, 33], "010386028450548701": [18, 19, 33, 34], "011409852883280122": [18, 19, 33], "0536273463274574": [18, 19, 33, 34], "003140278267313462": [18, 19, 33, 34], "07138288792343656": [18, 19, 33, 34], "01140985288328012": [18, 19, 33, 34], "regularis": [18, 19], "ipykernel_7350": 18, "evenli": [18, 19, 33, 34, 36], "drew": [18, 19, 33, 34], "sig": [18, 19], "credit": [18, 19], "dibgerg": [18, 19], "github": [18, 19, 31], "hi": [18, 19, 48], "plot_x": [18, 19], "plot_i": [18, 19], "transpos": [18, 19, 50], "level": [18, 19, 23, 52], "regula": [18, 19, 33, 34], "203390": [18, 19, 33], "x_plot": [18, 19], "y_plot": [18, 19], "z_predict": [18, 19], "ipykernel_6366": 18, "2829149365": [18, 19], "6893248648821225": [18, 19], "5594964140290553": [18, 19], "5365941656209957": [18, 19], "5311518234465994": [18, 19], "5296693737410955": [18, 19], "5292246537838604": [18, 19], "5290807827627604": [18, 19], "5290313609587369": [18, 19], "5290135693988894": [18, 19], "5290069311969307": [18, 19], "regression_and_classif": [19, 24], "welcom": [19, 20, 24, 25], "reinforc": [19, 20, 24, 52], "materi": [19, 20, 24], "tour": [19, 20, 24], "easiest": [19, 20, 24], "menu": [19, 20, 24], "document": [19, 20, 24, 26, 52], "languag": [19, 20, 24, 26], "understand": [19, 20, 24, 25, 26, 37, 48, 49, 50], "pulldown": [19, 20, 24], "occasion": [19, 20, 24], "wrong": [19, 20, 24, 53], "mode": [19, 20, 24, 52], "restor": [19, 20, 24, 50], "state": [19, 20, 24, 51, 52], "hold": [19, 20, 24, 26, 48], "shift": [19, 20, 24], "kei": [19, 20, 24], "hit": [19, 20, 24], "enter": [19, 20, 24, 50, 52], "arrow": [19, 20, 23, 24], "emb": [19, 20, 24, 52], "c1w2a1": [19, 25], "unoffici": [19, 26], "standard": [19, 26, 27, 28, 30, 43, 46, 51, 52], "review": [19, 23, 26, 27, 29, 50], "challeng": [19, 26], "topic": [19, 26, 38], "arithmet": [19, 26], "richer": [19, 26], "seamlessli": [19, 26], "order": [19, 26, 37, 49, 52], "denot": [19, 21, 26], "bold": [19, 21, 26, 27, 28], "letter": [19, 26], "charact": [19, 26], "though": [19, 23, 26, 28, 48], "mathematician": [19, 26], "rank": [19, 26], "referenc": [19, 26, 50], "scienc": [19, 26, 28], "individu": [19, 26], "subscript": [19, 26, 27], "awai": [19, 23, 26, 52], "overload": [19, 26], "object": [19, 26, 31, 50, 52], "alloc": [19, 26], "memori": [19, 26, 52], "fill": [19, 26, 37, 50, 52], "random_sampl": [19, 26], "manual": [19, 26, 31], "user": [19, 26, 50], "via": [19, 26, 52], "slice": [19, 26], "within": [19, 25, 26, 27, 40, 49, 50], "messag": [19, 26], "consecut": [19, 26, 52], "involv": [19, 22, 25, 26, 28, 50], "negat": [19, 26], "logic": [19, 26, 49], "comparison": [19, 26], "basi": [19, 26, 51], "a_i": [19, 26], "b_i": [19, 26], "mismatch": [19, 26], "scale": [19, 22, 23, 26, 50, 51], "mainstai": [19, 26], "algebra": [19, 26, 50], "extens": [19, 26, 27], "understood": [19, 26, 29], "my_dot": [19, 26], "10000000": [19, 26], "tic": [19, 26], "toc": [19, 26], "4f": [19, 23, 26], "del": [19, 26], "remov": [19, 26, 28, 51], "big": [19, 26], "underli": [19, 26], "hardwar": [19, 26], "modern": [19, 26], "simd": [19, 26], "pipelin": [19, 26], "issu": [19, 26, 27, 28], "appear": [19, 26, 27, 28, 51], "frequent": [19, 21, 26], "context": [19, 26, 37, 50, 51], "extract": [19, 26, 52], "consequ": [19, 26, 50, 52], "lengthi": [19, 26, 27], "explan": [19, 26], "common": [19, 26, 28, 48], "capitol": [19, 26], "1st": [19, 26], "were": [19, 26, 28, 29, 48, 49, 51], "earlier": [19, 26, 27, 28, 31, 38, 50], "bracket": [19, 26, 51], "attent": [19, 26, 50], "command": [19, 26, 35], "arriv": [19, 26, 52], "usag": [19, 26], "profit": [19, 25], "restaur": [19, 25], "franchis": [19, 25], "amitk": [19, 25], "ceo": [19, 25], "citi": [19, 25], "outlet": [19, 25], "busi": [19, 25], "chain": [19, 25], "alreadi": [19, 25, 49, 52], "candid": [19, 25], "decim": [19, 25], "1101": [19, 25], "similarli": [19, 25, 48], "monthli": [19, 25], "6807": [19, 25], "1d": [19, 25], "properti": [19, 25, 38, 49], "life": [19, 25], "household": [19, 25], "incom": [19, 25], "sale": [19, 25], "pair": [19, 25, 35], "come": [19, 21, 25, 37, 52], "closer": [19, 25], "lowest": [19, 22, 25, 48], "gradual": [19, 25, 52], "oppos": [19, 25], "record": [19, 25, 50], "intercept": [19, 25, 31], "wb": [19, 23, 25, 38, 43, 46], "cost_sum": [19, 22, 25], "ith": [19, 25], "paramat": [19, 25], "public": [19, 25, 50, 51], "video": [19, 25, 36, 52], "phantom": [19, 25], "0000": [19, 25], "dj_dw_i": [19, 23, 25], "tmp_dj_dw": [19, 25, 27], "tmp_dj_db": [19, 25, 27], "32884975": [19, 25], "83913505154639": [19, 25], "41610118": [19, 25], "007175051546391": [19, 25], "deepcopi": [19, 23, 25, 27, 40], "avoid": [19, 23, 25, 27, 40, 51, 52], "global": [19, 23, 25, 27, 40], "15000": 19, "16636235": [19, 25], "63029143940436": [19, 25], "dictat": 19, "automat": [19, 48, 50, 52], "costrain": 19, "boundri": 19, "xlim": 19, "predictedamit": 19, "peopl": [19, 25], "predict1": [19, 25], "predict2": [19, 25], "45342": [19, 25], "contrast": [19, 27, 28, 35], "module3": 19, "plt_one_addpt_onclick": [19, 35, 36], "email": [19, 35], "spam": [19, 35], "tumor": [19, 35, 36], "malign": [19, 35], "benign": [19, 28, 35], "outcom": [19, 35], "symbol": [19, 35], "x_train2": [19, 35], "y_train2": [19, 35], "tick": [19, 35, 36], "box": [19, 29, 35, 36], "toggl": [19, 35, 36], "incorrectli": [19, 35, 49], "renew": [19, 35], "addpt": [19, 35, 36], "insuffici": [19, 35], "draw_vthresh": [19, 36, 37], "6ad9867be1614455a28dddf811316f6f": 19, "ourselv": [19, 36], "input_arrai": [19, 36], "exp_arrai": [19, 36], "input_v": [19, 36], "exp_val": [19, 36], "z_tmp": [19, 36], "c_": [19, 29, 36, 50], "circl": [19, 37, 39, 40, 44, 45, 49], "w_0x_0": [19, 27, 29, 37], "w_1x_1": [19, 27, 29, 37], "w_0": [19, 23, 27, 28, 37, 39, 44, 45], "w_1": [19, 27, 28, 29, 37, 39, 44, 45], "learnt": [19, 37], "sqrt": [19, 49], "fill_between": [19, 37], "plt_logistic_loss": [19, 38], "plt_logistic_cost": [19, 38], "plt_two_logistic_loss_curv": [19, 38], "plt_simple_exampl": [19, 38], "soup_bowl": [19, 22, 38], "plt_logistic_squared_error": [19, 38], "nice": [19, 23, 38], "minimum": [19, 22, 23, 28, 38, 48, 51, 52], "natur": [19, 29, 38, 52], "surfac": [19, 38, 52], "logistic_model": 19, "cost_fn_logist": 19, "cost_f": 19, "wj": 19, "canva": 19, "toolbar_vis": 19, "header_vis": 19, "footer_vis": 19, "add_subplot": 19, "project": 19, "3d": 19, "plot_surfac": 19, "coolwarm": 19, "soup": [19, 22, 38], "bowl": [19, 22, 23, 38], "suitabl": [19, 38], "suit": [19, 38], "logleft": [19, 38], "fact": [19, 22, 38], "rapidli": [19, 22, 23, 38], "strictli": [19, 38], "rewritten": [19, 38], "easier": [19, 38], "formid": [19, 38], "daunt": [19, 38], "ok": [19, 38], "incorpor": [19, 38, 51], "cst": [19, 38], "plateau": [19, 38], "local": [19, 22, 23, 38], "minima": [19, 38], "discontinu": [19, 38], "declin": [19, 23, 27, 38], "remind": [19, 38], "rotat": [19, 38], "mous": [19, 21, 38], "compute_cost_logist": [19, 39, 40, 44, 45], "accumul": [19, 27, 39, 40, 45, 50], "z_i": [19, 39, 43, 44, 45, 46], "w_tmp": [19, 39, 40, 43, 44, 45, 46], "b_tmp": [19, 39, 40, 43, 44, 45, 46], "3668667864055175": [19, 39, 44, 45], "magenta": [19, 39, 44, 45], "x1_other": [19, 39, 44, 45], "dlmagenta": [19, 39, 44, 45], "w_array1": [19, 39, 44, 45], "b_1": [19, 39, 44, 45], "w_array2": [19, 39, 44, 45], "b_2": [19, 39, 44, 45], "5036808636748461": [19, 39, 44, 45], "behav": [19, 28, 39, 44, 45, 49], "inde": [19, 39, 44, 45], "plt_tumor_data": [19, 40], "plt_quad_logist": [19, 40], "simultan": [19, 23, 27, 28, 40, 43, 46, 50], "compute_gradient_logist": [19, 40], "ask": [19, 40], "x_tmp": [19, 40, 43, 46], "dj_db_tmp": [19, 40, 43, 46], "dj_dw_tmp": [19, 40, 43, 46], "49861806546328574": [19, 40], "498333393278696": [19, 40], "49883942983996693": [19, 40], "4d": [19, 27, 40], "alph": [19, 40], "w_out": [19, 40], "b_out": [19, 40], "nupdat": [19, 40], "idea": [19, 29, 40], "button": [19, 40], "steadili": [19, 40], "reset": [19, 40, 42, 52], "w_rang": [19, 23, 40], "b_rang": [19, 23, 40], "logisticregress": [19, 41], "lr_model": [19, 41], "occur": [19, 42, 48, 52], "aris": [19, 42], "ofit": [19, 42, 43, 46], "switch": [19, 42], "extrem": [19, 29, 42], "nomin": [19, 42], "slowli": [19, 23, 28, 42, 52], "receiv": [19, 42, 52], "pure": [19, 42], "commonli": [19, 42], "ipywidget": [19, 42], "encourag": [19, 43, 48, 52], "pattern": [19, 23, 27, 43, 46], "compute_cost_linear_reg": [19, 43, 46], "lambda_tmp": [19, 43, 46], "cost_tmp": [19, 43, 46], "07917239320214275": [19, 43, 46], "compute_cost_logistic_reg": [19, 43, 46], "6850849138741673": [19, 43, 46], "compute_gradient_linear_reg": [19, 43, 46], "6648774569425726": [19, 43, 46], "29653214748822276": [19, 43, 46], "4911679625918033": [19, 43, 46], "21645877535865857": [19, 43, 46], "compute_gradient_logistic_reg": [19, 43, 46], "341798994972791": [19, 43, 46], "17380012933994293": [19, 43, 46], "32007507881566943": [19, 43, 46], "10776313396851499": [19, 43, 46], "amit": 19, "62365962": [19, 33], "02469282": [19, 33], "28671077": [19, 33], "89499752": [19, 33], "84740877": [19, 33], "90219803": [19, 33], "18259939": [19, 33], "3085521": [19, 33], "03273605": [19, 33], "34437644": [19, 33], "ipykernel_6349": 19, "p_path": 19, "i_": [21, 27, 28, 51], "x_i": [21, 28, 49], "y_i": 21, "motiv": [21, 27, 28], "constitut": 21, "1200": [21, 23, 25, 27, 28, 31], "content": [21, 50], "curli": 21, "brace": 21, "offset": 21, "syntax": 21, "explicitli": 21, "unwieldi": 21, "repetit": 21, "compute_model_output": 21, "magnitud": [21, 23, 28], "tmp_f_wb": 21, "experi": [21, 52], "font": [21, 28], "darkgreen": [21, 28], "cost_1200sqft": 21, "0f": [21, 28, 51], "thousand": [21, 23, 28, 48], "establish": 21, "novel": 21, "lab_utils_uni": [22, 23], "plt_intuit": 22, "plt_stationari": 22, "plt_update_onclick": 22, "confus": 22, "focu": [22, 50, 51], "pedict": 22, "perfect": [22, 29], "read": [22, 48, 52], "dyn_item": 22, "dash": 22, "approxim": [22, 52], "easi": [22, 52], "symmetr": [22, 28], "lab_util": [23, 29], "plt_house_x": 23, "plt_contour_wgrad": 23, "plt_diverg": 23, "plt_gradient": 23, "embed": 23, "side": [23, 52], "due": [23, 28, 52], "quiver": 23, "ratio": 23, "subtract": [23, 28, 51], "p_histori": 23, "2e": [23, 28], "3e": [23, 28], "5e": [23, 28], "w_init": [23, 27], "b_init": [23, 27], "tmp_alpha": 23, "0e": [23, 27, 28], "w_final": [23, 27], "b_final": [23, 27], "j_hist": [23, 27], "p_hist": 23, "500e": 23, "000e": [23, 36], "00000e": 23, "712e": 23, "007e": 23, "949e": 23, "08228e": 23, "789e": 23, "895e": 23, "975e": [23, 36], "03966e": 23, "625e": 23, "396e": 23, "988e": 23, "01912e": 23, "158e": 23, "727e": 23, "994e": 23, "00922e": 23, "004e": 23, "243e": 23, "997e": [23, 36], "00444e": 23, "660e": 23, "563e": 23, "999e": [23, 36], "00214e": 23, "657e": 23, "535e": 23, "00103e": 23, "245e": 23, "632e": 23, "00050e": 23, "082e": 23, "751e": 23, "00024e": 23, "0116": 23, "characterist": [23, 48], "nears": 23, "slower": 23, "slow": 23, "rapid": [23, 28], "decent": 23, "ax1": [23, 27], "ax2": [23, 27], "constrained_layout": [23, 27], "discov": [23, 28], "1f": [23, 50, 51], "ring": [23, 50, 51], "overlai": 23, "monoton": 23, "zoom": 23, "approach": [23, 28, 36, 50], "resolut": 23, "img": 23, "src": 23, "c1_w1_lab03_alpha_too_big": 23, "png": [23, 48], "width": 23, "340px": 23, "height": 23, "240px": 23, "relat": [23, 28], "proper": [23, 48], "But": 23, "diverg": [23, 28], "200e": 23, "20000e": 23, "130e": 23, "840e": 23, "40000e": 23, "970e": 23, "216e": 23, "192e": [23, 36], "32800e": 23, "429e": 23, "121e": 23, "551e": 23, "63840e": 23, "974e": 23, "691e": 23, "228e": 23, "98886e": 23, "040e": 23, "431e": 23, "095e": 23, "15579e": 23, "812e": 23, "120e": 23, "402e": 23, "80237e": 23, "156e": 23, "950e": 23, "584e": 23, "80139e": 23, "496e": 23, "397e": 23, "813e": 23, "73730e": 23, "572e": 23, "916e": 23, "845e": 23, "99567e": 23, "bounc": 23, "forth": 23, "absolut": 23, "sign": [23, 28, 51], "oscil": [23, 28, 52], "pictur": [23, 28], "delv": 23, "5277": 25, "5186": 25, "0032": 25, "8598": 25, "1302": 25, "8233": 25, "32884974555672": 25, "41610118114435": 25, "1050": 25, "1350": 25, "166362350335582": 25, "pwd": 25, "toc_40015_1": 26, "abstract": 26, "toc_40015_3": 26, "creation": 26, "toc_40015_4": 26, "6c991b1287dc4cf18de6792998474604": 26, "17954544": 26, "47154822": 26, "44672505": 26, "14412252": 26, "73333494": 26, "74200217": 26, "37076377": 26, "84305645": 26, "int64": 26, "bound": 26, "2501072": 26, "5817": 26, "5285": 26, "44236513": 26, "previous": [27, 28], "minor": 27, "outlin": [27, 40], "toc_15456_1": 27, "toc_15456_2": 27, "toc_15456_3": 27, "toc_15456_5": 27, "rewrit": 27, "capit": [27, 28], "maxtrix": [27, 28], "bedroom": [27, 28, 30, 31], "floor": [27, 28, 30, 31], "ag": [27, 28, 30, 31], "2104": 27, "1416": 27, "year": [27, 28, 31, 50, 51], "old": [27, 28, 31], "pmatrix": 27, "superscript": 27, "parenthesi": 27, "1811367994083": 27, "39133535": 27, "75376741": 27, "36032453": 27, "42131618": 27, "predict_single_loop": 27, "p_i": 27, "x_vec": 27, "9999976194083": 27, "link": 27, "5578904428966628e": 27, "5578904045996674e": 27, "outer": [27, 52], "6739251501955248e": 27, "6739251122999121e": 27, "2529": 27, "versu": [27, 28, 30], "tail": 27, "inspir": 27, "lab_utils_multi": [28, 29, 30, 31], "load_house_data": [28, 30, 31], "run_gradient_desc": 28, "norm_plot": 28, "plt_equal_scal": 28, "plot_cost_i_w": 28, "x_featur": [28, 29, 30, 31], "sharei": [28, 29, 30], "strongest": 28, "influenc": 28, "strong": [28, 52], "newer": 28, "older": 28, "hist": 28, "w0": 28, "djdw0": 28, "djdw1": 28, "djdw2": 28, "djdw3": 28, "djdb": 28, "55884e": 28, "6e": 28, "28213e": 28, "8e": 28, "7e": 28, "4e": 28, "72159e": 28, "31358e": 28, "11100e": 28, "18517e": 28, "63212e": 28, "58122e": 28, "02068e": 28, "37435e": 28, "overshoot": 28, "slightli": 28, "64616e": 28, "18990e": 28, "76572e": 28, "37137e": 28, "00474e": 28, "66388e": 28, "34700e": 28, "05239e": 28, "77849e": 28, "52385e": 28, "throughout": [28, 50], "jump": 28, "42313e": 28, "76461e": 28, "75102e": 28, "13157e": 28, "53002e": 28, "21639e": 28, "80242e": 28, "93826e": 28, "41013e": 28, "08734e": 28, "dj_w0": 28, "rescal": 28, "header": [28, 51], "walk": 28, "long": [28, 29, 31, 52], "hour": [28, 31], "reduct": [28, 48], "dj_dw0": 28, "dj_dw1": 28, "someth": [28, 29], "unevenli": 28, "essenti": 28, "serv": 28, "dfrac": 28, "mu_i": [28, 49], "deviat": 28, "mu_j": [28, 48], "sigma_j": 28, "\u00b5_j": 28, "sigma": [28, 49], "2_j": 28, "live": [28, 29, 50], "room": 28, "bed": 28, "zscore_normalize_featur": [28, 29], "zcore": 28, "x_norm": [28, 30], "mu": [28, 49], "x_orig": 28, "with_mean": 28, "with_std": 28, "x_mean": 28, "unnorm": 28, "middl": 28, "clearli": 28, "x_mu": 28, "x_sigma": 28, "nx_sigma": 28, "ptp": [28, 29, 30], "factor": [28, 48, 52, 53], "importantli": 28, "vastli": 28, "w_norm": [28, 30], "b_norm": [28, 30], "76170e": 28, "21086e": 28, "19209e": 28, "19207e": 28, "tini": 28, "yp": 28, "longer": [28, 29], "x_hous": [28, 31], "x_house_norm": 28, "x_house_predict": [28, 31], "318709": [28, 31], "82483aeca05d4a338042e2786246049a": 28, "asymmetr": 28, "visibl": [28, 52], "am": 28, "dean": 28, "de": 28, "cock": 28, "educ": 28, "machineri": 29, "complic": 29, "run_gradient_descent_feng": 29, "overview": 29, "tend": 29, "penal": 29, "concaten": 29, "model_w": 29, "model_b": 29, "65756e": 29, "94549e": 29, "88475e": 29, "26414e": 29, "90103e": 29, "68858e": 29, "56428e": 29, "49155e": 29, "44900e": 29, "42411e": 29, "0834": 29, "great": 29, "swap": 29, "32922e": 29, "24844e": 29, "22795e": 29, "20764e": 29, "18752e": 29, "16758e": 29, "14782e": 29, "12824e": 29, "10884e": 29, "08962e": 29, "049": 29, "ran": 29, "knew": 29, "tri": [29, 51, 52], "w_2x_2": 29, "14029e": 29, "28539e": 29, "80443e": 29, "39389e": 29, "04344e": 29, "74430e": 29, "48896e": 29, "27100e": 29, "08495e": 29, "26132e": 29, "0106": 29, "08x": 29, "54x": 29, "03x": 29, "emphas": 29, "intial": 29, "against": 29, "easili": 29, "mean_norm": 29, "6859": 29, "aggress": 29, "42147e": 29, "90938e": 29, "20000": 29, "78389e": 29, "30000": 29, "98242e": 29, "40000": 29, "41169e": 29, "50000": 29, "00527e": 29, "60000": 29, "15855e": 29, "70000": 29, "09763e": 29, "80000": 29, "63004e": 29, "90000": 29, "58497e": 29, "co": 29, "1000000": 29, "20188e": 29, "70074e": 29, "27603e": 29, "300000": 29, "73032e": 29, "400000": 29, "56440e": 29, "500000": 29, "01412e": 29, "600000": 29, "90251e": 29, "700000": 29, "10351e": 29, "800000": 29, "52730e": 29, "900000": 29, "10989e": 29, "highli": [29, 51, 52], "commerci": [30, 31, 51], "usabl": [30, 31], "toolkit": [30, 31, 52], "pip": 30, "instal": 30, "scipi": 30, "sgdregressor": 30, "scaler": [30, 51], "fit_transform": 30, "sgdr": 30, "max_it": [30, 48], "n_iter_": 30, "t_": 30, "13267": 30, "intercept_": [30, 31], "coef_": [30, 31], "y_pred_sgd": 30, "earli": 31, "rerun": [31, 35, 40], "trust": 31, "unabl": 31, "render": [31, 52], "nbviewer": 31, "linearregressionlinearregress": 31, "coeffici": 31, "240100": 31, "un": 31, "took": 31, "instantan": 31, "computation": 31, "demand": 31, "051267": 33, "69956": 33, "092742": 33, "68494": 33, "21371": 33, "69225": 33, "50219": 33, "51325": 33, "46564": 33, "12670000e": 33, "99560000e": 33, "62830529e": 33, "58643425e": 33, "89384194e": 33, "34745327e": 33, "83865725e": 33, "50892595e": 33, "42353606e": 33, "90798869e": 33, "42624411e": 33, "28625106e": 33, "75514423e": 33, "39496889e": 33, "54151856e": 33, "83255257e": 33, "59422333e": 33, "99809795e": 33, "22782870e": 33, "67542444e": 33, "81563032e": 33, "47750473e": 33, "38066048e": 33, "61305487e": 33, "29470940e": 33, "58939846e": 33, "17205992e": 33, "0031402782673134655": 33, "hae": [33, 34], "typeerror": 34, "unsupport": 34, "nonetyp": 34, "ungrad": [36, 38], "7959311b198a4e5b918798d237930608": 36, "718281828459045": 36, "540e": 36, "234e": 36, "354e": 36, "111e": 36, "473e": 36, "693e": 36, "799e": 36, "743e": 36, "689e": 36, "311e": 36, "808e": 36, "526e": 36, "820e": 36, "933e": 36, "991e": 36, "36686678640551745": 39, "684610468560574": 40, "1590977666870457": 40, "08460064176930078": 40, "05705327279402531": 40, "04290759421682": 40, "03433847729884557": 40, "02860379802212006": 40, "02450156960879306": 40, "02142370332569295": 40, "019030137124109114": 40, "222409982019837": 40, "get_ipython": [44, 45, 46], "run_line_mag": [44, 45, 46], "incent": 46, "07917239320214277": 46, "recommenders_reinforcement_learn": 47, "compress": 48, "wil": 48, "closest": [48, 51], "centroid": 48, "concret": 48, "cohes": 48, "refin": 48, "recomput": 48, "pseudocod": 48, "kmeans_init_centroid": 48, "idx": 48, "find_closest_centroid": 48, "compute_mean": 48, "carri": 48, "usual": 48, "distort": 48, "phase": 48, "compute_centroid": 48, "insid": 48, "membership": 48, "norm_ij": 48, "linalg": [48, 50, 51], "norm": 48, "84207953": 48, "6075716": 48, "65858312": 48, "79996405": 48, "35257892": 48, "2908545": 48, "90401653": 48, "61220411": 48, "23197916": 48, "93989405": 48, "initial_centroid": 48, "find_closest_centroids_test": 48, "mu_k": 48, "c_k": 48, "mu_2": 48, "compute_centpod": 48, "compute_centroids_test": 48, "42830111": 48, "15792418": 48, "81350331": 48, "63365645": 48, "11938687": 48, "6166844": 48, "toi": [48, 50, 51], "run_kmean": 48, "plot_progress": 48, "previous_centroid": 48, "plot_progress_kmean": 48, "design": [48, 52], "strategi": 48, "shuffl": [48, 51], "permut": 48, "risk": 48, "reorder": 48, "randidx": 48, "unsign": 48, "rgb": 48, "necessari": [48, 52], "treat": 48, "belong": 48, "frank": 48, "wouter": 48, "permiss": 48, "bird": 48, "original_img": 48, "imread": 48, "bird_smal": 48, "axesimag": 48, "0x7fec91c97650": 48, "third": [48, 51], "16384": 48, "times128": 48, "x_img": 48, "overhead": 48, "storag": 48, "dictionari": [48, 52], "itself": 48, "x_recov": 48, "recov": 48, "retain": 48, "artifact": 48, "colour": 48, "server": 49, "anomal": 49, "throughput": 49, "mb": 49, "latenc": 49, "unlabel": 49, "ldot": 49, "suspect": 49, "vast": 49, "major": 49, "act": [49, 51], "henc": 49, "x_val": 49, "y_val": 49, "04681517": 49, "74115241": 49, "40852019": 49, "7632696": 49, "19591481": 49, "85318113": 49, "91470077": 49, "17425987": 49, "57669961": 49, "04284944": 49, "79025979": 49, "9210243": 49, "63961877": 49, "32995521": 49, "86589943": 49, "47386514": 49, "58467605": 49, "98930611": 49, "46404167": 49, "63533011": 49, "pi": [49, 52], "sigma_i": 49, "estimate_gaussian": 49, "var": 49, "nest": 49, "manner": 49, "estimate_gaussian_test": 49, "11222578": 49, "99771051": 49, "83263141": 49, "70974533": 49, "densiti": 49, "multivari": 49, "multivariate_gaussian": 49, "visualize_fit": 49, "investig": [49, 50], "select_threshold": 49, "varepsilon": 49, "f_1": 49, "rm": [49, 52], "p_val": 49, "ground": [49, 52], "truth": 49, "f1": 49, "prec": 49, "tp": 49, "fp": 49, "rec": 49, "fn": 49, "best_epsilon": 49, "best_f1": 49, "step_siz": 49, "\ud835\udc65": 49, "tn": 49, "select_threshold_test": 49, "990853e": 49, "875000": 49, "ro": 49, "markers": 49, "markerfacecolor": 49, "markeredgewidth": 49, "line2d": 49, "0x7f9000717290": 49, "realist": 49, "harder": 49, "x_train_high": 49, "x_val_high": 49, "y_val_high": 49, "_high": 49, "distinguish": 49, "load_data_multi": 49, "mu_high": 49, "var_high": 49, "probabilit": 49, "p_high": 49, "p_val_high": 49, "epsilon_high": 49, "f1_high": 49, "377229e": 49, "615385": 49, "movi": [50, 51], "recsys_util": 50, "game": 50, "n_u": [50, 51], "num_us": 50, "n_m": [50, 51], "num_movi": 50, "embodi": 50, "tast": 50, "inclus": [50, 51], "satisfi": 50, "unrat": 50, "coficostfunc": 50, "custom": [50, 52], "movielen": [50, 51], "ml": [50, 51], "latest": [50, 51, 52], "maxwel": [50, 51], "harper": [50, 51], "joseph": [50, 51], "konstan": [50, 51], "acm": [50, 51], "transact": [50, 51], "interact": [50, 51, 52], "intellig": [50, 51], "tii": [50, 51], "doi": [50, 51], "1145": [50, 51], "2827872": [50, 51], "gave": [50, 51], "correspondingli": 50, "load_precalc_params_smal": 50, "load_ratings_smal": 50, "statist": 50, "tsmean": 50, "bool": 50, "wish": 50, "underbrac": [50, 52], "cofi_cost_func": 50, "item": 50, "nm": 50, "nu": 50, "b_j": 50, "test_cofi_cost_func": 50, "pai": 50, "forget": 50, "resort": 50, "num_users_r": 50, "num_movies_r": 50, "num_features_r": 50, "x_r": 50, "w_r": 50, "b_r": 50, "y_r": 50, "r_r": 50, "seri": 50, "expert": 50, "cofi_cost_func_v": 50, "reduce_sum": 50, "movielist": 50, "movielist_df": 50, "load_movie_list_pd": 50, "my_rat": 50, "my": [50, 51], "small_movie_list": 50, "csv": 50, "id": [50, 51], "stori": [50, 51], "enjoi": 50, "persuas": 50, "2007": 50, "lord": 50, "king": 50, "shrek": [50, 51], "incept": 50, "incred": 50, "ameli": 50, "fabuleux": 50, "destin": [50, 51], "am\u00e9li": 50, "poulain": 50, "le": 50, "harri": 50, "potter": 50, "sorcer": 50, "stone": 50, "philosoph": 50, "chamber": 50, "secret": 50, "2002": [50, 51], "etern": 50, "sunshin": 50, "spotless": 50, "mind": [50, 51, 52], "loui": 50, "theroux": 50, "law": 50, "disord": 50, "noth": [50, 52], "declar": 50, "rien": 50, "\u00e0": 50, "d\u00e9clarer": 50, "pirat": 50, "caribbean": 50, "curs": 50, "black": [50, 51], "pearl": 50, "2003": [50, 51], "nnew": 50, "amp": [50, 51], "reload": 50, "ynorm": 50, "ymean": 50, "normalizer": 50, "prepar": [50, 51], "flow": 50, "marvel": 50, "gradienttap": [50, 52], "tape": [50, 52], "cost_valu": 50, "retriev": [50, 52], "grad": 50, "apply_gradi": [50, 52], "period": 50, "2321191": 50, "136168": 50, "51863": 50, "24598": 50, "13630": 50, "8487": 50, "pm": 50, "ix": 50, "argsort": 50, "descend": 50, "norigin": 50, "sassi": 50, "girl": 50, "yeopgijeogin": 50, "geunyeo": 50, "martin": 50, "lawrenc": 50, "runteldat": 50, "memento": 50, "delirium": 50, "laggi": 50, "love": [50, 51], "particl": 50, "fever": 50, "eichmann": 50, "battl": 50, "royal": 50, "requiem": 50, "batoru": 50, "rowaiaru": 50, "ii": [50, 51], "chinkonka": 50, "Into": 50, "abyss": 50, "enhanc": 50, "hundr": 50, "lie": 50, "augment": 50, "panda": [50, 51], "frame": [50, 52], "handi": 50, "pred": 50, "reindex": 50, "sort_valu": 50, "ascend": 50, "030965": 50, "252336": 50, "2112": 50, "985287": 50, "238255": 50, "dark": 50, "knight": [50, 51], "477792": 50, "122642": 50, "887053": 50, "118919": 50, "796530": 50, "109091": 50, "357304": 50, "021277": 50, "tower": 50, "004469": 50, "006494": 50, "shaun": 50, "dead": 50, "980647": 50, "fuzz": 50, "084633": 50, "993421": 50, "434171": 50, "989362": 50, "deathli": 50, "hallow": 50, "289679": 50, "960993": 50, "nemo": 50, "344993": 50, "944444": 50, "casino": 50, "2649": 50, "133482": 50, "943396": 50, "dragon": 50, "175746": 50, "887931": 50, "half": [50, 51], "blood": 50, "princ": 50, "135291": 50, "871212": 50, "monster": [50, 51], "inc": [50, 51], "3014": 50, "967901": 50, "869565": 50, "aveng": 50, "897137": 50, "867647": 50, "971888": 50, "836364": 50, "crouch": 50, "tiger": 50, "hidden": 50, "wo": 50, "hu": 50, "cang": 50, "lon": 50, "898892": 50, "836000": 50, "874935": 50, "778523": 50, "bla": 50, "843375": 50, "761682": 50, "021774": 50, "723684": 50, "x2": 50, "men": [50, 51], "242984": 50, "699248": 50, "878342": 50, "598039": 50, "recommend": [51, 52], "system": [51, 52], "tabul": 51, "neatli": 51, "organ": 51, "tabular": 51, "ma": 51, "genfromtxt": 51, "defaultdict": 51, "pd": 51, "minmaxscal": 51, "recsysnn_util": 51, "set_opt": 51, "genr": 51, "date": 51, "adventur": 51, "anim": 51, "children": 51, "comedi": 51, "fantasi": 51, "imax": 51, "collabor": 51, "sole": 51, "configur": 51, "item_train": 51, "user_train": 51, "item_featur": 51, "user_featur": 51, "item_vec": 51, "movie_dict": 51, "user_to_genr": 51, "num_user_featur": 51, "userid": 51, "av": 51, "num_item_featur": 51, "uv": 51, "iv": 51, "u_": 51, "scaledata": 51, "58187": 51, "pprint_train": 51, "maxcount": 51, "ion": 51, "adv": 51, "nture": 51, "ation": 51, "chil": 51, "dren": 51, "edi": 51, "crime": 51, "docum": 51, "entari": 51, "drama": 51, "fan": 51, "tasi": 51, "hor": 51, "ror": 51, "teri": 51, "rom": 51, "anc": 51, "sci": 51, "fi": 51, "thri": 51, "ller": 51, "6874": 51, "8798": 51, "thriller": 51, "inverse_transform": 51, "item_train_sav": 51, "user_train_sav": 51, "scaleritem": 51, "scalerus": 51, "allclos": 51, "sklean": 51, "item_test": 51, "train_siz": 51, "user_test": 51, "46549": 51, "11638": 51, "ynorm_train": 51, "ynorm_test": 51, "elect": 51, "num_output": 51, "remaind": 51, "api": 51, "flexibl": 51, "interconnect": 51, "graded_cel": 51, "user_nn": 51, "item_nn": 51, "input_us": 51, "vu": 51, "l2_normal": 51, "input_item": 51, "vm": 51, "__________________________________________________________________________________________________": 51, "connect": 51, "input_1": 51, "input_2": 51, "40864": 51, "41376": 51, "tf_op_layer_l2_norm": 51, "tf_op_layer_l2_normalize_1": 51, "squa": 51, "maximu": 51, "maxi": 51, "rsqrt": 51, "rsqr": 51, "tenso": 51, "test_tow": 51, "cost_fn": 51, "opt": 51, "133u": 51, "1254": 51, "122u": 51, "1187": 51, "121u": 51, "1169": 51, "120u": 51, "1142": 51, "1130": 51, "1119": 51, "119u": 51, "1095": 51, "1083": 51, "1066": 51, "1054": 51, "1036": 51, "1030": 51, "1027": 51, "1010": 51, "1003": 51, "0997": 51, "0989": 51, "0x7fba9d2b5110": 51, "36u": 51, "1045": 51, "10449595100221243": 51, "circumst": 51, "new_user_id": 51, "new_rating_av": 51, "new_act": 51, "new_adventur": 51, "new_anim": 51, "new_children": 51, "new_comedi": 51, "new_crim": 51, "new_documentari": 51, "new_drama": 51, "new_fantasi": 51, "new_horror": 51, "new_mysteri": 51, "new_rom": 51, "new_scifi": 51, "new_thril": 51, "new_rating_count": 51, "user_vec": 51, "favor": 51, "romanc": 51, "gen_user_vec": 51, "sorted_index": 51, "sorted_ypu": 51, "sorted_item": 51, "sorted_us": 51, "predict_uservec": 51, "print_pred_movi": 51, "y_p": 51, "avetitl": 51, "86762": 51, "64969": 51, "61765ye": 51, "man": 51, "86692": 51, "69122": 51, "63158hangov": 51, "86477": 51, "63131": 51, "85853": 51, "60756": 51, "55357step": 51, "brother": 51, "85785": 51, "68135": 51, "85178": 51, "78209": 51, "him": 51, "greek": 51, "85138": 51, "8622": 51, "48649fahrenheit": 51, "documentari": 51, "8505": 51, "67087": 51, "52941i": 51, "85043": 51, "69784": 51, "br\u00fcno": 51, "bruno": 51, "84934": 51, "89864": 51, "6315850": 51, "meaning": 51, "uid": 51, "y_vec": 51, "get_user_vec": 51, "sorted_i": 51, "print_existing_us": 51, "86time": 51, "00beauti": 51, "52road": 51, "perdit": 51, "52gang": 51, "york": 51, "v_u": 51, "v_m": 51, "vert": 51, "v_": 51, "m_l": 51, "graded_funct": 51, "sq_dist": 51, "test_sq_dist": 51, "030000000000000054": 51, "reus": 51, "retrain": 51, "input_item_m": 51, "vm_m": 51, "model_m": 51, "model_1": 51, "input_3": 51, "tf_op_layer_l2_normalize_2": 51, "scaled_item_vec": 51, "mask": 51, "diagon": 51, "won": [51, 52], "m_dist": 51, "masked_arrai": 51, "disp": 51, "movie1": 51, "movie2": 51, "min_idx": 51, "movie1_id": 51, "movie2_id": 51, "genre1": 51, "get_item_genr": 51, "genre2": 51, "tablefmt": 51, "firstrow": 51, "floatfmt": 51, "danc": 51, "john": 51, "q": [51, 53], "silverman": 51, "evil": 51, "woman": 51, "wed": 51, "planner": 51, "nation": 51, "lampoon": 51, "x27": 51, "van": 51, "wilder": 51, "mr": 51, "deed": 51, "hannib": 51, "horror": 51, "fear": 51, "earth": 51, "joe": 51, "dirt": 51, "haunt": 51, "mansion": 51, "mexican": 51, "tale": 51, "heartbreak": 51, "charli": 51, "angel": 51, "throttl": 51, "stepford": 51, "wive": 51, "spy": 51, "kid": 51, "lara": 51, "croft": 51, "tomb": 51, "raider": 51, "adventurelara": 51, "princess": 51, "diari": 51, "miib": 51, "mib": 51, "came": 51, "spider": 51, "swordfish": 51, "mysteri": 51, "blow": 51, "dai": 51, "bridget": 51, "jone": 51, "super": 51, "trooper": 51, "punch": 51, "drunk": 51, "adventurecharli": 51, "dr": 51, "dolittl": 51, "doom": 51, "crocodil": 51, "dunde": 51, "lo": 51, "scari": 51, "mummi": 51, "adventurerundown": 51, "american": 51, "pie": 51, "star": 51, "trek": 51, "nemesi": 51, "bruce": 51, "almighti": 51, "adventuremonst": 51, "animationmonst": 51, "monsoon": 51, "greatli": [51, 52], "book": 51, "car": 51, "shop": 51, "cart": 51, "agent": 52, "land": 52, "moon": 52, "82af44d698af424faadd9bd4d8cb5073": 52, "hyperparamet": 52, "observ": 52, "reward": [52, 53], "episod": 52, "termin": 52, "gym": 52, "dynam": 52, "replai": 52, "dequ": 52, "buffer": 52, "namedtupl": 52, "pil": 52, "pyvirtualdisplai": 52, "virtual": 52, "memory_s": 52, "100_000": 52, "gamma": [52, 53], "discount": [52, 53], "num_steps_for_upd": 52, "openai": 52, "pole": 52, "forc": 52, "mass": 52, "infinit": 52, "fuel": 52, "discret": 52, "fire": 52, "main": 52, "veloc": 52, "angl": 52, "angular": 52, "boolean": 52, "leg": 52, "contact": 52, "lose": 52, "crash": 52, "bodi": 52, "ai": 52, "lunarland": 52, "v2": 52, "env": 52, "fromarrai": 52, "rgb_arrai": 52, "observation_spac": 52, "action_spac": 52, "state_s": 52, "num_act": [52, 53], "formal": 52, "polici": 52, "a_t": 52, "s_t": 52, "r_t": 52, "info": 52, "diagnost": 52, "debug": 52, "initial_st": 52, "taken": 52, "next_stat": 52, "printopt": 52, "formatt": 52, "002": 52, "044": 52, "004": 52, "1043263227541047": 52, "bellman": 52, "q_": 52, "max_": 52, "q_i": 52, "infti": 52, "imposs": 52, "unfortun": 52, "proven": 52, "unstabl": 52, "luckili": 52, "emploi": 52, "instabl": 52, "overbrac": 52, "constantli": 52, "soft": 52, "rule": 52, "leftarrow": 52, "tau": 52, "dqn": 52, "lastli": 52, "q_network": 52, "target_q_network": 52, "test_network": 52, "test_optim": 52, "correl": 52, "uncorrel": 52, "mini": 52, "field_nam": 52, "problemat": 52, "togther": 52, "compute_loss": 52, "y_j": 52, "r_j": 52, "done_v": 52, "y_target": 52, "q_valu": 52, "calculate_loss": 52, "kara": 52, "int32": 52, "max_qsa": 52, "reduce_max": 52, "\u03b3": 52, "gather_nd": 52, "stack": 52, "cast": 52, "test_compute_loss": 52, "agent_learn": 52, "decor": 52, "update_target_network": 52, "trainable_vari": 52, "readi": 52, "scroll": 52, "memory_buff": 52, "capac": 52, "skip": 52, "num_episod": 52, "max_num_timestep": 52, "hasn": 52, "epsilon": 52, "greedi": 52, "equiprob": 52, "regardless": 52, "decai": 52, "lean": 52, "believ": 52, "get_act": 52, "check_update_condit": 52, "least": 52, "extra": 52, "total_point_histori": 52, "num_p_av": 52, "\u03b5": 52, "maxlen": 52, "total_point": 52, "state_qn": 52, "expand_dim": 52, "get_experi": 52, "av_latest_point": 52, "get_new_ep": 52, "repisod": 52, "nenviron": 52, "lunar_lander_model": 52, "h5": 52, "tot_tim": 52, "ntotal": 52, "runtim": 52, "plot_histori": 52, "create_video": 52, "imageio": 52, "distract": 52, "suppress": 52, "folder": 52, "filenam": 52, "embed_mp4": 52, "download": 52, "properli": 52, "lunar_land": 52, "mp4": 52, "browser": 52, "paper": 52, "human": 52, "atari": 52, "mar": 53, "rover": 53, "num_stat": 53, "terminal_left_reward": 53, "terminal_right_reward": 53, "each_step_reward": 53, "misstep_prob": 53, "generate_visu": 53}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"welcom": 0, "machin": [0, 16], "learn": [0, 16, 18, 19, 28, 30, 31, 41, 51, 52], "andrew": 0, "ng": 0, "": [0, 19, 40], "document": 0, "content": [0, 51], "indic": 0, "tabl": 0, "advanced_learning_algorithm": [1, 2, 4], "convolut": [1, 2, 4], "neural": [1, 2, 4, 5, 6, 8, 9, 10], "network": [1, 2, 4, 5, 6, 8, 9, 10], "option": [2, 4, 7, 8, 9, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46], "lab": [2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51], "neuron": [2, 4, 7], "layer": [2, 4, 7, 8, 11], "packag": [2, 4, 7, 19, 50], "without": [2, 4, 7], "activ": [2, 4, 7, 12], "regress": [2, 4, 7, 18, 19, 23, 25, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46], "linear": [2, 4, 7, 12, 19, 23, 25, 27, 30, 31, 35, 43, 46], "model": [2, 4, 7, 8, 9, 11, 16, 18, 19, 21, 25, 31, 37, 41], "dataset": [2, 4, 7, 8, 9, 19, 25, 28, 37, 39, 41, 44, 45], "sigmoid": [2, 7, 18, 19, 36], "logist": [2, 4, 7, 18, 19, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46], "tensorflow": [2, 4, 8, 13, 14, 15], "updat": [2, 4, 8], "weight": [2, 4, 8], "epoch": [2, 4, 8, 10], "batch": [2, 4, 8, 10, 19], "function": [2, 4, 8, 9, 13, 14, 15, 18, 19, 21, 22, 25, 29, 36, 38, 39, 43, 44, 45, 46, 53], "congratul": [2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 28, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46], "simpl": [2, 4, 8, 9], "normal": [4, 8, 9, 28], "data": [4, 8, 9, 10, 11, 18, 19, 22, 25, 31, 33, 34, 37, 40, 48, 49], "numpi": [4, 9, 19, 26], "forward": [4, 9], "prop": [4, 9], "predict": [4, 8, 9, 10, 19, 21, 23, 25, 31, 41, 51], "practic": [5, 10, 16, 17, 19, 24, 25, 32, 50, 51], "handwritten": [5, 6, 10], "digit": [5, 6, 10], "recognit": [5, 6, 10], "binari": [5, 6], "outlin": [5, 6, 10, 16, 17, 19, 25, 26, 33, 34, 48, 49, 50, 51, 52], "multiclass": 10, "4": [10, 18, 19], "2": [10, 11, 16, 18, 19, 24, 25, 32, 49], "1": [10, 11, 16, 18, 19, 24, 32, 49], "view": [10, 17, 19, 25, 29, 31, 33, 34, 49], "variabl": [10, 17, 19, 25, 27, 28, 33, 34, 49], "check": [10, 17, 19, 25, 33, 34, 49], "dimens": [10, 17, 19, 25, 33, 34, 49], "your": [10, 17, 19, 25, 33, 34, 49], "3": [10, 18, 19, 24, 25, 32], "visual": [10, 11, 18, 19, 22, 25, 33, 34, 49], "loss": [10, 19, 38], "cost": [10, 13, 14, 15, 18, 19, 22, 23, 25, 39, 43, 44, 45, 46], "multi": [11, 28], "class": 11, "classif": [11, 19, 35], "goal": [11, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 37, 39, 40, 41, 42, 43, 44, 45, 46], "tool": [11, 21, 22, 23, 28, 29, 30, 31], "0": 11, "prepar": 11, "our": 11, "explan": 11, "7d751c8658284b28bf1734eed56153b5": 11, "output": [11, 13, 14, 15], "db5508d4774e4bfdbf6b6e91b1596d8d": 11, "relu": 12, "why": 12, "non": 12, "softmax": [13, 14, 15], "The": [13, 14, 15], "obviou": [13, 14, 15], "organ": [13, 14, 15], "prefer": [13, 14, 15], "a3547526c0a344d19eba1bb25a072d4f": 13, "handl": [13, 14, 15], "sparsecategorialcrossentropi": [13, 14, 15], "categoricalcrossentropi": [13, 14, 15], "2d68fe26ee2d4ee0a0dd375b30d3b5c3": 14, "cb2e8466a51b460cb6c1d35f4a7cde47": 15, "advic": 16, "appli": 16, "plot": [16, 18, 19, 37, 40], "train": 16, "test": 16, "set": [16, 22, 31, 40], "5": [16, 18, 19], "complex": [16, 29], "decis": [17, 18, 19, 37], "tree": 17, "problem": [18, 19, 21, 22, 25, 28, 35], "statement": [18, 19, 20, 21, 22, 24, 25, 28], "load": [18, 19, 31], "gradient": [18, 19, 23, 30, 40, 43, 46], "6": [18, 19], "paramet": [18, 19, 31, 49], "us": [18, 19, 30, 31, 41], "descent": [18, 19, 23, 30, 40, 43, 46], "7": [18, 19, 28], "boundari": [18, 19, 37], "8": [18, 19], "evalu": [18, 19], "exercis": [18, 19], "regular": [18, 19, 43, 46], "featur": [18, 19, 28, 29], "map": [18, 19], "my": [18, 19], "solut": [18, 19], "supervised_machine_learn": [19, 24], "modul": 19, "w1": 19, "brief": [19, 20, 24], "introduct": [19, 20, 24], "python": [19, 20, 24, 26], "jupyt": [19, 20, 24], "notebook": [19, 20, 24], "print": [19, 20, 24], "quiz": [19, 24, 32], "w2": [19, 25], "vector": [19, 26], "refer": 19, "abstract": 19, "arrai": 19, "creation": 19, "oper": 19, "matric": 19, "matrix": 19, "assign": [19, 25], "refresh": [19, 37], "comput": [19, 22, 43, 46], "implement": [19, 25, 40], "assignment2": 19, "w3": 19, "approach": [19, 35], "formula": [19, 36], "squar": [19, 38], "error": [19, 38], "code": [19, 40], "descript": [19, 40], "exampl": [19, 31, 39, 43, 44, 45, 46, 53], "let": [19, 40], "result": [19, 40], "ungrad": [19, 41, 42], "scikit": [19, 30, 31, 41], "fit": [19, 31, 41, 43, 46], "make": [19, 31, 41], "calcul": [19, 40, 41], "accuraci": [19, 41], "overfit": [19, 42], "9": [19, 28], "ad": [19, 43, 46], "both": [19, 43, 46], "rerun": [19, 43, 46], "over": [19, 43, 46], "represent": 21, "notat": [21, 28], "challeng": 21, "tip": 21, "intuit": 22, "3d": 22, "larger": 22, "convex": 22, "surfac": 22, "versu": 23, "iter": 23, "weak": [24, 32], "multipl": 27, "scale": [28, 29], "rate": 28, "alpha": 28, "9e": 28, "1e": 28, "z": 28, "score": 28, "acknowledg": 28, "engin": 29, "polynomi": 29, "select": [29, 49], "an": [29, 51], "altern": 29, "creat": 31, "second": 31, "anoth": 40, "unsupervised_learn": 47, "k": 48, "mean": 48, "cluster": 48, "process": 48, "anomali": 49, "detect": 49, "estim": 49, "gaussian": 49, "threshold": 49, "epsilon": 49, "5ff5059644d14581b2ede9b6e83274e4": 50, "collabor": 50, "filter": [50, 51], "recommend": 50, "system": 50, "70d809325fa34fdf820b6f7e2299c5a1": 50, "63d83120825841468e46bdb655c6b010": 50, "97ed931890c34e4887390a8c0e1a89a7": 51, "deep": [51, 52], "base": 51, "426b53334ef34731b981afd5c3b4ebe2": 51, "exist": 51, "user": 51, "find": 51, "similar": 51, "item": 51, "q": 52, "lunar": 52, "lander": 52, "state": 53, "action": 53, "valu": 53}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx": 57}, "alltitles": {"Welcome to Machine-Learning-Andrew-Ng\u2019s documentation!": [[0, "welcome-to-machine-learning-andrew-ng-s-documentation"]], "Contents:": [[0, null]], "Indices and tables": [[0, "indices-and-tables"]], "Advanced_Learning_Algorithms": [[1, "Advanced_Learning_Algorithms"], [2, "Advanced_Learning_Algorithms"], [4, "Advanced_Learning_Algorithms"]], "(Convolutional Neural Networks)": [[1, "(Convolutional-Neural-Networks)"], [2, "(Convolutional-Neural-Networks)"], [4, "(Convolutional-Neural-Networks)"]], "Optional Lab - Neurons and Layers": [[2, "Optional-Lab---Neurons-and-Layers"], [4, "Optional-Lab---Neurons-and-Layers"], [7, "Optional-Lab---Neurons-and-Layers"]], "Packages": [[2, "Packages"], [4, "Packages"], [7, "Packages"]], "Neuron without activation - Regression/Linear Model": [[2, "Neuron-without-activation---Regression/Linear-Model"], [4, "Neuron-without-activation---Regression/Linear-Model"], [7, "Neuron-without-activation---Regression/Linear-Model"]], "DataSet": [[2, "DataSet"], [2, "id1"], [4, "DataSet"], [4, "id1"], [4, "id3"], [7, "DataSet"], [7, "id1"], [8, "DataSet"], [9, "DataSet"]], "Neuron with Sigmoid activation": [[2, "Neuron-with-Sigmoid-activation"], [7, "Neuron-with-Sigmoid-activation"]], "Logistic Neuron": [[2, "Logistic-Neuron"], [4, "Logistic-Neuron"], [7, "Logistic-Neuron"]], "Tensorflow Model": [[2, "Tensorflow-Model"], [4, "Tensorflow-Model"], [8, "Tensorflow-Model"]], "Updated Weights": [[2, "Updated-Weights"], [4, "Updated-Weights"], [8, "Updated-Weights"]], "Epochs and batches": [[2, "Epochs-and-batches"], [4, "Epochs-and-batches"], [8, "Epochs-and-batches"], [10, "Epochs-and-batches"]], "Layer Functions": [[2, "Layer-Functions"], [8, "Layer-Functions"]], "Congratulations!": [[2, "Congratulations!"], [4, "Congratulations!"], [7, "Congratulations!"], [8, "Congratulations!"], [9, "Congratulations!"], [10, "Congratulations!"], [11, "Congratulations!"], [12, "Congratulations!"], [13, "Congratulations!"], [14, "Congratulations!"], [15, "Congratulations!"], [16, "Congratulations!"], [20, "Congratulations!"], [21, "Congratulations!"], [22, "Congratulations!"], [23, "Congratulations!"], [28, "Congratulations!"], [35, "Congratulations!"], [36, "Congratulations!"], [37, "Congratulations!"], [39, "Congratulations!"], [40, "Congratulations!"], [42, "Congratulations!"], [43, "Congratulations!"], [44, "Congratulations!"], [45, "Congratulations!"], [46, "Congratulations!"]], "Optional Lab - Simple Neural Network": [[2, "Optional-Lab---Simple-Neural-Network"], [4, "Optional-Lab---Simple-Neural-Network"], [4, "id2"], [8, "Optional-Lab---Simple-Neural-Network"], [9, "Optional-Lab---Simple-Neural-Network"]], "Normalize Data": [[4, "Normalize-Data"], [4, "id4"], [8, "Normalize-Data"], [9, "Normalize-Data"]], "Numpy Model (Forward Prop in NumPy)": [[4, "Numpy-Model-(Forward-Prop-in-NumPy)"], [9, "Numpy-Model-(Forward-Prop-in-NumPy)"]], "Predictions": [[4, "Predictions"], [8, "Predictions"], [9, "Predictions"], [23, "Predictions"]], "Network function": [[4, "Network-function"], [9, "Network-function"]], "Practice Lab: Neural Networks for Handwritten Digit Recognition, Binary": [[5, "Practice-Lab:-Neural-Networks-for-Handwritten-Digit-Recognition,-Binary"]], "Outline": [[5, "Outline"], [6, "Outline"], [10, "Outline"], [16, "Outline"], [17, "Outline"], [19, "Outline"], [19, "id8"], [25, "Outline"], [26, "Outline"], [33, "Outline"], [34, "Outline"], [48, "Outline"], [49, "Outline"], [52, "Outline"]], "Neural Networks for Handwritten Digit Recognition, Binary": [[6, "Neural-Networks-for-Handwritten-Digit-Recognition,-Binary"]], "Regression/Linear Model": [[7, "Regression/Linear-Model"]], "Model": [[8, "Model"]], "Practice Lab: Neural Networks for Handwritten Digit Recognition, Multiclass": [[10, "Practice-Lab:-Neural-Networks-for-Handwritten-Digit-Recognition,-Multiclass"]], "4.2.1 View the variables": [[10, "4.2.1-View-the-variables"]], "4.2.2 Check the dimensions of your variables": [[10, "4.2.2-Check-the-dimensions-of-your-variables"]], "4.2.3 Visualizing the Data": [[10, "4.2.3-Visualizing-the-Data"]], "Loss (cost)": [[10, "Loss-(cost)"]], "Prediction": [[10, "Prediction"], [21, "Prediction"]], "Optional Lab - Multi-class Classification": [[11, "Optional-Lab---Multi-class-Classification"]], "1.1 Goals": [[11, "1.1-Goals"], [19, "1.1-Goals"]], "1.2 Tools": [[11, "1.2-Tools"]], "2.0 Multi-class Classification": [[11, "2.0-Multi-class-Classification"]], "2.1 Prepare and visualize our data": [[11, "2.1-Prepare-and-visualize-our-data"]], "2.2 Model": [[11, "2.2-Model"]], "Explanation": [[11, "Explanation"]], "Layer 1 7d751c8658284b28bf1734eed56153b5": [[11, "Layer-1-7d751c8658284b28bf1734eed56153b5"]], "Layer 2, the output layer db5508d4774e4bfdbf6b6e91b1596d8d": [[11, "Layer-2,-the-output-layer-db5508d4774e4bfdbf6b6e91b1596d8d"]], "Optional Lab - ReLU activation": [[12, "Optional-Lab---ReLU-activation"]], "Why Non-Linear Activations?": [[12, "Why-Non-Linear-Activations?"]], "Optional Lab - Softmax Function": [[13, "Optional-Lab---Softmax-Function"], [14, "Optional-Lab---Softmax-Function"], [15, "Optional-Lab---Softmax-Function"]], "Softmax Function": [[13, "Softmax-Function"], [14, "Softmax-Function"], [15, "Softmax-Function"]], "Cost": [[13, "Cost"], [14, "Cost"], [15, "Cost"]], "Tensorflow": [[13, "Tensorflow"], [14, "Tensorflow"], [15, "Tensorflow"]], "The Obvious organization": [[13, "The-Obvious-organization"], [14, "The-Obvious-organization"], [15, "The-Obvious-organization"]], "Preferred a3547526c0a344d19eba1bb25a072d4f": [[13, "Preferred-a3547526c0a344d19eba1bb25a072d4f"]], "Output Handling": [[13, "Output-Handling"], [14, "Output-Handling"], [15, "Output-Handling"]], "SparseCategorialCrossentropy or CategoricalCrossEntropy": [[13, "SparseCategorialCrossentropy-or-CategoricalCrossEntropy"], [14, "SparseCategorialCrossentropy-or-CategoricalCrossEntropy"], [15, "SparseCategorialCrossentropy-or-CategoricalCrossEntropy"]], "Preferred 2d68fe26ee2d4ee0a0dd375b30d3b5c3": [[14, "Preferred-2d68fe26ee2d4ee0a0dd375b30d3b5c3"]], "Preferred cb2e8466a51b460cb6c1d35f4a7cde47": [[15, "Preferred-cb2e8466a51b460cb6c1d35f4a7cde47"]], "Practice Lab: Advice for Applying Machine Learning": [[16, "Practice-Lab:-Advice-for-Applying-Machine-Learning"]], "2.1.1 Plot Train, Test sets": [[16, "2.1.1-Plot-Train,-Test-sets"]], "5.1 Complex model": [[16, "5.1-Complex-model"]], "Practice Lab: Decision Trees": [[17, "Practice-Lab:-Decision-Trees"]], "View the variables": [[17, "View-the-variables"], [19, "View-the-variables"], [25, "View-the-variables"], [33, "View-the-variables"], [33, "id1"], [34, "View-the-variables"], [34, "id1"], [49, "View-the-variables"]], "Check the dimensions of your variables": [[17, "Check-the-dimensions-of-your-variables"], [19, "Check-the-dimensions-of-your-variables"], [25, "Check-the-dimensions-of-your-variables"], [33, "Check-the-dimensions-of-your-variables"], [33, "id2"], [34, "Check-the-dimensions-of-your-variables"], [34, "id2"], [49, "Check-the-dimensions-of-your-variables"], [49, "id1"]], "2 - Logistic Regression": [[18, "2---Logistic-Regression"], [18, "id5"], [19, "2---Logistic-Regression"]], "2.1 Problem Statement": [[18, "2.1-Problem-Statement"], [18, "id6"], [19, "2.1-Problem-Statement"]], "2.2 Loading and visualizing the data": [[18, "2.2-Loading-and-visualizing-the-data"], [18, "id7"], [19, "2.2-Loading-and-visualizing-the-data"]], "2.3 Sigmoid function": [[18, "2.3-Sigmoid-function"], [18, "id8"], [19, "2.3-Sigmoid-function"]], "2.4 Cost function for logistic regression": [[18, "2.4-Cost-function-for-logistic-regression"], [18, "id9"], [19, "2.4-Cost-function-for-logistic-regression"]], "2.5 Gradient for logistic regression": [[18, "2.5-Gradient-for-logistic-regression"], [18, "id10"], [19, "2.5-Gradient-for-logistic-regression"]], "2.6 Learning parameters using gradient descent": [[18, "2.6-Learning-parameters-using-gradient-descent"], [18, "id11"], [19, "2.6-Learning-parameters-using-gradient-descent"]], "2.7 Plotting the decision boundary": [[18, "2.7-Plotting-the-decision-boundary"], [18, "id12"], [19, "2.7-Plotting-the-decision-boundary"]], "2.8 Evaluating logistic regression": [[18, "2.8-Evaluating-logistic-regression"], [18, "id13"], [19, "2.8-Evaluating-logistic-regression"]], "Exercise 4": [[18, "Exercise-4"], [18, "id14"], [19, "Exercise-4"]], "3 - Regularized Logistic Regression": [[18, "3---Regularized-Logistic-Regression"], [18, "id15"], [19, "3---Regularized-Logistic-Regression"]], "3.1 Problem Statement": [[18, "3.1-Problem-Statement"], [18, "id16"], [19, "3.1-Problem-Statement"]], "3.2 Loading and visualizing the data": [[18, "3.2-Loading-and-visualizing-the-data"], [18, "id17"], [19, "3.2-Loading-and-visualizing-the-data"]], "3.3 Feature mapping": [[18, "3.3-Feature-mapping"], [18, "id18"], [19, "3.3-Feature-mapping"]], "3.4 Cost function for regularized logistic regression": [[18, "3.4-Cost-function-for-regularized-logistic-regression"], [18, "id19"], [19, "3.4-Cost-function-for-regularized-logistic-regression"]], "3.5 Gradient for regularized logistic regression": [[18, "3.5-Gradient-for-regularized-logistic-regression"], [18, "id20"], [19, "3.5-Gradient-for-regularized-logistic-regression"]], "3.6 Learning parameters using gradient descent": [[18, "3.6-Learning-parameters-using-gradient-descent"], [18, "id21"], [19, "3.6-Learning-parameters-using-gradient-descent"]], "3.7 Plotting the decision boundary": [[18, "3.7-Plotting-the-decision-boundary"], [18, "id22"], [19, "3.7-Plotting-the-decision-boundary"]], "3.8 Evaluating regularized logistic regression model": [[18, "3.8-Evaluating-regularized-logistic-regression-model"], [18, "id23"], [19, "3.8-Evaluating-regularized-logistic-regression-model"]], "My Solution": [[18, "My-Solution"], [18, "id24"], [19, "My-Solution"]], "Supervised_Machine_Learning": [[19, "Supervised_Machine_Learning"], [24, "Supervised_Machine_Learning"]], "Module - 1": [[19, "Module---1"]], "Optional Lab - W1: Brief Introduction to Python and Jupyter Notebooks": [[19, "Optional-Lab---W1:-Brief-Introduction-to-Python-and-Jupyter-Notebooks"]], "Goals": [[19, "Goals"], [19, "id11"], [19, "id15"], [19, "id17"], [19, "id18"], [20, "Goals"], [21, "Goals"], [22, "Goals"], [23, "Goals"], [24, "Goals"], [28, "Goals"], [29, "Goals"], [30, "Goals"], [31, "Goals"], [37, "Goals"], [39, "Goals"], [40, "Goals"], [41, "Goals"], [42, "Goals"], [43, "Goals"], [44, "Goals"], [45, "Goals"], [46, "Goals"]], "Python": [[19, "Python"], [20, "Python"], [24, "Python"]], "Print statement": [[19, "Print-statement"], [20, "Print-statement"], [24, "Print-statement"]], "Practice Quiz": [[19, "Practice-Quiz"], [19, "id4"], [19, "id19"]], "Quiz - 1": [[19, "Quiz---1"]], "Quiz - 2": [[19, "Quiz---2"]], "Quiz - 3": [[19, "Quiz---3"]], "Module - 2": [[19, "Module---2"]], "Optional Lab W2: Python, NumPy and Vectorization": [[19, "Optional-Lab-W2:-Python,-NumPy-and-Vectorization"]], "1.2 Useful References": [[19, "1.2-Useful-References"]], "2 Python and NumPy": [[19, "2-Python-and-NumPy"]], "3 Vectors": [[19, "3-Vectors"]], "3.1 Abstract": [[19, "3.1-Abstract"]], "3.2 NumPy Arrays": [[19, "3.2-NumPy-Arrays"]], "3.3 Vector Creation": [[19, "3.3-Vector-Creation"]], "3.4 Operations on Vectors": [[19, "3.4-Operations-on-Vectors"]], "4 Matrices": [[19, "4-Matrices"]], "4.1 Abstract": [[19, "4.1-Abstract"]], "4.2 NumPy Arrays": [[19, "4.2-NumPy-Arrays"]], "4.3 Matrix Creation": [[19, "4.3-Matrix-Creation"]], "4.4 Operations on Matrices": [[19, "4.4-Operations-on-Matrices"]], "Quiz-1": [[19, "Quiz-1"], [19, "id20"]], "Quiz-2": [[19, "Quiz-2"], [19, "id21"]], "Quiz-3": [[19, "Quiz-3"]], "Assignment W2:": [[19, "Assignment-W2:"]], "Practice Lab: Linear Regression": [[19, "Practice-Lab:-Linear-Regression"], [25, "Practice-Lab:-Linear-Regression"]], "1 - Packages": [[19, "1---Packages"], [19, "id22"]], "2 - Problem Statement": [[19, "2---Problem-Statement"], [25, "2---Problem-Statement"]], "3 - Dataset": [[19, "3---Dataset"], [25, "3---Dataset"]], "Visualize your data": [[19, "Visualize-your-data"], [25, "Visualize-your-data"], [33, "Visualize-your-data"], [33, "id3"], [34, "Visualize-your-data"], [34, "id3"], [49, "Visualize-your-data"]], "4 - Refresher on linear regression": [[19, "4---Refresher-on-linear-regression"]], "5 - Compute Cost": [[19, "5---Compute-Cost"]], "Cost function": [[19, "Cost-function"], [19, "id16"], [25, "Cost-function"], [39, "Cost-function"], [44, "Cost-function"], [45, "Cost-function"]], "Model prediction": [[19, "Model-prediction"], [25, "Model-prediction"]], "Implementation": [[19, "Implementation"], [25, "Implementation"]], "Exercise 1": [[19, "Exercise-1"]], "6 - Gradient descent": [[19, "6---Gradient-descent"]], "Exercise 2": [[19, "Exercise-2"]], "6.1 Learning parameters using batch gradient descent": [[19, "6.1-Learning-parameters-using-batch-gradient-descent"]], "Assignment2: My solution": [[19, "Assignment2:-My-solution"]], "Module - 3": [[19, "Module---3"]], "Optional Lab W3": [[19, "Optional-Lab-W3"]], "Optional Lab - 3.1: Classification": [[19, "Optional-Lab---3.1:-Classification"]], "Classification Problems": [[19, "Classification-Problems"], [35, "Classification-Problems"]], "Linear Regression approach": [[19, "Linear-Regression-approach"], [35, "Linear-Regression-approach"]], "Optional Lab - 3.2: Logistic Regression": [[19, "Optional-Lab---3.2:-Logistic-Regression"]], "Sigmoid or Logistic Function": [[19, "Sigmoid-or-Logistic-Function"], [36, "Sigmoid-or-Logistic-Function"]], "Formula for Sigmoid function": [[19, "Formula-for-Sigmoid-function"], [36, "Formula-for-Sigmoid-function"]], "Logistic Regression": [[19, "Logistic-Regression"], [33, "Logistic-Regression"], [34, "Logistic-Regression"], [36, "Logistic-Regression"]], "Optional Lab - 3.3: Logistic Regression, Decision Boundary": [[19, "Optional-Lab---3.3:-Logistic-Regression,-Decision-Boundary"]], "Dataset": [[19, "Dataset"], [37, "Dataset"], [39, "Dataset"], [41, "Dataset"], [44, "Dataset"], [45, "Dataset"]], "Plot data": [[19, "Plot-data"], [37, "Plot-data"]], "Logistic regression model": [[19, "Logistic-regression-model"], [37, "Logistic-regression-model"]], "Refresher on logistic regression and decision boundary": [[19, "Refresher-on-logistic-regression-and-decision-boundary"], [37, "Refresher-on-logistic-regression-and-decision-boundary"]], "Plotting decision boundary": [[19, "Plotting-decision-boundary"], [37, "Plotting-decision-boundary"]], "Optional Lab - 3.4: Logistic Regression, Logistic Loss": [[19, "Optional-Lab---3.4:-Logistic-Regression,-Logistic-Loss"]], "Squared error for logistic regression?": [[19, "Squared-error-for-logistic-regression?"], [38, "Squared-error-for-logistic-regression?"]], "Logistic Loss Function": [[19, "Logistic-Loss-Function"], [38, "Logistic-Loss-Function"]], "Optional Lab - 3.5: Cost Function for Logistic Regression": [[19, "Optional-Lab---3.5:-Cost-Function-for-Logistic-Regression"]], "Code Description": [[19, "Code-Description"]], "Example": [[19, "Example"], [39, "Example"], [44, "Example"], [45, "Example"]], "Optional Lab - 3.6: Gradient Descent for Logistic Regression": [[19, "Optional-Lab---3.6:-Gradient-Descent-for-Logistic-Regression"]], "Logistic Gradient Descent": [[19, "Logistic-Gradient-Descent"], [40, "Logistic-Gradient-Descent"]], "Gradient Descent Implementation": [[19, "Gradient-Descent-Implementation"], [40, "Gradient-Descent-Implementation"]], "My solution": [[19, "My-solution"]], "Gradient Descent Code": [[19, "Gradient-Descent-Code"], [40, "Gradient-Descent-Code"]], "Let\u2019s plot the results of gradient descent:": [[19, "Let's-plot-the-results-of-gradient-descent:"], [40, "Let's-plot-the-results-of-gradient-descent:"]], "Optional Lab - 3.7: Ungraded Lab: Logistic Regression using Scikit-Learn": [[19, "Optional-Lab---3.7:-Ungraded-Lab:-Logistic-Regression-using-Scikit-Learn"]], "Fit the model": [[19, "Fit-the-model"], [41, "Fit-the-model"]], "Make Predictions": [[19, "Make-Predictions"], [31, "Make-Predictions"], [41, "Make-Predictions"]], "Calculate accuracy": [[19, "Calculate-accuracy"], [41, "Calculate-accuracy"]], "Optional Lab - 3.8: Ungraded Lab: Logistic Regression using Scikit-Learn": [[19, "Optional-Lab---3.8:-Ungraded-Lab:-Logistic-Regression-using-Scikit-Learn"]], "Ungraded Lab: Overfitting": [[19, "Ungraded-Lab:-Overfitting"], [42, "Ungraded-Lab:-Overfitting"]], "Overfitting": [[19, "Overfitting"], [42, "Overfitting"]], "Optional Lab - 3.9 - Regularized Cost and Gradient": [[19, "Optional-Lab---3.9---Regularized-Cost-and-Gradient"]], "Adding regularization": [[19, "Adding-regularization"], [43, "Adding-regularization"], [46, "Adding-regularization"]], "Cost functions with regularization": [[19, "Cost-functions-with-regularization"], [43, "Cost-functions-with-regularization"], [46, "Cost-functions-with-regularization"]], "Cost function for regularized logistic regression": [[19, "Cost-function-for-regularized-logistic-regression"], [43, "Cost-function-for-regularized-logistic-regression"], [46, "Cost-function-for-regularized-logistic-regression"]], "Gradient descent with regularization": [[19, "Gradient-descent-with-regularization"], [43, "Gradient-descent-with-regularization"], [46, "Gradient-descent-with-regularization"]], "Computing the Gradient with regularization (both linear/logistic)": [[19, "Computing-the-Gradient-with-regularization-(both-linear/logistic)"], [43, "Computing-the-Gradient-with-regularization-(both-linear/logistic)"], [46, "Computing-the-Gradient-with-regularization-(both-linear/logistic)"]], "Gradient function for regularized linear regression": [[19, "Gradient-function-for-regularized-linear-regression"], [43, "Gradient-function-for-regularized-linear-regression"], [46, "Gradient-function-for-regularized-linear-regression"]], "Gradient function for regularized logistic regression": [[19, "Gradient-function-for-regularized-logistic-regression"], [43, "Gradient-function-for-regularized-logistic-regression"], [46, "Gradient-function-for-regularized-logistic-regression"]], "Rerun over-fitting example": [[19, "Rerun-over-fitting-example"], [43, "Rerun-over-fitting-example"], [46, "Rerun-over-fitting-example"]], "Assignment W3:": [[19, "Assignment-W3:"]], "Optional Lab: Brief Introduction to Python and Jupyter Notebooks": [[20, "Optional-Lab:-Brief-Introduction-to-Python-and-Jupyter-Notebooks"]], "Optional Lab: Model Representation": [[21, "Optional-Lab:-Model-Representation"]], "Notation": [[21, "Notation"], [28, "Notation"]], "Tools": [[21, "Tools"], [22, "Tools"], [23, "Tools"], [28, "Tools"], [29, "Tools"], [30, "Tools"], [31, "Tools"]], "Problem Statement": [[21, "Problem-Statement"], [22, "Problem-Statement"], [28, "Problem-Statement"]], "Model function": [[21, "Model-function"]], "Challenge": [[21, "Challenge"]], "Tip:": [[21, "Tip:"]], "Optional Lab: Cost Function": [[22, "Optional-Lab:-Cost-Function"]], "Computing Cost": [[22, "Computing-Cost"]], "Cost Function Intuition": [[22, "Cost-Function-Intuition"]], "Cost Function Visualization- 3D": [[22, "Cost-Function-Visualization--3D"]], "Larger Data Set": [[22, "Larger-Data-Set"]], "Convex Cost surface": [[22, "Convex-Cost-surface"]], "Optional Lab: Gradient Descent for Linear Regression": [[23, "Optional-Lab:-Gradient-Descent-for-Linear-Regression"]], "Cost versus iterations of gradient descent": [[23, "Cost-versus-iterations-of-gradient-descent"]], "Weak-1": [[24, "Weak-1"]], "Practice Quiz - 1": [[24, "Practice-Quiz---1"], [32, "Practice-Quiz---1"]], "Practice Quiz - 2": [[24, "Practice-Quiz---2"], [32, "Practice-Quiz---2"]], "Practice Quiz - 3": [[24, "Practice-Quiz---3"], [32, "Practice-Quiz---3"]], "Optional Lab - 1: Brief Introduction to Python and Jupyter Notebooks": [[24, "Optional-Lab---1:-Brief-Introduction-to-Python-and-Jupyter-Notebooks"]], "Assignment - W2:": [[25, "Assignment---W2:"]], "Optional Lab: Python, NumPy and Vectorization": [[26, "Optional-Lab:-Python,-NumPy-and-Vectorization"]], "Optional Lab: Multiple Variable Linear Regression": [[27, "Optional-Lab:-Multiple-Variable-Linear-Regression"]], "Optional Lab: Feature scaling and Learning Rate (Multi-variable)": [[28, "Optional-Lab:-Feature-scaling-and-Learning-Rate-(Multi-variable)"]], "Dataset:": [[28, "Dataset:"]], "Learning Rate": [[28, "Learning-Rate"]], "\\alpha = 9.9e-7": [[28, "\\alpha-=-9.9e-7"]], "\\alpha = 9e-7": [[28, "\\alpha-=-9e-7"]], "\\alpha = 1e-7": [[28, "\\alpha-=-1e-7"]], "Feature Scaling": [[28, "Feature-Scaling"]], "z-score normalization": [[28, "z-score-normalization"]], "Acknowledgments": [[28, "Acknowledgments"]], "Optional Lab: Feature Engineering and Polynomial Regression": [[29, "Optional-Lab:-Feature-Engineering-and-Polynomial-Regression"]], "Selecting Features": [[29, "Selecting-Features"]], "An Alternate View": [[29, "An-Alternate-View"]], "Scaling features": [[29, "Scaling-features"]], "Complex Functions": [[29, "Complex-Functions"]], "Optional Lab: Linear Regression using Scikit-Learn": [[30, "Optional-Lab:-Linear-Regression-using-Scikit-Learn"], [31, "Optional-Lab:-Linear-Regression-using-Scikit-Learn"]], "Gradient Descent": [[30, "Gradient-Descent"]], "Load the data set": [[31, "Load-the-data-set"]], "Create and fit the model": [[31, "Create-and-fit-the-model"]], "View Parameters": [[31, "View-Parameters"]], "Second Example": [[31, "Second-Example"]], "Weak-2": [[32, "Weak-2"]], "Optional Lab: Classification": [[35, "Optional-Lab:-Classification"]], "Optional Lab: Logistic Regression": [[36, "Optional-Lab:-Logistic-Regression"]], "Optional Lab: Logistic Regression, Decision Boundary": [[37, "Optional-Lab:-Logistic-Regression,-Decision-Boundary"]], "Optional Lab: Logistic Regression, Logistic Loss": [[38, "Optional-Lab:-Logistic-Regression,-Logistic-Loss"]], "Congratulation!": [[38, "Congratulation!"]], "Optional Lab: Cost Function for Logistic Regression": [[39, "Optional-Lab:-Cost-Function-for-Logistic-Regression"], [44, "Optional-Lab:-Cost-Function-for-Logistic-Regression"], [45, "Optional-Lab:-Cost-Function-for-Logistic-Regression"]], "Optional Lab: Gradient Descent for Logistic Regression": [[40, "Optional-Lab:-Gradient-Descent-for-Logistic-Regression"]], "Data set": [[40, "Data-set"]], "Calculating the Gradient, Code Description": [[40, "Calculating-the-Gradient,-Code-Description"]], "Another Data set": [[40, "Another-Data-set"]], "Ungraded Lab: Logistic Regression using Scikit-Learn": [[41, "Ungraded-Lab:-Logistic-Regression-using-Scikit-Learn"]], "Optional Lab - Regularized Cost and Gradient": [[43, "Optional-Lab---Regularized-Cost-and-Gradient"], [46, "Optional-Lab---Regularized-Cost-and-Gradient"]], "Cost function for regularized linear regression": [[43, "Cost-function-for-regularized-linear-regression"], [46, "Cost-function-for-regularized-linear-regression"]], "Unsupervised_Learning": [[47, "Unsupervised_Learning"]], "K-means Clustering": [[48, "K-means-Clustering"]], "Processing data": [[48, "Processing-data"]], "Anomaly Detection": [[49, "Anomaly-Detection"]], "2.2.1 Estimating parameters for a Gaussian": [[49, "2.2.1-Estimating-parameters-for-a-Gaussian"]], "2.2.2 Selecting the threshold \\epsilon": [[49, "2.2.2-Selecting-the-threshold-\\epsilon"]], "Anomaly detection": [[49, "Anomaly-detection"]], "5ff5059644d14581b2ede9b6e83274e4 Practice lab: Collaborative Filtering Recommender Systems": [[50, "5ff5059644d14581b2ede9b6e83274e4-Practice-lab:-Collaborative-Filtering-Recommender-Systems"]], "70d809325fa34fdf820b6f7e2299c5a1 Outline": [[50, "70d809325fa34fdf820b6f7e2299c5a1-Outline"]], "Packages 63d83120825841468e46bdb655c6b010": [[50, "Packages-63d83120825841468e46bdb655c6b010"]], "97ed931890c34e4887390a8c0e1a89a7 Practice lab: Deep Learning for Content-Based Filtering": [[51, "97ed931890c34e4887390a8c0e1a89a7-Practice-lab:-Deep-Learning-for-Content-Based-Filtering"]], "Outline 426b53334ef34731b981afd5c3b4ebe2": [[51, "Outline-426b53334ef34731b981afd5c3b4ebe2"]], "Predictions for an existing user.": [[51, "Predictions-for-an-existing-user."]], "Finding Similar Items": [[51, "Finding-Similar-Items"]], "Deep Q-Learning - Lunar Lander": [[52, "Deep-Q-Learning---Lunar-Lander"]], "State Action Value Function Example": [[53, "State-Action-Value-Function-Example"]]}, "indexentries": {}})